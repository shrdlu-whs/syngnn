{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Export env vars to limit number of threads to use\n",
    "num_threads = \"26\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = num_threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = num_threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = num_threads\n",
    "\n",
    "# Only use CPU, hide GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#Import SummaryWriter for Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import evaluate\n",
    "import numpy as np\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "# Easy file reading\n",
    "import glob\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/home/shrdlu/cdaniel/syntrans/utilities.py'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utilities as utils\n",
    "# Reload library if changed\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit no. of threads used by Pytorch\n",
    "torch.set_num_threads = int(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 12622, PGID: 113\n"
     ]
    }
   ],
   "source": [
    "PID = os.getpid()\n",
    "PGID = os.getpgid(PID)\n",
    "print(f\"PID: {PID}, PGID: {PGID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "activeMode= \"develop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: bert-base-uncased\n",
      "Data path: ./data/original/ud/\n",
      "Tokenizer: bert-base-uncased\n",
      "Batch size: 2\n",
      "Epochs: 3\n",
      "Learning rate: 5e-05\n",
      "Sequence length: 133\n",
      "Training: False\n"
     ]
    }
   ],
   "source": [
    "configuration_csv = pd.read_csv(f\"./config/{activeMode}.csv\", dtype=str, sep=\";\")\n",
    "config = utils.configureParameters(configuration_csv)\n",
    "print(f\"Model path: {config.saved_model_path}\")\n",
    "print(f\"Data path: {config.data_path}\")\n",
    "print(f\"Tokenizer: {config.tokenizer}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"Sequence length: {config.sequence_length}\")\n",
    "print(f\"Training: {config.train_model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "tokenizer = BertTokenizer.from_pretrained(config.tokenizer)\n",
    "model = BertForMaskedLM.from_pretrained(config.saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cpu')\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMaskedInputs(inputs):\n",
    "    \"\"\"\n",
    "    creates masked input embeddings and labels from tokenized text\n",
    "\n",
    "    :param inputs: tokenized text\n",
    "    :return: masked input embeddings and new column labels \n",
    "    \"\"\" \n",
    "    # Clone input ids (tokens) to create labels\n",
    "    inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "    # create random array of floats with equal dimensions to input_ids tensor\n",
    "    rand = torch.rand(inputs.input_ids.shape)\n",
    "    # create mask array with 15% masked tokens\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "    # Select indices of each nonzero (= selected) value as token to be masked\n",
    "    selection = []\n",
    "\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        selection.append(\n",
    "            torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        )\n",
    "    # Mask selected tokens: replace with [MASK] code 103 in tensor\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntransDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ud_tokenizer(tokenizer, tokenizer_name):\n",
    "    tokenizer_path = \"./tokenizers/\" + tokenizer_name \n",
    "    special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "    ]\n",
    "    # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "    vocab_size = 30_522\n",
    "    # Load data\n",
    "    text = []\n",
    "    for ud_file in glob.iglob(config.data_path + '**/UD_English-Pronouns/en_*.txt', recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        tokenizer.train(files=ud_file, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "    # make the directory if not already there\n",
    "    if not os.path.isdir(tokenizer_path):\n",
    "        os.mkdir(tokenizer_path)\n",
    "    # save the tokenizer  \n",
    "    tokenizer.save_model(tokenizer_path)\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSentencesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentences\n",
    "    \"\"\" \n",
    "    sentences = []\n",
    "    for ud_file in glob.iglob(filepath, recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            sentences.extend(fp.read().split('\\n'))\n",
    "    return sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Print example of tokenized text\\nsentences = []\\nfor ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\\n\\n    ud_file = os.path.abspath(ud_file)\\n    filename = os.path.basename(ud_file)\\n    print(filename, flush = True)\\n    with open(ud_file, 'r') as fp:\\n        sentences.extend(fp.read().split('\\n'))\\ncount = 0\\nfor sentence in sentences:\\n    # Tokenize data\\n    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\\n    inputs = createMaskedInputs(inputs)\\n\\n    # Create dataset from tokenized data\\n    dataset = SyntransDataset(inputs)\\n    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\\n    if(count==1):\\n        print(inputs['input_ids'])\\n        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\\n        print(tokens)\\n        print(inputs['labels'])\\n        break\\n    count=count+1\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Print example of tokenized text\n",
    "sentences = []\n",
    "for ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\n",
    "\n",
    "    ud_file = os.path.abspath(ud_file)\n",
    "    filename = os.path.basename(ud_file)\n",
    "    print(filename, flush = True)\n",
    "    with open(ud_file, 'r') as fp:\n",
    "        sentences.extend(fp.read().split('\\n'))\n",
    "count = 0\n",
    "for sentence in sentences:\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs = createMaskedInputs(inputs)\n",
    "\n",
    "    # Create dataset from tokenized data\n",
    "    dataset = SyntransDataset(inputs)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    if(count==1):\n",
    "        print(inputs['input_ids'])\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        print(tokens)\n",
    "        print(inputs['labels'])\n",
    "        break\n",
    "    count=count+1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxSequenceLength(sentences, cutoff_limit_percent=0.9999):\n",
    "    \"\"\"\n",
    "    Calculate maximum sequence length for given data.\n",
    "    param sentences: list of sentences\n",
    "    param cutoff_limit_percent: percentage of all samples to accommodate with the max sequence length.\n",
    "    returns: max sequence length which encompasses cutoff_limit_percent of all data samples\n",
    "    \"\"\"\n",
    "    # Get number of tokens per sentence        \n",
    "    max_sentence_tokens = 0\n",
    "    sentence_tokens = {}\n",
    "    print(f\"Amount of samples: {len(sentences)}\")\n",
    "    # Tokenize data\n",
    "    for sentence in sentences:\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors='pt')\n",
    "        \n",
    "        token_count = inputs.input_ids.size(dim=1)\n",
    "        sentence_tokens[inputs.input_ids.size(dim=1)] = sentence_tokens.get(token_count,0) + 1\n",
    "        if(token_count > max_sentence_tokens): \n",
    "            max_sentence_tokens = token_count\n",
    "            \n",
    "    no_tokens = 0\n",
    "    # Calulate number of samples which should have a sequence length smaller than max_sequence_length\n",
    "    cutoff = cutoff_limit_percent * len(sentences)\n",
    "    max_sequence_length = 0\n",
    "    print(max_sentence_tokens)\n",
    "    for i in sorted(sentence_tokens):\n",
    "        # print((i, sentence_tokens[i]), end=\" \")\n",
    "        if(no_tokens <= cutoff):\n",
    "            no_tokens = no_tokens + sentence_tokens[i]\n",
    "            max_sequence_length = i\n",
    "\n",
    "    print(f\"Max sequence length: {max_sequence_length} with {cutoff_limit_percent}% of samples smaller\")\n",
    "    return max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = loadSentencesFromFiles(config.data_path + '**/en_*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getMaxSequenceLength(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (config.train_model):\n",
    "    print(\"Training model\", flush=True)\n",
    "\n",
    "    # Load data\n",
    "    sentences = loadSentencesFromFiles(config.data_path + '**/*-train.txt')\n",
    "\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs = createMaskedInputs(inputs)\n",
    "\n",
    "    # Create dataset from tokenized data\n",
    "    dataset = SyntransDataset(inputs)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "    # initialize optimizer\n",
    "    optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    epochs = config['epochs']\n",
    "    writer.add_scalar(\"LR\", config.learning_rate)\n",
    "    writer.add_scalar(\"Batchsize\", config.batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        scalar_loss = 0\n",
    "        # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(loader, leave=True, mininterval=40,maxinterval=120)\n",
    "        for batch in loop:\n",
    "            # initialize calculated gradients (from prev step)\n",
    "            optim.zero_grad()\n",
    "            # pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            # process\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            # extract loss\n",
    "            loss = outputs.loss\n",
    "            # calculate loss for every parameter that needs grad update\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            optim.step()\n",
    "            # print relevant info to progress bar\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            scalar_loss = loss.item()\n",
    "            loop.set_postfix(loss=scalar_loss)\n",
    "        # Print info to Tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", scalar_loss, epoch)\n",
    "        # Save model after each epoch\n",
    "        model.save_pretrained(save_directory=f\"./trained_models/{config.tokenizer}_E{epoch}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}/\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation\n",
      "\n",
      "en_gum-ud-test.txt\n",
      "en_lines-ud-test.txt\n",
      "en_atis-ud-test.txt\n",
      "en_pud-ud-test.txt\n",
      "en_pronouns-ud-test.txt\n",
      "en_partut-ud-test.txt\n",
      "en_esl-ud-test.txt\n",
      "en_ewt-ud-test.txt\n",
      "en_gumreddit-ud-test.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Model evaluation\\n\", flush = True)\n",
    "# Read test files\n",
    "sentences = loadSentencesFromFiles(config.data_path + '**/*-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "print(config.sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputsTest = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "inputsTest = createMaskedInputs(inputsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest = SyntransDataset(inputsTest)\n",
    "loader = torch.utils.data.DataLoader(datasetTest, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/93684 [00:00<?, ?it/s]/tmp/ipykernel_12622/3498486969.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  0%|          | 0/93684 [00:05<?, ?it/s]\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    references_all = []\n",
    "    predictions_all = []\n",
    "    references_roc_all = []\n",
    "    predictions_roc_all = []\n",
    "    # Setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True, mininterval=20,maxinterval=120)\n",
    "    for batch in loop:\n",
    "        # Pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).tolist()\n",
    "\n",
    "        softmax = nn.Softmax(dim = -1)\n",
    "        predictions = model(input_ids)\n",
    "        predictions = predictions['logits']\n",
    "        #print(np.shape(np.array(predictions)))\n",
    "        \n",
    "        predictions_sm = softmax(predictions)\n",
    "        #print(np.sum(np.array(predictions_sm[0][0])))\n",
    "        # Get index of argmax\n",
    "        #y = np.argmax(predictions_sm, axis = -1)\n",
    "        # y = y.tolist()\n",
    "        y = torch.topk(predictions, k=1, dim = 2)[1].squeeze()\n",
    "        y = y.tolist()\n",
    "\n",
    "#        words_pred = []\n",
    "#        words_true = []\n",
    "#        for w in y:\n",
    "#            words_pred.append( tokenizer.convert_ids_to_tokens(w))\n",
    "        \n",
    "#        for w in labels[0]:\n",
    "#            words_true.append( tokenizer.convert_ids_to_tokens(w))\n",
    "        \n",
    "        #print(words_pred[0:50])\n",
    "        #print(words_true[0:50])\n",
    "            \n",
    "\n",
    "        recall_metric = evaluate.load('recall')\n",
    "        precision_metric = evaluate.load('precision')\n",
    "        f1_metric = evaluate.load('f1')\n",
    "        roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "\n",
    "        # Go through all samples in batch and add to computation batch\n",
    "        for idx, pred_batch in enumerate(y):\n",
    "            references_all.extend(labels[idx])\n",
    "            predictions_all.extend(pred_batch)\n",
    "            #precision_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "            #recall_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "            #f1_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "        \n",
    "        # Calculate ROC\n",
    "        for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "            predictions_roc_all.extend(pred_batch.tolist())\n",
    "            references_roc_all.extend(labels[batch_idx])\n",
    "            #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "            break\n",
    "        break\n",
    "\n",
    "    numberOfBatches = len(loop)\n",
    "    # List all possible labels\n",
    "    labels = np.arange(tokenizer.vocab_size)\n",
    "    with open(f\"./logs/Results_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", \"w\") as output:\n",
    "        print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "        output.write(\"macro averaging\\n\")\n",
    "        output.write(str(recall_metric.compute(references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(precision_metric.compute(references = references_all, predictions = predictions_all, average = 'macro', zero_division = 0)))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(\"weighted averaging\\n\")\n",
    "        output.write(str(recall_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(precision_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted', zero_division = 0)))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000028vscode-remote?line=0'>1</a>\u001b[0m confusion_matrix \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mconfusion_matrix(references_all, predictions_all, labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000028vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m#print(confusion_matrix)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000028vscode-remote?line=2'>3</a>\u001b[0m disp \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mConfusionMatrixDisplay(references_all, predictions_all, labels\u001b[39m=\u001b[39;49mlabels)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000028vscode-remote?line=3'>4</a>\u001b[0m disp\u001b[39m.\u001b[39mplot()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(references_all, predictions_all, labels=labels)\n",
    "#print(confusion_matrix)\n",
    "#disp = metrics.ConfusionMatrixDisplay(references_all, predictions_all, labels=labels)\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got 101",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000029vscode-remote?line=5'>6</a>\u001b[0m recall \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000029vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m labels:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000029vscode-remote?line=7'>8</a>\u001b[0m     precision[i], recall[i], _ \u001b[39m=\u001b[39m precision_recall_curve(references_roc_all[i],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000029vscode-remote?line=8'>9</a>\u001b[0m                                                         predictions_roc_all[i])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000029vscode-remote?line=9'>10</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(recall[i], precision[i], lw\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclass \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_masked.ipynb#ch0000029vscode-remote?line=10'>11</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:867\u001b[0m, in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_recall_curve\u001b[39m(y_true, probas_pred, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    787\u001b[0m     \u001b[39m\"\"\"Compute precision-recall pairs for different probability thresholds.\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \n\u001b[1;32m    789\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[39m    array([0.1 , 0.35, 0.4 , 0.8 ])\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    868\u001b[0m         y_true, probas_pred, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    869\u001b[0m     )\n\u001b[1;32m    871\u001b[0m     ps \u001b[39m=\u001b[39m tps \u001b[39m+\u001b[39m fps\n\u001b[1;32m    872\u001b[0m     precision \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdivide(tps, ps, where\u001b[39m=\u001b[39m(ps \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:736\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m\"\"\"Calculate true and false positives per binary classification threshold.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \n\u001b[1;32m    704\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[39m    Decreasing score values.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[39m# Check to make sure y_true is valid\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m    738\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/sklearn/utils/multiclass.py:278\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    273\u001b[0m valid \u001b[39m=\u001b[39m (\n\u001b[1;32m    274\u001b[0m     \u001b[39misinstance\u001b[39m(y, Sequence) \u001b[39mor\u001b[39;00m issparse(y) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m ) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(y, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid:\n\u001b[0;32m--> 278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected array-like (array or non-string sequence), got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    282\u001b[0m sparse_pandas \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mSparseSeries\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSparseArray\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m sparse_pandas:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got 101"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# precision recall curve\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in labels:\n",
    "    precision[i], recall[i], _ = precision_recall_curve(references_roc_all[i],\n",
    "                                                        predictions_roc_all[i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "    break\n",
    "    \n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_syntrans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86a731642ee256d624a4d29e8688bb9c6ad7b39856affb444c6cc9f38126795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
