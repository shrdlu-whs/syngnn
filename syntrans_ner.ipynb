{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import utilities as utils\n",
    "\n",
    "activeMode= \"prod\"\n",
    "\n",
    "# Reload library if changed\n",
    "importlib.reload(utils)\n",
    "\n",
    "configuration_csv = pd.read_csv(f\"./config/{activeMode}.csv\", dtype=str, sep=\";\")\n",
    "config = utils.configureParameters(configuration_csv)\n",
    "print(f\"Task: {config.task}\")\n",
    "print(f\"Model path: {config.saved_model_path}\")\n",
    "print(f\"Data path: {config.data_path}\")\n",
    "print(f\"Tokenizer: {config.tokenizer}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"Sequence length: {config.sequence_length}\")\n",
    "print(f\"Training: {config.train_model}\")\n",
    "print(f\"Num Threads: {config.num_threads}\")\n",
    "print(f\"Num Sentences: {config.num_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Export env vars to limit number of threads to use\n",
    "num_threads = str(config.num_threads)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = num_threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = num_threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = num_threads\n",
    "\n",
    "# Only use CPU, hide GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForTokenClassification, BertConfig, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Import SummaryWriter for Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "# Load Pytorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.data as tg_data\n",
    "import torch_geometric.utils as tg_utils\n",
    "import torch_geometric.nn as tg_nn\n",
    "import evaluate\n",
    "# Evaluation metrics for NER task\n",
    "from seqeval.metrics import classification_report\n",
    "# Support for IOBES style NER labels\n",
    "from seqeval.scheme import IOBES\n",
    "import numpy as np\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "# Easy file reading\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID = os.getpid()\n",
    "PGID = os.getpgid(PID)\n",
    "print(f\"PID: {PID}, PGID: {PGID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit no. of threads used by Pytorch\n",
    "torch.set_num_threads = int(num_threads)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_list = ['X','O','<unk>', 'B-CARDINAL', 'E-CARDINAL', 'S-PERSON', 'S-CARDINAL', 'S-PRODUCT', 'B-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'E-WORK_OF_ART', 'B-PERSON', 'E-PERSON', 'S-GPE', 'B-DATE', 'I-DATE', 'E-DATE', 'S-ORDINAL', 'S-LANGUAGE', 'I-PERSON', 'S-EVENT', 'S-DATE', 'B-QUANTITY', 'E-QUANTITY', 'S-TIME', 'B-TIME', 'I-TIME', 'E-TIME', 'B-GPE', 'E-GPE', 'S-ORG', 'I-GPE', 'S-NORP', 'B-FAC', 'I-FAC', 'E-FAC', 'B-NORP', 'E-NORP', 'S-PERCENT', 'B-ORG', 'E-ORG', 'B-LANGUAGE', 'E-LANGUAGE', 'I-CARDINAL', 'I-ORG', 'S-WORK_OF_ART', 'I-QUANTITY', 'B-MONEY', 'I-MONEY', 'E-MONEY', 'B-LOC', 'E-LOC', 'I-LOC', 'B-PERCENT', 'I-PERCENT', 'E-PERCENT', 'S-LOC', 'S-FAC', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'S-MONEY', 'B-LAW', 'I-LAW', 'E-LAW', 'I-NORP', 'I-LANGUAGE', 'S-LAW', 'S-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'E-ORDINAL', '<START>', '<STOP>', \"[CLS]\", \"[SEP]\"]\n",
    "num_labels = len(ner_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train_data = config.data_path + '**/*-train.txt'\n",
    "filepath_validation_data = config.data_path + '**/*-dev.txt'\n",
    "filepath_test_data = config.data_path + '**/*-test.txt'\n",
    "\n",
    "filepath_train_syntrees = config.data_path + '**/*-train.syntree'\n",
    "filepath_validation_syntrees = config.data_path + '**/*-dev.syntree'\n",
    "filepath_test_syntrees = config.data_path + '**/*-test.syntree'\n",
    "\n",
    "filepath_train_ner_labels = config.data_path + '**/*-train-orig.ner'\n",
    "filepath_validation_ner_labels = config.data_path + '**/*-dev-orig.ner'\n",
    "filepath_test_ner_labels = config.data_path + '**/*-test-orig.ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForNer(BertForTokenClassification):\n",
    "    \"\"\"\n",
    "    Adapted from Huggingface BertForTokenClassification\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,valid_ids=None,attention_mask_label=None):\n",
    "        \n",
    "        # Calculate new embeddings\n",
    "        sequence_output = self.bert(input_ids, token_type_ids, attention_mask,head_mask=None)[0]\n",
    "        batch_size,max_len,feat_dim = sequence_output.shape\n",
    "\n",
    "        # Initialize valid output\n",
    "        valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32)\n",
    "        # Calculate new sequence output: ignore non-valid tokens, e.g. subtokens of words\n",
    "        for batch_idx in range(batch_size):\n",
    "            valid_idx = -1\n",
    "            for token_idx in range(max_len):\n",
    "                    if valid_ids[batch_idx][token_idx].item() == 1:\n",
    "                        valid_idx += 1\n",
    "                        valid_output[batch_idx][valid_idx] = sequence_output[batch_idx][token_idx]\n",
    "        sequence_output = self.dropout(valid_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=0)\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask_label is not None:\n",
    "                active_loss = attention_mask_label.view(-1) == 1\n",
    "                active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                active_labels = labels.view(-1)[active_loss]\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    SynGNN Pytorch module\n",
    "    based on Pytorch TransformerEncoderLayer implementing the architecture in paper “Attention Is All You Need”. \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in, dim_hdn, dim_out, num_heads, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        :param dim_in: input dimension\n",
    "        :param dim_hdn: hidden nodes dimension\n",
    "        :param dim_out: output dimension\n",
    "        \"\"\"\n",
    "        super(nn.TransformerEncoderLayer, self).__init__()\n",
    "        # Graph attention sublayer\n",
    "        self.graph_attn = tg_nn.GATv2Conv(dim_in, dim_hdn , heads=num_heads)\n",
    "        self.linear1 = nn.Linear(dim_hdn, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, dim_out)\n",
    "        self.norm0 = tg_nn.LayerNorm(dim_in)\n",
    "        self.norm1 = nn.LayerNorm(dim_hdn)\n",
    "        self.norm2 = nn.LayerNorm(dim_hdn)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "        \n",
    "        def __setstate__(self, state):\n",
    "            if 'activation' not in state:\n",
    "                state['activation'] = F.relu\n",
    "            super(nn.TransformerEncoderLayer, self).__setstate__(state)\n",
    "\n",
    "        def forward(self, x, edge_index, batch):\n",
    "            r\"\"\"Pass the input through the encoder layer.\n",
    "            Args:\n",
    "                x: node features\n",
    "                edge_index: graph edges\n",
    "                batch: current batch\n",
    "            \"\"\"\n",
    "            # Graph attention sublayer\n",
    "            x_norm = self.norm0(x, batch)\n",
    "            src2, att_weight = self.graph_attn(x_norm, edge_index)\n",
    "            src = src + self.dropout1(src2)\n",
    "            src = self.norm1(src)\n",
    "\n",
    "            # Feed-Forward-Network sublayer\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "            src = src + self.dropout2(src2)\n",
    "            src = self.norm2(src)\n",
    "            return src, att_weight\n",
    "        \n",
    "        def _get_activation_fn(activation):\n",
    "            if activation == \"relu\":\n",
    "                return F.relu\n",
    "            elif activation == \"gelu\":\n",
    "                return F.gelu\n",
    "\n",
    "            raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynBertForNer(BertForTokenClassification):\n",
    "      def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        # self.syngnn = SynGNN()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "      def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,valid_ids=None,attention_mask_label=None):\n",
    "         sequence_output = self.bert(input_ids, token_type_ids, attention_mask,head_mask=None)[0]\n",
    "         batch_size,max_len,feat_dim = sequence_output.shape\n",
    "         valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32)\n",
    "         # Calculate sequence output: ignore non-valid tokens, e.g. subtokens of words\n",
    "         for batch_idx in range(batch_size):\n",
    "            valid_idx = -1\n",
    "            for token_idx in range(max_len):\n",
    "                     if valid_ids[batch_idx][token_idx].item() == 1:\n",
    "                        valid_idx += 1\n",
    "                        valid_output[batch_idx][valid_idx] = sequence_output[batch_idx][token_idx]\n",
    "\n",
    "         # Pipe Bert embeddings into syntactic GAN\n",
    "\n",
    "         sequence_output = self.dropout(valid_output)\n",
    "         logits = self.classifier(sequence_output)\n",
    "\n",
    "         if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=0)\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask_label is not None:\n",
    "                  active_loss = attention_mask_label.view(-1) == 1\n",
    "                  active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                  active_labels = labels.view(-1)[active_loss]\n",
    "                  loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                  loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "         else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.tokenizer)\n",
    "if(config.task == 'mlm'):\n",
    "    model = BertForMaskedLM.from_pretrained(config.saved_model_path)\n",
    "if(config.task == 'ner'):\n",
    "    BERTconfig = BertConfig.from_pretrained(config.saved_model_path, num_labels=num_labels, tokenizer = tokenizer)\n",
    "    model = BertForNer.from_pretrained(config.saved_model_path, from_tf = False, config = BERTconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device('cpu')\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, valid_ids=None, label_mask=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMaskedInputs(inputs):\n",
    "    \"\"\"\n",
    "    creates masked input embeddings and labels from tokenized text\n",
    "\n",
    "    :param inputs: tokenized text\n",
    "    :return: masked input embeddings and new column labels \n",
    "    \"\"\" \n",
    "    # Clone input ids (tokens) to create labels\n",
    "    inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "    # create random array of floats with equal dimensions to input_ids tensor\n",
    "    rand = torch.rand(inputs.input_ids.shape)\n",
    "    # create mask array with 15% masked tokens\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "    # Select indices of each nonzero (= selected) value as token to be masked\n",
    "    selection = []\n",
    "\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        selection.append(\n",
    "            torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        )\n",
    "    # Mask selected tokens: replace with [MASK] code 103 in tensor\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNERInputFeatures(sentence_labels_list, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a list of sentences into a list of input features for the transformer\n",
    "    \n",
    "        :return: list of inpt features objects\n",
    "    \"\"\"\n",
    "\n",
    "    # Map NER labels to indices\n",
    "    # start with 1: 0 reserved for invalid labels e.g. subtoken labels\n",
    "    label_map = {label : i for i, label in enumerate(label_list,0)}\n",
    "    #label_map['X'] = 0\n",
    "\n",
    "    features = []\n",
    "    for (sentence_idx,sentence_label_pair) in enumerate(sentence_labels_list):\n",
    "    #     sentence = sentence.split(\" \")\n",
    "    #     labellist = labels[sentence_idx]\n",
    "        if sentence_idx < 2:\n",
    "            sentence_label_pair\n",
    "        # Tokenized text of sentence\n",
    "        tokens = []\n",
    "        # Token labels for sentence\n",
    "        labels = []\n",
    "        # Lists valid labels as 1 and labels to be ignored as 0 (e.g. for the labels for subword tokens which are not counting as separate labels for each token)\n",
    "        valid = []\n",
    "        # Mask for transformer indicating which tokens to ignore\n",
    "        label_mask = []\n",
    "        for word_label_pair in sentence_label_pair:\n",
    "            token = tokenizer.tokenize(word_label_pair[0])\n",
    "            tokens.extend(token)\n",
    "\n",
    "            label_word = word_label_pair[1]\n",
    "            for token_idx in range(len(token)):\n",
    "                # Append label for first token in word, mark as valid\n",
    "                if token_idx == 0:\n",
    "                    labels.append(label_word)\n",
    "                    valid.append(1)\n",
    "                    label_mask.append(1)\n",
    "                # Subword tokens: Mark as not valid\n",
    "                else:\n",
    "                    labels.append('X')\n",
    "                    valid.append(0)\n",
    "                    label_mask.append(1)\n",
    "        # Sentence exceeds max sequence length: cut to sequence length\n",
    "        if len(tokens) >= max_seq_length - 1:\n",
    "            tokens = tokens[0:(max_seq_length - 2)]\n",
    "            labels = labels[0:(max_seq_length - 2)]\n",
    "            valid = valid[0:(max_seq_length - 2)]\n",
    "            label_mask = label_mask[0:(max_seq_length - 2)]\n",
    "        # Tokens with BERT [CLS] and [SEP] tokens\n",
    "        ntokens = []\n",
    "        # Segment ids for BERT\n",
    "        segment_ids = []\n",
    "        # Label embedding ids for BERT\n",
    "        label_ids = []\n",
    "        # Start segment\n",
    "        ntokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(label_map[\"[CLS]\"])\n",
    "        # Mark as valid label\n",
    "        valid.insert(0,1)\n",
    "        label_mask.insert(0,1)\n",
    "\n",
    "        # add sentence tokens and label ids\n",
    "        for i, token in enumerate(tokens):\n",
    "            ntokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "            if len(labels) > i:\n",
    "                label_ids.append(label_map[labels[i]])\n",
    "        # End segment\n",
    "        ntokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "        valid.append(1)\n",
    "        label_mask.append(1)\n",
    "        label_ids.append(label_map[\"[SEP]\"])\n",
    "\n",
    "        # Convert tokens to ids\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Pad sentence to sequence length\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "            label_ids.append(0)\n",
    "            valid.append(1)\n",
    "            label_mask.append(0)\n",
    "\n",
    "        # Pad labels to sequence length\n",
    "        while len(label_ids) < max_seq_length:\n",
    "            label_ids.append(0)\n",
    "            label_mask.append(0)\n",
    "        \n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "        assert len(valid) == max_seq_length\n",
    "        assert len(label_mask) == max_seq_length\n",
    "        \n",
    "\n",
    "        features.append(\n",
    "        InputFeatures(input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        valid_ids=valid,\n",
    "                        label_mask=label_mask))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntransDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ud_tokenizer(tokenizer, tokenizer_name):\n",
    "    tokenizer_path = \"./tokenizers/\" + tokenizer_name \n",
    "    special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "    ]\n",
    "    # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "    vocab_size = 30_522\n",
    "    # Load data\n",
    "    text = []\n",
    "    for ud_file in glob.iglob(config.data_path + '**/UD_English-Pronouns/en_*.txt', recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        tokenizer.train(files=ud_file, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "    # make the directory if not already there\n",
    "    if not os.path.isdir(tokenizer_path):\n",
    "        os.mkdir(tokenizer_path)\n",
    "    # save the tokenizer  \n",
    "    tokenizer.save_model(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSentencesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentences\n",
    "    \"\"\" \n",
    "    sentences = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            sentences.extend(fp.read().split('\\n'))\n",
    "    return sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNERLabelsFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of NER labels per sentence\n",
    "    \"\"\" \n",
    "    all_token_label_pairs = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            # Split labels file by sentences\n",
    "            sentences = (fp.read().split('\\n'))\n",
    "        # Split sentences by tokens\n",
    "        token_labels = [x.split(\"\\t\") for x in sentences]\n",
    "        # Remove empty line at end of sentence\n",
    "        [x.remove('') for x in token_labels] \n",
    "        # Split token and NER tags\n",
    "        token_labels = [list(map(lambda x:x.split(\" \") ,tag_token)) for tag_token in token_labels]\n",
    "        all_token_label_pairs.extend(token_labels)\n",
    "\n",
    "    return all_token_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSyntaxTreesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load binary syntax tree files (*.syntree).\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentence syntax trees\n",
    "    \"\"\" \n",
    "    all_syntrees = []\n",
    "    for syntree_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        syntree_file = os.path.abspath(syntree_file)\n",
    "        filename = os.path.basename(syntree_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(syntree_file, 'rb') as fp:\n",
    "            all_syntrees.append(pd.read_pickle(fp))\n",
    "    return all_syntrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_syntrees = loadSyntaxTreesFromFiles(filepath_test_syntrees)\n",
    "#print(all_syntrees[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_syntrees = loadSyntaxTreesFromFiles(filepath_test_syntrees)\n",
    "# print(all_syntrees[0][0:2])\n",
    "\n",
    "# syntree_train_loader = tg_data.DataLoader(all_syntrees[0], batch_size=config.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Print example of tokenized text\n",
    "sentences = []\n",
    "for ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\n",
    "\n",
    "    ud_file = os.path.abspath(ud_file)\n",
    "    filename = os.path.basename(ud_file)\n",
    "    print(filename, flush = True)\n",
    "    with open(ud_file, 'r') as fp:\n",
    "        sentences.extend(fp.read().split('\\n'))\n",
    "count = 0\n",
    "for sentence in sentences:\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs = createMaskedInputs(inputs)\n",
    "\n",
    "    # Create dataset from tokenized data\n",
    "    dataset = SyntransDataset(inputs)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    if(count==1):\n",
    "        print(inputs['input_ids'])\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        print(tokens)\n",
    "        print(inputs['labels'])\n",
    "        break\n",
    "    count=count+1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxSequenceLength(sentences, cutoff_limit_percent=0.9999):\n",
    "    \"\"\"\n",
    "    Calculate maximum sequence length for given data.\n",
    "    param sentences: list of sentences\n",
    "    param cutoff_limit_percent: percentage of all samples to accommodate with the max sequence length.\n",
    "    returns: max sequence length which encompasses cutoff_limit_percent of all data samples\n",
    "    \"\"\"\n",
    "    # Get number of tokens per sentence        \n",
    "    max_sentence_tokens = 0\n",
    "    sentence_tokens = {}\n",
    "    print(f\"Amount of samples: {len(sentences)}\")\n",
    "    # Tokenize data\n",
    "    for sentence in sentences:\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors='pt')\n",
    "        \n",
    "        token_count = inputs.input_ids.size(dim=1)\n",
    "        sentence_tokens[inputs.input_ids.size(dim=1)] = sentence_tokens.get(token_count,0) + 1\n",
    "        if(token_count > max_sentence_tokens): \n",
    "            max_sentence_tokens = token_count\n",
    "            \n",
    "    no_tokens = 0\n",
    "    # Calulate number of samples which should have a sequence length smaller than max_sequence_length\n",
    "    cutoff = cutoff_limit_percent * len(sentences)\n",
    "    max_sequence_length = 0\n",
    "    print(max_sentence_tokens)\n",
    "    for i in sorted(sentence_tokens):\n",
    "        # print((i, sentence_tokens[i]), end=\" \")\n",
    "        if(no_tokens <= cutoff):\n",
    "            no_tokens = no_tokens + sentence_tokens[i]\n",
    "            max_sequence_length = i\n",
    "\n",
    "    print(f\"Max sequence length: {max_sequence_length} with {cutoff_limit_percent}% of samples smaller\")\n",
    "    return max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = loadSentencesFromFiles(config.data_path + '**/en_*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getMaxSequenceLength(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataloader(filepath, shuffle_data=False):\n",
    "\n",
    "        # Load NER labels\n",
    "        if(config.task == 'ner'):\n",
    "            print(filepath)\n",
    "\n",
    "            sentence_labels_list = loadNERLabelsFromFiles(filepath)\n",
    "            num_sentences = len(sentence_labels_list)\n",
    "            num_batches = math.ceil(num_sentences / config.batch_size)\n",
    "            print(f\"{num_sentences} sentences, {num_batches} batches of size {config.batch_size}\")\n",
    "            print(sentence_labels_list[0:2])\n",
    "\n",
    "            sentence_labels_list = sentence_labels_list[0:config.num_sentences]\n",
    "            features = createNERInputFeatures(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer)\n",
    "            all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "            all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "            all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "            all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "            all_valid_ids = torch.tensor([f.valid_ids for f in features], dtype=torch.long)\n",
    "            all_lmask_ids = torch.tensor([f.label_mask for f in features], dtype=torch.long)\n",
    "            data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids)\n",
    "            print(data.__sizeof__())\n",
    "            # Print control example of InputFeatures\n",
    "            print(\"Control example of InputFeatures\")\n",
    "            print(str(features[1].input_ids))\n",
    "            print(str(features[1].input_mask))\n",
    "            print(str(features[1].label_ids))\n",
    "            print(str(features[1].valid_ids))\n",
    "            print(str(features[1].label_mask))\n",
    "            print(str(features[1].segment_ids))\n",
    "\n",
    "\n",
    "        if(config.task == 'mlm'):\n",
    "            # Load data\n",
    "            sentences = loadSentencesFromFiles(filepath)\n",
    "            # Tokenize data\n",
    "            inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "            inputs = createMaskedInputs(inputs)\n",
    "\n",
    "            # Create dataset from tokenized data\n",
    "            data = SyntransDataset(inputs)\n",
    "        \n",
    "        loader = DataLoader(data, batch_size=config.batch_size, shuffle=shuffle_data)\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainData():\n",
    "    print(\"Loading Training Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        return createDataloader(filepath_train_ner_labels, shuffle_data=True)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_train_data, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadValidationData():\n",
    "    print(\"Loading Validation Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        return createDataloader(filepath_validation_ner_labels)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestData():\n",
    "    print(\"Test Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        return createDataloader(filepath_test_ner_labels)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(epoch, trainLoader, writer):\n",
    "    # activate training mode\n",
    "    model.train()\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "    # initialize optimizer\n",
    "    optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    epoch_loss = 0\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(trainLoader, leave=True, mininterval=40,maxinterval=120)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        if (config.task == 'ner'):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "            batch_loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "            batch_loss = loss.item()\n",
    "        if (config.task == 'mlm'):\n",
    "            # pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            # process\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            # extract loss\n",
    "            loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Train Epoch {epoch}')\n",
    "        loop.set_postfix(loss=batch_loss)\n",
    "        epoch_loss = epoch_loss + batch_loss\n",
    "    # Calculate epoch loss\n",
    "    epoch_loss = epoch_loss / len(trainLoader)\n",
    "    # Print info to Tensorboard\n",
    "    writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "    return epoch_loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateModel(epoch, validationLoader, writer):\n",
    "    # activate eval mode\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    # setup loop with TQDM and dataloader\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(validationLoader, leave=True, mininterval=40,maxinterval=120)\n",
    "        for batch in loop:\n",
    "            # pull all tensor batches required for training\n",
    "            if (config.task == 'ner'):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "                batch_loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "                batch_loss = batch_loss.item()\n",
    "            if (config.task == 'mlm'):\n",
    "                # pull all tensor batches required for training\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                # process\n",
    "                batch_loss, logits = model(input_ids, attention_mask=attention_mask,\n",
    "                                labels=labels)\n",
    "                batch_loss = batch_loss.item()\n",
    "\n",
    "            # print relevant info to progress bar\n",
    "            loop.set_description(f'Validation Epoch {epoch}')\n",
    "\n",
    "            loop.set_postfix(loss=batch_loss)\n",
    "            epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(validationLoader)\n",
    "            #print(epoch_loss)\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "            return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stderr\n",
    "\n",
    "\n",
    "def evaluateModel(data_loader, mode=None, writer = None, results_dir = None,  epoch = None):\n",
    "    if(mode == 'Train'):\n",
    "        model.train()\n",
    "        from torch.optim import AdamW\n",
    "        # initialize optimizer\n",
    "        optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    elif(mode == 'Test' or mode == 'Validation'):\n",
    "        model.eval()\n",
    "    else:\n",
    "        stderr(\"Mode must be Train, Validation or Test\")\n",
    "        exit()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    label_map = {i : label for i, label in enumerate(ner_tags_list,0)}\n",
    "\n",
    "    references_all = []\n",
    "    predictions_all = []\n",
    "    references_roc_all = []\n",
    "    predictions_roc_all = []\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        # Setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        for batch in loop:\n",
    "    \n",
    "            # Pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).tolist()\n",
    "\n",
    "            softmax = nn.Softmax(dim = -1)\n",
    "            if (mode == 'Test' or mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(input_ids)\n",
    "            if(mode == 'Train'):\n",
    "                # initialize calculated gradients (from prev step)\n",
    "                optim.zero_grad()\n",
    "                predictions = model(input_ids)\n",
    "            predictions = predictions['logits']\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Change type to double to prevent floating point rounding errors\n",
    "            predictions = predictions.type(torch.float64)\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Get index of argmax\n",
    "            #y = np.argmax(predictions_sm, axis = -1)\n",
    "            # y = y.tolist()\n",
    "            y = torch.topk(predictions, k=1, dim = 2)[1].squeeze()\n",
    "            y = y.tolist()\n",
    "                \n",
    "\n",
    "            recall_metric = evaluate.load('recall')\n",
    "            precision_metric = evaluate.load('precision')\n",
    "            f1_metric = evaluate.load('f1')\n",
    "            roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "\n",
    "            # Go through all samples in batch and add to computation batch\n",
    "            for idx, pred_batch in enumerate(y):\n",
    "                references_all.extend(labels[idx])\n",
    "                predictions_all.extend(pred_batch)\n",
    "                #precision_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "                #recall_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "                #f1_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "            \n",
    "            # Calculate ROC\n",
    "            for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "                predictions_roc_all.extend(pred_batch.tolist())\n",
    "                references_roc_all.extend(labels[batch_idx])\n",
    "                #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "                break\n",
    "            break\n",
    "\n",
    "        numberOfBatches = len(loop)\n",
    "        # List all possible labels\n",
    "        labels = np.arange(tokenizer.vocab_size)\n",
    "        with open(f\"./logs/Results_{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}.txt\", \"w\") as output:\n",
    "            print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "            output.write(\"macro averaging\\n\")\n",
    "            output.write(str(recall_metric.compute(references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute(references = references_all, predictions = predictions_all, average = 'macro', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(\"weighted averaging\\n\")\n",
    "            output.write(str(recall_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.close()\n",
    "    \n",
    "    if (config.task == 'ner'):\n",
    "\n",
    "        sep_token_id = int(ner_tags_list.index(\"[SEP]\"))\n",
    "        cls_token_id = int(ner_tags_list.index(\"[CLS]\"))\n",
    "        unk_token_id = int(ner_tags_list.index(\"<unk>\"))\n",
    "        O_token_id = int(ner_tags_list.index(\"O\"))\n",
    "\n",
    "        special_token_predictions = 0\n",
    "        O_token_predictions = 0\n",
    "        epoch_loss = 0\n",
    "        # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        # Loop over all batches\n",
    "        for batch in loop:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "\n",
    "            if(mode == 'Train'):\n",
    "                # initialize calculated gradients (from prev step)\n",
    "                optim.zero_grad()\n",
    "                loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "                # calculate loss for every parameter that needs grad update\n",
    "                loss.backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                # update parameters\n",
    "                optim.step()\n",
    "            elif(mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "            elif(mode == 'Test'):\n",
    "                logits = model(input_ids, segment_ids, input_mask,valid_ids=valid_ids,attention_mask_label=l_mask)\n",
    "\n",
    "            if(mode == 'Validation' or mode == 'Train'):\n",
    "                # print relevant info to progress bar\n",
    "                loop.set_description(f'{mode} Epoch {epoch}')\n",
    "                batch_loss = loss.item()\n",
    "                loop.set_postfix(loss=batch_loss)\n",
    "                epoch_loss = epoch_loss + batch_loss\n",
    "            \n",
    "            softmax = nn.Softmax(dim=2)\n",
    "\n",
    "            # Get highest NER label prediction for all sentences\n",
    "            logits = torch.argmax(softmax(logits),dim=2)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            input_mask = input_mask.to('cpu').numpy()\n",
    "\n",
    "            # Go through true labels\n",
    "            for label_list_idx, true_sentence_labels in enumerate(label_ids):\n",
    "                y_true_temp = []\n",
    "                y_pred_temp = []\n",
    "\n",
    "                for label_idx, label_id in enumerate(true_sentence_labels):\n",
    "\n",
    "                    # Skip 0 label\n",
    "                    if label_id == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip [CLS] label at sequence beginning\n",
    "                    if label_id == cls_token_id:\n",
    "                        continue\n",
    "\n",
    "                    # Detect [SEP] label at sentence end and ignore [SEP] and all sequence padding\n",
    "                    elif label_id == sep_token_id:\n",
    "                        y_true.append(y_true_temp)\n",
    "                        y_pred.append(y_pred_temp)\n",
    "                        break\n",
    "                    else:\n",
    "                        # Predicted NER label is special token: count preds\n",
    "                        if (logits[label_list_idx][label_idx] == 0):\n",
    "                            special_token_predictions = special_token_predictions +1\n",
    "                        # Predicted NER label is O: count preds\n",
    "                        elif (logits[label_list_idx][label_idx] == O_token_id):\n",
    "                            O_token_predictions = O_token_predictions +1\n",
    "\n",
    "                        # Append label and prediction to list\n",
    "                        y_true_temp.append(label_map[label_id])\n",
    "                        y_pred_temp.append(label_map[logits[label_list_idx][label_idx]])\n",
    "\n",
    "        if (mode == 'Train' or mode == 'Validation'):\n",
    "            print(f\"True: {y_true[0:1]}, Predicted: {y_pred[0:1]}\")\n",
    "            report = classification_report(y_true, y_pred, digits=6, output_dict=True, zero_division = 0)\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(data_loader)\n",
    "\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "            macro_precision = report['macro avg']['precision']\n",
    "            writer.add_scalar(\"macro_avg/precision\", macro_precision, epoch)\n",
    "            macro_recall = report['macro avg']['recall']\n",
    "            writer.add_scalar(\"macro_avg/recall\", macro_recall, epoch)\n",
    "            macro_f1 = report['macro avg']['f1-score']\n",
    "            writer.add_scalar(\"macro_avg/f1\", macro_f1, epoch)\n",
    "\n",
    "            weighted_precision = report['weighted avg']['precision']\n",
    "            writer.add_scalar(\"weighted_avg/precision\", weighted_precision, epoch)\n",
    "            weighted_recall = report['weighted avg']['recall']\n",
    "            writer.add_scalar(\"weighted_avg/recall\", weighted_recall, epoch)\n",
    "            weighted_f1 = report['weighted avg']['f1-score']\n",
    "            writer.add_scalar(\"weighted_avg/f1\", weighted_f1, epoch)\n",
    "            print(f\"O Token Predictions: {O_token_predictions}\")\n",
    "            print(f\"loss: {epoch_loss} w prec: {weighted_precision} w recall: {weighted_recall} w f1: {weighted_f1}\")\n",
    "            return epoch_loss, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1\n",
    "\n",
    "        else:\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=False)\n",
    "            with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "                print(\"***** Test results *****\")\n",
    "                print(f\"Task: {config.task}\")\n",
    "                print(f\"Model path: {config.saved_model_path}\")\n",
    "                print(f\"Data path: {config.data_path}\")\n",
    "                print(f\"Tokenizer: {config.tokenizer}\")\n",
    "                print(f\"Batch size: {config.batch_size}\")\n",
    "                print(f\"Epochs: {config.epochs}\")\n",
    "                print(f\"Learning rate: {config.learning_rate}\")\n",
    "                print(f\"Sequence length: {config.sequence_length}\")\n",
    "                print(f\"Training: {config.train_model}\")\n",
    "                print(f\"Num Threads: {config.num_threads}\")\n",
    "                print(f\"Num Sentences: {config.num_sentences}\")\n",
    "                print(f\"{report}\\n Special token predictions: {special_token_predictions}\")\n",
    "                output.write(report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_idx = 0\n",
    "# Tensorboard logging\n",
    "tensorboard_dir = f\"./runs/{config.task}/{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\"\n",
    "while(os.path.exists(tensorboard_dir+f\"_{log_idx}\")):\n",
    "    # Check is dir is not empty\n",
    "    if(os.listdir(tensorboard_dir+f\"_{log_idx}\") and log_idx <30):\n",
    "        log_idx = log_idx+1\n",
    "    else:\n",
    "        break\n",
    "tensorboard_dir = tensorboard_dir+f\"_{log_idx}/\"\n",
    "#_dir = f\"./runs/{config.task}/{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_{log_idx}/\"\n",
    "if not os.path.isdir(tensorboard_dir):\n",
    "    os.makedirs(tensorboard_dir)\n",
    "\n",
    "results_dir = f\"./logs/{config.task}/Results/{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\"\n",
    "while(os.path.exists(results_dir+f\"_{log_idx}\")):\n",
    "    # Check if directory is empty\n",
    "    if( os.listdir(results_dir+f\"_{log_idx}\") and log_idx <30):\n",
    "        log_idx = log_idx+1\n",
    "    else:\n",
    "        break\n",
    "results_dir = results_dir+f\"_{log_idx}/\"\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (config.train_model):\n",
    "    print(\"Training model\", flush=True)\n",
    "\n",
    "    trainLoader = loadTrainData()\n",
    "    validationLoader = loadValidationData()\n",
    "\n",
    "    epochs = config.epochs\n",
    "\n",
    "    train_writer = SummaryWriter(log_dir=tensorboard_dir+\"training\")\n",
    "    validation_writer = SummaryWriter(log_dir=tensorboard_dir+\"validation\")\n",
    "\n",
    "    epoch_losses_train = []\n",
    "    macro_precisions_train = []\n",
    "    macro_recalls_train = []\n",
    "    macro_f1s_train = []\n",
    "    weighted_precisions_train = []\n",
    "    weighted_recalls_train = []\n",
    "    weighted_f1s_train = []\n",
    "\n",
    "    epoch_losses_validation = []\n",
    "    macro_precisions_val = []\n",
    "    macro_recalls_val = []\n",
    "    macro_f1s_val = []\n",
    "    weighted_precisions_val = []\n",
    "    weighted_recalls_val = []\n",
    "    weighted_f1s_val = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #epoch_losses_train.append(trainModel(epoch, trainLoader, train_writer))\n",
    "        #epoch_losses_validation.append(validateModel(epoch, validationLoader, validation_writer))\n",
    "\n",
    "        epoch_loss_train, macro_precision_train, macro_recall_train, macro_f1_train, weighted_precision_train, weighted_recall_train, weighted_f1_train = evaluateModel(trainLoader, mode = 'Train', writer = train_writer, results_dir = results_dir, epoch=epoch)\n",
    "        epoch_losses_train.append(epoch_loss_train)\n",
    "        macro_precisions_train.append(macro_precision_train)\n",
    "        macro_recalls_train.append(macro_recall_train)\n",
    "        macro_f1s_train.append(macro_f1_train)\n",
    "\n",
    "        weighted_precisions_train.append(weighted_precision_train)\n",
    "        weighted_recalls_train.append(weighted_recall_train)\n",
    "        weighted_f1s_train.append(weighted_f1_train)\n",
    "\n",
    "        epoch_loss_val, macro_precision_val, macro_recall_val, macro_f1_val, weighted_precision_val, weighted_recall_val, weighted_f1_val = evaluateModel(validationLoader, mode = 'Validation', writer = validation_writer, results_dir = results_dir, epoch=epoch)\n",
    "        epoch_losses_validation.append(epoch_loss_val)\n",
    "        macro_precisions_val.append(macro_precision_val)\n",
    "        macro_recalls_val.append(macro_recall_val)\n",
    "        macro_f1s_val.append(macro_f1_val)\n",
    "\n",
    "        weighted_precisions_val.append(weighted_precision_val)\n",
    "        weighted_recalls_val.append(weighted_recall_val)\n",
    "        weighted_f1s_val.append(weighted_f1_val)\n",
    "\n",
    "\n",
    "        if (activeMode == 'prod'):\n",
    "            # Save model after each epoch\n",
    "            model.save_pretrained(save_directory=f\"./trained_models/{config.task}/{config.tokenizer}_E{epoch}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}/\")\n",
    "    \n",
    "    train_writer.close()\n",
    "    validation_writer.close()\n",
    "    # Save epoch loss plots\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), epoch_losses_train, 'b', label='Training loss')\n",
    "    plt.plot(range(0,epochs), epoch_losses_validation, 'g', label='Validation loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/loss.png\", facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), macro_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), macro_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), weighted_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), weighted_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    #  # Save weighted precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Precison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_macro.png\", facecolor='white', transparent=False)\n",
    "    #plt.show()\n",
    "\n",
    "    # print(str(features[1].input_ids))\n",
    "    # print(str(features[1].input_mask))\n",
    "    # print(str(features[1].label_ids))\n",
    "    # print(str(features[1].valid_ids))\n",
    "    # print(str(features[1].label_mask))\n",
    "    # print(str(features[1].segment_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model evaluation\\n\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = loadTestData()\n",
    "evaluateModel(test_loader, mode = 'Test', results_dir=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(references_all, predictions_all, labels=labels)\n",
    "#print(confusion_matrix)\n",
    "#disp = metrics.ConfusionMatrixDisplay(references_all, predictions_all, labels=labels)\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# precision recall curve\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in labels:\n",
    "    precision[i], recall[i], _ = precision_recall_curve(references_roc_all[i],\n",
    "                                                        predictions_roc_all[i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "    break\n",
    "    \n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_syntrans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86a731642ee256d624a4d29e8688bb9c6ad7b39856affb444c6cc9f38126795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
