{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Export env vars to limit number of threads to use\n",
    "num_threads = \"4\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = num_threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = num_threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = num_threads\n",
    "\n",
    "# Only use CPU, hide GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForTokenClassification, BertConfig, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Import SummaryWriter for Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "# Load Pytorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.data as tg_data\n",
    "import torch_geometric.utils as tg_utils\n",
    "import torch_geometric.nn as tg_nn\n",
    "import evaluate\n",
    "# Evaluation metrics for NER task\n",
    "from seqeval.metrics import classification_report\n",
    "# Support for IOBES style NER labels\n",
    "from seqeval.scheme import IOBES\n",
    "import numpy as np\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "# Easy file reading\n",
    "import glob\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/home/shrdlu/cdaniel/syntrans/utilities.py'>"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utilities as utils\n",
    "# Reload library if changed\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit no. of threads used by Pytorch\n",
    "torch.set_num_threads = int(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 263, PGID: 149\n"
     ]
    }
   ],
   "source": [
    "PID = os.getpid()\n",
    "PGID = os.getpgid(PID)\n",
    "print(f\"PID: {PID}, PGID: {PGID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f30c324e070>"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "activeMode= \"develop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: ner\n",
      "Model path: bert-base-uncased\n",
      "Data path: ./data/ud/UD_English-GUM/\n",
      "Tokenizer: bert-base-uncased\n",
      "Batch size: 2\n",
      "Epochs: 1\n",
      "Learning rate: 5e-05\n",
      "Sequence length: 136\n",
      "Training: False\n"
     ]
    }
   ],
   "source": [
    "configuration_csv = pd.read_csv(f\"./config/{activeMode}.csv\", dtype=str, sep=\";\")\n",
    "config = utils.configureParameters(configuration_csv)\n",
    "print(f\"Task: {config.task}\")\n",
    "print(f\"Model path: {config.saved_model_path}\")\n",
    "print(f\"Data path: {config.data_path}\")\n",
    "print(f\"Tokenizer: {config.tokenizer}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"Sequence length: {config.sequence_length}\")\n",
    "print(f\"Training: {config.train_model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_list = ['O','<unk>', 'B-CARDINAL', 'E-CARDINAL', 'S-PERSON', 'S-CARDINAL', 'S-PRODUCT', 'B-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'E-WORK_OF_ART', 'B-PERSON', 'E-PERSON', 'S-GPE', 'B-DATE', 'I-DATE', 'E-DATE', 'S-ORDINAL', 'S-LANGUAGE', 'I-PERSON', 'S-EVENT', 'S-DATE', 'B-QUANTITY', 'E-QUANTITY', 'S-TIME', 'B-TIME', 'I-TIME', 'E-TIME', 'B-GPE', 'E-GPE', 'S-ORG', 'I-GPE', 'S-NORP', 'B-FAC', 'I-FAC', 'E-FAC', 'B-NORP', 'E-NORP', 'S-PERCENT', 'B-ORG', 'E-ORG', 'B-LANGUAGE', 'E-LANGUAGE', 'I-CARDINAL', 'I-ORG', 'S-WORK_OF_ART', 'I-QUANTITY', 'B-MONEY', 'I-MONEY', 'E-MONEY', 'B-LOC', 'E-LOC', 'I-LOC', 'B-PERCENT', 'I-PERCENT', 'E-PERCENT', 'S-LOC', 'S-FAC', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'S-MONEY', 'B-LAW', 'I-LAW', 'E-LAW', 'I-NORP', 'I-LANGUAGE', 'S-LAW', 'S-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'E-ORDINAL', '<START>', '<STOP>', \"[CLS]\", \"[SEP]\"]\n",
    "num_labels = len(ner_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForNer(BertForTokenClassification):\n",
    "    \"\"\"\n",
    "    Adapted from Huggingface BertForTokenClassification\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,valid_ids=None,attention_mask_label=None):\n",
    "        \n",
    "        # Calculate new embeddings\n",
    "        sequence_output = self.bert(input_ids, token_type_ids, attention_mask,head_mask=None)[0]\n",
    "        batch_size,max_len,feat_dim = sequence_output.shape\n",
    "\n",
    "        # Initialize valid output\n",
    "        valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32)\n",
    "        # Calculate new sequence output: ignore non-valid tokens, e.g. subtokens of words\n",
    "        for batch_idx in range(batch_size):\n",
    "            valid_idx = -1\n",
    "            for token_idx in range(max_len):\n",
    "                    if valid_ids[batch_idx][token_idx].item() == 1:\n",
    "                        valid_idx += 1\n",
    "                        valid_output[batch_idx][valid_idx] = sequence_output[batch_idx][token_idx]\n",
    "        sequence_output = self.dropout(valid_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=0)\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask_label is not None:\n",
    "                active_loss = attention_mask_label.view(-1) == 1\n",
    "                active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                active_labels = labels.view(-1)[active_loss]\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    SynGNN Pytorch module\n",
    "    based on Pytorch TransformerEncoderLayer implementing the architecture in paper “Attention Is All You Need”. \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in, dim_hdn, dim_out, num_heads, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        :param dim_in: input dimension\n",
    "        :param dim_hdn: hidden nodes dimension\n",
    "        :param dim_out: output dimension\n",
    "        \"\"\"\n",
    "        super(nn.TransformerEncoderLayer, self).__init__()\n",
    "        # Graph attention sublayer\n",
    "        self.graph_attn = tg_nn.GATv2Conv(dim_in, dim_hdn , heads=num_heads)\n",
    "        self.linear1 = nn.Linear(dim_hdn, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, dim_out)\n",
    "        self.norm0 = tg_nn.LayerNorm(dim_in)\n",
    "        self.norm1 = nn.LayerNorm(dim_hdn)\n",
    "        self.norm2 = nn.LayerNorm(dim_hdn)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "        \n",
    "        def __setstate__(self, state):\n",
    "            if 'activation' not in state:\n",
    "                state['activation'] = F.relu\n",
    "            super(nn.TransformerEncoderLayer, self).__setstate__(state)\n",
    "\n",
    "        def forward(self, x, edge_index, batch):\n",
    "            r\"\"\"Pass the input through the encoder layer.\n",
    "            Args:\n",
    "                x: node features\n",
    "                edge_index: graph edges\n",
    "                batch: current batch\n",
    "            \"\"\"\n",
    "            # Graph attention sublayer\n",
    "            x_norm = self.norm0(x, batch)\n",
    "            src2, att_weight = self.graph_attn(x_norm, edge_index)\n",
    "            src = src + self.dropout1(src2)\n",
    "            src = self.norm1(src)\n",
    "\n",
    "            # Feed-Forward-Network sublayer\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "            src = src + self.dropout2(src2)\n",
    "            src = self.norm2(src)\n",
    "            return src, att_weight\n",
    "        \n",
    "        def _get_activation_fn(activation):\n",
    "            if activation == \"relu\":\n",
    "                return F.relu\n",
    "            elif activation == \"gelu\":\n",
    "                return F.gelu\n",
    "\n",
    "            raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynBertForNer(BertForTokenClassification):\n",
    "      def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        # self.syngnn = SynGNN()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "      def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,valid_ids=None,attention_mask_label=None):\n",
    "         sequence_output = self.bert(input_ids, token_type_ids, attention_mask,head_mask=None)[0]\n",
    "         batch_size,max_len,feat_dim = sequence_output.shape\n",
    "         valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32)\n",
    "         # Calculate sequence output: ignore non-valid tokens, e.g. subtokens of words\n",
    "         for batch_idx in range(batch_size):\n",
    "            valid_idx = -1\n",
    "            for token_idx in range(max_len):\n",
    "                     if valid_ids[batch_idx][token_idx].item() == 1:\n",
    "                        valid_idx += 1\n",
    "                        valid_output[batch_idx][valid_idx] = sequence_output[batch_idx][token_idx]\n",
    "\n",
    "         # Pipe Bert embeddings into syntactic GAN\n",
    "\n",
    "         sequence_output = self.dropout(valid_output)\n",
    "         logits = self.classifier(sequence_output)\n",
    "\n",
    "         if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=0)\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask_label is not None:\n",
    "                  active_loss = attention_mask_label.view(-1) == 1\n",
    "                  active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                  active_labels = labels.view(-1)[active_loss]\n",
    "                  loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                  loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "         else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNer: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForNer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForNer were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.tokenizer)\n",
    "if(config.task == 'mlm'):\n",
    "    model = BertForMaskedLM.from_pretrained(config.saved_model_path)\n",
    "if(config.task == 'ner'):\n",
    "    BERTconfig = BertConfig.from_pretrained(config.saved_model_path, num_labels=num_labels, tokenizer = tokenizer)\n",
    "    model = BertForNer.from_pretrained(config.saved_model_path, from_tf = False, config = BERTconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNer(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=78, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cpu')\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train_data = config.data_path + '**/*-train.txt'\n",
    "filepath_test_data = config.data_path + '**/*-test.txt'\n",
    "filepath_train_syntrees = config.data_path + '**/*-train.syntree'\n",
    "filepath_test_syntrees = config.data_path + '**/*-test.syntree'\n",
    "filepath_train_ner_labels = config.data_path + '**/*-train-orig.ner'\n",
    "filepath_test_ner_labels = config.data_path + '**/*-test-orig.ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, valid_ids=None, label_mask=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMaskedInputs(inputs):\n",
    "    \"\"\"\n",
    "    creates masked input embeddings and labels from tokenized text\n",
    "\n",
    "    :param inputs: tokenized text\n",
    "    :return: masked input embeddings and new column labels \n",
    "    \"\"\" \n",
    "    # Clone input ids (tokens) to create labels\n",
    "    inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "    # create random array of floats with equal dimensions to input_ids tensor\n",
    "    rand = torch.rand(inputs.input_ids.shape)\n",
    "    # create mask array with 15% masked tokens\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "    # Select indices of each nonzero (= selected) value as token to be masked\n",
    "    selection = []\n",
    "\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        selection.append(\n",
    "            torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        )\n",
    "    # Mask selected tokens: replace with [MASK] code 103 in tensor\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNERInputFeatures(sentence_labels_list, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a list of sentences into a list of input features for the transformer\n",
    "    \n",
    "        :return: list of inpt features objects\n",
    "    \"\"\"\n",
    "\n",
    "    # Map NER labels to indices\n",
    "    # start with 1: 0 reserved for invalid labels e.g. subtoken labels\n",
    "    label_map = {label : i for i, label in enumerate(label_list,1)}\n",
    "    label_map['X'] = 0\n",
    "\n",
    "    features = []\n",
    "    for (sentence_idx,sentence_label_pair) in enumerate(sentence_labels_list):\n",
    "    #     sentence = sentence.split(\" \")\n",
    "    #     labellist = labels[sentence_idx]\n",
    "        if sentence_idx < 2:\n",
    "            sentence_label_pair\n",
    "        # Tokenized text of sentence\n",
    "        tokens = []\n",
    "        # Token labels for sentence\n",
    "        labels = []\n",
    "        # Lists valid labels as 1 and labels to be ignored as 0 (e.g. for the labels for subword tokens which are not counting as separate labels for each token)\n",
    "        valid = []\n",
    "        # Mask for transformer indicating which tokens to ignore\n",
    "        label_mask = []\n",
    "        for word_label_pair in sentence_label_pair:\n",
    "            token = tokenizer.tokenize(word_label_pair[0])\n",
    "            tokens.extend(token)\n",
    "\n",
    "            label_word = word_label_pair[1]\n",
    "            for token_idx in range(len(token)):\n",
    "                # Append label for first token in word, mark as valid\n",
    "                if token_idx == 0:\n",
    "                    labels.append(label_word)\n",
    "                    valid.append(1)\n",
    "                    label_mask.append(1)\n",
    "                # Subword tokens: Mark as not valid\n",
    "                else:\n",
    "                    labels.append('X')\n",
    "                    valid.append(0)\n",
    "                    label_mask.append(1)\n",
    "        # Sentence exceeds max sequence length: cut to sequence length\n",
    "        if len(tokens) >= max_seq_length - 1:\n",
    "            tokens = tokens[0:(max_seq_length - 2)]\n",
    "            labels = labels[0:(max_seq_length - 2)]\n",
    "            valid = valid[0:(max_seq_length - 2)]\n",
    "            label_mask = label_mask[0:(max_seq_length - 2)]\n",
    "        # Tokens with BERT [CLS] and [SEP] tokens\n",
    "        ntokens = []\n",
    "        # Segment ids for BERT\n",
    "        segment_ids = []\n",
    "        # Label embedding ids for BERT\n",
    "        label_ids = []\n",
    "        # Start segment\n",
    "        ntokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(label_map[\"[CLS]\"])\n",
    "        # Mark as valid label\n",
    "        valid.insert(0,1)\n",
    "        label_mask.insert(0,1)\n",
    "\n",
    "        # add sentence tokens\n",
    "        for i, token in enumerate(tokens):\n",
    "            ntokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "            if len(labels) > i:\n",
    "                label_ids.append(label_map[labels[i]])\n",
    "        # End segment\n",
    "        ntokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "        valid.append(1)\n",
    "        label_mask.append(1)\n",
    "        label_ids.append(label_map[\"[SEP]\"])\n",
    "\n",
    "        # Convert tokens to ids\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Pad sentence to sequence length\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "            label_ids.append(0)\n",
    "            valid.append(1)\n",
    "            label_mask.append(0)\n",
    "        # Pad labels to sequence length\n",
    "        while len(label_ids) < max_seq_length:\n",
    "            label_ids.append(0)\n",
    "            label_mask.append(0)\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "        assert len(valid) == max_seq_length\n",
    "        assert len(label_mask) == max_seq_length\n",
    "        \n",
    "\n",
    "        features.append(\n",
    "        InputFeatures(input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        valid_ids=valid,\n",
    "                        label_mask=label_mask))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntransDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ud_tokenizer(tokenizer, tokenizer_name):\n",
    "    tokenizer_path = \"./tokenizers/\" + tokenizer_name \n",
    "    special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "    ]\n",
    "    # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "    vocab_size = 30_522\n",
    "    # Load data\n",
    "    text = []\n",
    "    for ud_file in glob.iglob(config.data_path + '**/UD_English-Pronouns/en_*.txt', recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        tokenizer.train(files=ud_file, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "    # make the directory if not already there\n",
    "    if not os.path.isdir(tokenizer_path):\n",
    "        os.mkdir(tokenizer_path)\n",
    "    # save the tokenizer  \n",
    "    tokenizer.save_model(tokenizer_path)\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSentencesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentences\n",
    "    \"\"\" \n",
    "    sentences = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            sentences.extend(fp.read().split('\\n'))\n",
    "    return sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNERLabelsFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of NER labels per sentence\n",
    "    \"\"\" \n",
    "    labels = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            # Split labels file by sentences\n",
    "            labels.extend(fp.read().split('\\n'))\n",
    "        # Split sentences by tokens\n",
    "        labels = [x.split(\"\\t\") for x in labels]\n",
    "        # Remove empty line at end of sentence\n",
    "        [x.remove('') for x in labels] \n",
    "        # Split token and NER tags\n",
    "        labels = [list(map(lambda x:x.split(\" \") ,tag_token)) for tag_token in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSyntaxTreesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load binary syntax tree files (*.syntree).\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentence syntax trees\n",
    "    \"\"\" \n",
    "    all_syntrees = []\n",
    "    for syntree_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        syntree_file = os.path.abspath(syntree_file)\n",
    "        filename = os.path.basename(syntree_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(syntree_file, 'rb') as fp:\n",
    "            all_syntrees.append(pd.read_pickle(fp))\n",
    "    return all_syntrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_gum-ud-test.syntree\n",
      "Data(x=[33, 53], edge_index=[2, 64])\n"
     ]
    }
   ],
   "source": [
    "all_syntrees = loadSyntaxTreesFromFiles(filepath_test_syntrees)\n",
    "print(all_syntrees[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_syntrees = loadSyntaxTreesFromFiles(filepath_test_syntrees)\n",
    "# print(all_syntrees[0][0:2])\n",
    "\n",
    "# syntree_train_loader = tg_data.DataLoader(all_syntrees[0], batch_size=config.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Print example of tokenized text\\nsentences = []\\nfor ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\\n\\n    ud_file = os.path.abspath(ud_file)\\n    filename = os.path.basename(ud_file)\\n    print(filename, flush = True)\\n    with open(ud_file, 'r') as fp:\\n        sentences.extend(fp.read().split('\\n'))\\ncount = 0\\nfor sentence in sentences:\\n    # Tokenize data\\n    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\\n    inputs = createMaskedInputs(inputs)\\n\\n    # Create dataset from tokenized data\\n    dataset = SyntransDataset(inputs)\\n    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\\n    if(count==1):\\n        print(inputs['input_ids'])\\n        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\\n        print(tokens)\\n        print(inputs['labels'])\\n        break\\n    count=count+1\""
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Print example of tokenized text\n",
    "sentences = []\n",
    "for ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\n",
    "\n",
    "    ud_file = os.path.abspath(ud_file)\n",
    "    filename = os.path.basename(ud_file)\n",
    "    print(filename, flush = True)\n",
    "    with open(ud_file, 'r') as fp:\n",
    "        sentences.extend(fp.read().split('\\n'))\n",
    "count = 0\n",
    "for sentence in sentences:\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs = createMaskedInputs(inputs)\n",
    "\n",
    "    # Create dataset from tokenized data\n",
    "    dataset = SyntransDataset(inputs)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    if(count==1):\n",
    "        print(inputs['input_ids'])\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        print(tokens)\n",
    "        print(inputs['labels'])\n",
    "        break\n",
    "    count=count+1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxSequenceLength(sentences, cutoff_limit_percent=0.9999):\n",
    "    \"\"\"\n",
    "    Calculate maximum sequence length for given data.\n",
    "    param sentences: list of sentences\n",
    "    param cutoff_limit_percent: percentage of all samples to accommodate with the max sequence length.\n",
    "    returns: max sequence length which encompasses cutoff_limit_percent of all data samples\n",
    "    \"\"\"\n",
    "    # Get number of tokens per sentence        \n",
    "    max_sentence_tokens = 0\n",
    "    sentence_tokens = {}\n",
    "    print(f\"Amount of samples: {len(sentences)}\")\n",
    "    # Tokenize data\n",
    "    for sentence in sentences:\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors='pt')\n",
    "        \n",
    "        token_count = inputs.input_ids.size(dim=1)\n",
    "        sentence_tokens[inputs.input_ids.size(dim=1)] = sentence_tokens.get(token_count,0) + 1\n",
    "        if(token_count > max_sentence_tokens): \n",
    "            max_sentence_tokens = token_count\n",
    "            \n",
    "    no_tokens = 0\n",
    "    # Calulate number of samples which should have a sequence length smaller than max_sequence_length\n",
    "    cutoff = cutoff_limit_percent * len(sentences)\n",
    "    max_sequence_length = 0\n",
    "    print(max_sentence_tokens)\n",
    "    for i in sorted(sentence_tokens):\n",
    "        # print((i, sentence_tokens[i]), end=\" \")\n",
    "        if(no_tokens <= cutoff):\n",
    "            no_tokens = no_tokens + sentence_tokens[i]\n",
    "            max_sequence_length = i\n",
    "\n",
    "    print(f\"Max sequence length: {max_sequence_length} with {cutoff_limit_percent}% of samples smaller\")\n",
    "    return max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = loadSentencesFromFiles(config.data_path + '**/en_*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getMaxSequenceLength(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (config.train_model):\n",
    "    print(\"Training model\", flush=True)\n",
    "\n",
    "    # Load data\n",
    "    sentences = loadSentencesFromFiles(filepath_train_data)\n",
    "    # Load NER labels\n",
    "    print(filepath_train_ner_labels)\n",
    "    if(config.task == 'ner'):\n",
    "        sentence_labels_list = loadNERLabelsFromFiles(filepath_train_ner_labels)\n",
    "        #print(labels[0][0])\n",
    "        #print(sentences[0][0])\n",
    "        train_features = createNERInputFeatures(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.long)\n",
    "        all_valid_ids = torch.tensor([f.valid_ids for f in train_features], dtype=torch.long)\n",
    "        all_lmask_ids = torch.tensor([f.label_mask for f in train_features], dtype=torch.long)\n",
    "        train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids)\n",
    "\n",
    "        # Print control example of InputFeatures\n",
    "        print(str(train_features[1].input_ids))\n",
    "        print(str(train_features[1].input_mask))\n",
    "        print(str(train_features[1].label_ids))\n",
    "        print(str(train_features[1].valid_ids))\n",
    "        print(str(train_features[1].label_mask))\n",
    "        print(str(train_features[1].segment_ids))\n",
    "\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        # Tokenize data\n",
    "        inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "        inputs = createMaskedInputs(inputs)\n",
    "\n",
    "        # Create dataset from tokenized data\n",
    "        train_data = SyntransDataset(inputs)\n",
    "    \n",
    "    loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "    # initialize optimizer\n",
    "    optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    epochs = config.epochs\n",
    "    # Tensorboard logging\n",
    "    log_dir = f\"./runs/{config.task}/{config.tokenizer}_E{epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}/\"\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    #writer.add_scalar(\"LR\", config.learning_rate)\n",
    "    #writer.add_scalar(\"Batchsize\", config.batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        scalar_loss = 0\n",
    "        # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(loader, leave=True, mininterval=40,maxinterval=120)\n",
    "        for batch in loop:\n",
    "            # initialize calculated gradients (from prev step)\n",
    "            optim.zero_grad()\n",
    "            # pull all tensor batches required for training\n",
    "            if (config.task == 'ner'):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "                loss = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "            if (config.task == 'mlm'):\n",
    "                # pull all tensor batches required for training\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                # process\n",
    "                outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                                labels=labels)\n",
    "                # extract loss\n",
    "                loss = outputs.loss\n",
    "            # calculate loss for every parameter that needs grad update\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            optim.step()\n",
    "            # print relevant info to progress bar\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            scalar_loss = loss.item()\n",
    "            loop.set_postfix(loss=scalar_loss)\n",
    "        # Print info to Tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", scalar_loss, epoch)\n",
    "        # Save model after each epoch\n",
    "        #model.save_pretrained(save_directory=f\"./trained_models/mlm/{config.tokenizer}_E{epoch}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}/\")\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model evaluation\\n\", flush = True)\n",
    "# Load test data\n",
    "if (config.task == 'mlm'):\n",
    "    # Read test files\n",
    "    sentences = loadSentencesFromFiles(config.data_path + '**/*-test.txt')\n",
    "    \n",
    "    test_inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    test_inputs = createMaskedInputs(test_inputs)\n",
    "    test_data = SyntransDataset(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_gum-ud-test-orig.ner\n",
      "Input Ids: \n",
      "[101, 25428, 2031, 8920, 1996, 5177, 6194, 2008, 2104, 8091, 9715, 1998, 9787, 13827, 2229, 1031, 1020, 1033, 1025, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input Tokens: \n",
      "['[CLS]', 'psychologists', 'have', 'examined', 'the', 'mental', 'processes', 'that', 'under', '##pin', 'conscious', 'and', 'unconscious', 'bias', '##es', '[', '6', ']', ';', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "Input Mask: \n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label Ids: \n",
      "[77, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 6, 1, 1, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Valid Ids: \n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Label Mask: \n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Segment Ids: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "if (config.task == 'ner'):\n",
    "    sentence_labels_list = loadNERLabelsFromFiles(filepath_test_ner_labels)\n",
    "    test_features = createNERInputFeatures(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer)\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in test_features], dtype=torch.long)\n",
    "    all_valid_ids = torch.tensor([f.valid_ids for f in test_features], dtype=torch.long)\n",
    "    all_lmask_ids = torch.tensor([f.label_mask for f in test_features], dtype=torch.long)\n",
    "\n",
    "    # Print control example of InputFeatures\n",
    "    print(f\"Input Ids: \\n{str(test_features[5].input_ids)}\")\n",
    "    tokens = []\n",
    "    for input_id in test_features[5].input_ids:\n",
    "        tokens.append(tokenizer.convert_ids_to_tokens(input_id))\n",
    "    print(f\"Input Tokens: \\n{str(tokens)}\")\n",
    "    print(f\"Input Mask: \\n{str(test_features[5].input_mask)}\")\n",
    "    print(f\"Label Ids: \\n{str(test_features[5].label_ids)}\")\n",
    "    print(f\"Valid Ids: \\n{str(test_features[5].valid_ids)}\")\n",
    "    print(f\"Label Mask: \\n{str(test_features[5].label_mask)}\")\n",
    "    print(f\"Segment Ids: \\n{str(test_features[5].segment_ids)}\")\n",
    "\n",
    "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = torch.utils.data.DataLoader(test_data, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "label_map = {i : label for i, label in enumerate(ner_tags_list,1)}\n",
    "\n",
    "references_all = []\n",
    "predictions_all = []\n",
    "references_roc_all = []\n",
    "predictions_roc_all = []\n",
    "\n",
    "if(config.task == 'mlm'):\n",
    "    # Setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True, mininterval=20,maxinterval=120)\n",
    "    for batch in loop:\n",
    "   \n",
    "        # Pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).tolist()\n",
    "\n",
    "        softmax = nn.Softmax(dim = -1)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(input_ids)\n",
    "        predictions = predictions['logits']\n",
    "        predictions_sm = softmax(predictions)\n",
    "\n",
    "        # Change type to double to prevent floating point rounding errors\n",
    "        predictions = predictions.type(torch.float64)\n",
    "        predictions_sm = softmax(predictions)\n",
    "\n",
    "        # Get index of argmax\n",
    "        #y = np.argmax(predictions_sm, axis = -1)\n",
    "        # y = y.tolist()\n",
    "        y = torch.topk(predictions, k=1, dim = 2)[1].squeeze()\n",
    "        y = y.tolist()\n",
    "\n",
    "    #        words_pred = []\n",
    "    #        words_true = []\n",
    "    #        for w in y:\n",
    "    #            words_pred.append( tokenizer.convert_ids_to_tokens(w))\n",
    "        \n",
    "    #        for w in labels[0]:\n",
    "    #            words_true.append( tokenizer.convert_ids_to_tokens(w))\n",
    "        \n",
    "        #print(words_pred[0:50])\n",
    "        #print(words_true[0:50])\n",
    "            \n",
    "\n",
    "        recall_metric = evaluate.load('recall')\n",
    "        precision_metric = evaluate.load('precision')\n",
    "        f1_metric = evaluate.load('f1')\n",
    "        roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "\n",
    "        # Go through all samples in batch and add to computation batch\n",
    "        for idx, pred_batch in enumerate(y):\n",
    "            references_all.extend(labels[idx])\n",
    "            predictions_all.extend(pred_batch)\n",
    "            #precision_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "            #recall_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "            #f1_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "        \n",
    "        # Calculate ROC\n",
    "        for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "            predictions_roc_all.extend(pred_batch.tolist())\n",
    "            references_roc_all.extend(labels[batch_idx])\n",
    "            #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "            break\n",
    "        break\n",
    "\n",
    "    numberOfBatches = len(loop)\n",
    "    # List all possible labels\n",
    "    labels = np.arange(tokenizer.vocab_size)\n",
    "    with open(f\"./logs/Results_{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}.txt\", \"w\") as output:\n",
    "        print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "        output.write(\"macro averaging\\n\")\n",
    "        output.write(str(recall_metric.compute(references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(precision_metric.compute(references = references_all, predictions = predictions_all, average = 'macro', zero_division = 0)))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(\"weighted averaging\\n\")\n",
    "        output.write(str(recall_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(precision_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted', zero_division = 0)))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "        output.write(\"\\n\")\n",
    "        output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "        output.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 448/448 [12:57<00:00,  1.73s/it]\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [CLS] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <unk> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <STOP> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <START> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL     0.0075    0.0921    0.0138       152\n",
      "        CLS]     0.0000    0.0000    0.0000         0\n",
      "        DATE     0.0085    0.0556    0.0147       180\n",
      "       EVENT     0.0000    0.0000    0.0000        14\n",
      "         FAC     0.0000    0.0000    0.0000        48\n",
      "         GPE     0.0036    0.0102    0.0054       196\n",
      "    LANGUAGE     0.0023    0.0200    0.0041        50\n",
      "         LAW     0.0000    0.0000    0.0000         8\n",
      "         LOC     0.0000    0.0000    0.0000        45\n",
      "       MONEY     0.0000    0.0000    0.0000         2\n",
      "        NORP     0.0035    0.1017    0.0067        59\n",
      "     ORDINAL     0.0019    0.0208    0.0035        48\n",
      "         ORG     0.0041    0.0267    0.0071       150\n",
      "     PERCENT     0.0000    0.0000    0.0000         6\n",
      "      PERSON     0.0000    0.0000    0.0000       154\n",
      "     PRODUCT     0.0000    0.0000    0.0000        32\n",
      "    QUANTITY     0.0000    0.0000    0.0000        16\n",
      "      START>     0.0000    0.0000    0.0000         0\n",
      "       STOP>     0.0000    0.0000    0.0000         0\n",
      "        TIME     0.0000    0.0000    0.0000         9\n",
      " WORK_OF_ART     0.0000    0.0000    0.0000        26\n",
      "        unk>     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.0027    0.0318    0.0049      1195\n",
      "   macro avg     0.0014    0.0149    0.0025      1195\n",
      "weighted avg     0.0037    0.0318    0.0064      1195\n",
      "\n",
      " Special token predictions: 101\n"
     ]
    }
   ],
   "source": [
    "if (config.task == 'ner'):\n",
    "\n",
    "    sep_token_id = int(ner_tags_list.index(\"[SEP]\")+1)\n",
    "    cls_token_id = int(ner_tags_list.index(\"[CLS]\")+1)\n",
    "    unk_token_id = int(ner_tags_list.index(\"<unk>\")+1)\n",
    "    O_token_id = int(ner_tags_list.index(\"O\")+1)\n",
    "\n",
    "    special_token_predictions = 0\n",
    "\n",
    "    for input_ids, input_mask, segment_ids, label_ids,valid_ids,l_mask in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            valid_ids = valid_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "            l_mask = l_mask.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_ids, segment_ids, input_mask,valid_ids=valid_ids,attention_mask_label=l_mask)\n",
    "\n",
    "            softmax = nn.Softmax(dim=2)\n",
    "            logits = torch.argmax(softmax(logits),dim=2)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            input_mask = input_mask.to('cpu').numpy()\n",
    "\n",
    "            #print(f\"First label in labels: {label_ids[1][0]}\")\n",
    "\n",
    "            for label_list_idx, true_sentence_labels in enumerate(label_ids):\n",
    "                y_true_temp = []\n",
    "                y_pred_temp = []\n",
    "\n",
    "                for label_idx, label_id in enumerate(true_sentence_labels):\n",
    "\n",
    "                    # Skip 0 label\n",
    "                    if label_id == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip [CLS] label at sequence beginning\n",
    "                    if label_id == cls_token_id:\n",
    "                        continue\n",
    "\n",
    "                    # Detect [SEP] label at sentence end and ignore [SEP] and sequence padding\n",
    "                    elif label_id == sep_token_id:\n",
    "                         y_true.append(y_true_temp)\n",
    "                         y_pred.append(y_pred_temp)\n",
    "                         break\n",
    "                    else:\n",
    "                        if (logits[label_list_idx][label_idx] == 0):\n",
    "                            special_token_predictions = special_token_predictions +1\n",
    "                            logits[label_list_idx][label_idx] = O_token_id\n",
    "                           \n",
    "                        y_true_temp.append(label_map[label_id])\n",
    "                        y_pred_temp.append(label_map[logits[label_list_idx][label_idx]])\n",
    "\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    with open(f\"./logs/{config.task}/Results_{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}.txt\", \"w\") as output:\n",
    "        print(\"***** Eval results *****\")\n",
    "        print(f\"{report}\\n Special token predictions: {special_token_predictions}\")\n",
    "        output.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(references_all, predictions_all, labels=labels)\n",
    "#print(confusion_matrix)\n",
    "#disp = metrics.ConfusionMatrixDisplay(references_all, predictions_all, labels=labels)\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# precision recall curve\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in labels:\n",
    "    precision[i], recall[i], _ = precision_recall_curve(references_roc_all[i],\n",
    "                                                        predictions_roc_all[i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "    break\n",
    "    \n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_syntrans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86a731642ee256d624a4d29e8688bb9c6ad7b39856affb444c6cc9f38126795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
