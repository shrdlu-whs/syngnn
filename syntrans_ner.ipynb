{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Export env vars to limit number of threads to use\n",
    "num_threads = \"4\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = num_threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = num_threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = num_threads\n",
    "\n",
    "# Only use CPU, hide GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForTokenClassification, BertConfig, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Import SummaryWriter for Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "# Load Pytorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.data as tg_data\n",
    "import torch_geometric.utils as tg_utils\n",
    "import torch_geometric.nn as tg_nn\n",
    "import evaluate\n",
    "# Evaluation metrics for NER task\n",
    "from seqeval.metrics import classification_report\n",
    "# Support for IOBES style NER labels\n",
    "from seqeval.scheme import IOBES\n",
    "import numpy as np\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "# Easy file reading\n",
    "import glob\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/home/shrdlu/cdaniel/syntrans/utilities.py'>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utilities as utils\n",
    "# Reload library if changed\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit no. of threads used by Pytorch\n",
    "torch.set_num_threads = int(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 5479, PGID: 116\n"
     ]
    }
   ],
   "source": [
    "PID = os.getpid()\n",
    "PGID = os.getpgid(PID)\n",
    "print(f\"PID: {PID}, PGID: {PGID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa132e322d0>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "activeMode= \"develop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: ner\n",
      "Model path: bert-base-uncased\n",
      "Data path: ./data/ud/UD_English-GUM/\n",
      "Tokenizer: bert-base-uncased\n",
      "Batch size: 4\n",
      "Epochs: 2\n",
      "Learning rate: 5e-05\n",
      "Sequence length: 136\n",
      "Training: True\n"
     ]
    }
   ],
   "source": [
    "configuration_csv = pd.read_csv(f\"./config/{activeMode}.csv\", dtype=str, sep=\";\")\n",
    "config = utils.configureParameters(configuration_csv)\n",
    "print(f\"Task: {config.task}\")\n",
    "print(f\"Model path: {config.saved_model_path}\")\n",
    "print(f\"Data path: {config.data_path}\")\n",
    "print(f\"Tokenizer: {config.tokenizer}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"Sequence length: {config.sequence_length}\")\n",
    "print(f\"Training: {config.train_model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_list = ['X','O','<unk>', 'B-CARDINAL', 'E-CARDINAL', 'S-PERSON', 'S-CARDINAL', 'S-PRODUCT', 'B-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'E-WORK_OF_ART', 'B-PERSON', 'E-PERSON', 'S-GPE', 'B-DATE', 'I-DATE', 'E-DATE', 'S-ORDINAL', 'S-LANGUAGE', 'I-PERSON', 'S-EVENT', 'S-DATE', 'B-QUANTITY', 'E-QUANTITY', 'S-TIME', 'B-TIME', 'I-TIME', 'E-TIME', 'B-GPE', 'E-GPE', 'S-ORG', 'I-GPE', 'S-NORP', 'B-FAC', 'I-FAC', 'E-FAC', 'B-NORP', 'E-NORP', 'S-PERCENT', 'B-ORG', 'E-ORG', 'B-LANGUAGE', 'E-LANGUAGE', 'I-CARDINAL', 'I-ORG', 'S-WORK_OF_ART', 'I-QUANTITY', 'B-MONEY', 'I-MONEY', 'E-MONEY', 'B-LOC', 'E-LOC', 'I-LOC', 'B-PERCENT', 'I-PERCENT', 'E-PERCENT', 'S-LOC', 'S-FAC', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'S-MONEY', 'B-LAW', 'I-LAW', 'E-LAW', 'I-NORP', 'I-LANGUAGE', 'S-LAW', 'S-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'E-ORDINAL', '<START>', '<STOP>', \"[CLS]\", \"[SEP]\"]\n",
    "num_labels = len(ner_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train_data = config.data_path + '**/*-train.txt'\n",
    "filepath_validation_data = config.data_path + '**/*-dev.txt'\n",
    "filepath_test_data = config.data_path + '**/*-test.txt'\n",
    "\n",
    "filepath_train_syntrees = config.data_path + '**/*-train.syntree'\n",
    "filepath_validation_syntrees = config.data_path + '**/*-dev.syntree'\n",
    "filepath_test_syntrees = config.data_path + '**/*-test.syntree'\n",
    "\n",
    "filepath_train_ner_labels = config.data_path + '**/*-train-orig.ner'\n",
    "filepath_validation_ner_labels = config.data_path + '**/*-dev-orig.ner'\n",
    "filepath_test_ner_labels = config.data_path + '**/*-test-orig.ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForNer(BertForTokenClassification):\n",
    "    \"\"\"\n",
    "    Adapted from Huggingface BertForTokenClassification\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,valid_ids=None,attention_mask_label=None):\n",
    "        \n",
    "        # Calculate new embeddings\n",
    "        sequence_output = self.bert(input_ids, token_type_ids, attention_mask,head_mask=None)[0]\n",
    "        batch_size,max_len,feat_dim = sequence_output.shape\n",
    "\n",
    "        # Initialize valid output\n",
    "        valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32)\n",
    "        # Calculate new sequence output: ignore non-valid tokens, e.g. subtokens of words\n",
    "        for batch_idx in range(batch_size):\n",
    "            valid_idx = -1\n",
    "            for token_idx in range(max_len):\n",
    "                    if valid_ids[batch_idx][token_idx].item() == 1:\n",
    "                        valid_idx += 1\n",
    "                        valid_output[batch_idx][valid_idx] = sequence_output[batch_idx][token_idx]\n",
    "        sequence_output = self.dropout(valid_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=0)\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask_label is not None:\n",
    "                active_loss = attention_mask_label.view(-1) == 1\n",
    "                active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                active_labels = labels.view(-1)[active_loss]\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    SynGNN Pytorch module\n",
    "    based on Pytorch TransformerEncoderLayer implementing the architecture in paper “Attention Is All You Need”. \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in, dim_hdn, dim_out, num_heads, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        :param dim_in: input dimension\n",
    "        :param dim_hdn: hidden nodes dimension\n",
    "        :param dim_out: output dimension\n",
    "        \"\"\"\n",
    "        super(nn.TransformerEncoderLayer, self).__init__()\n",
    "        # Graph attention sublayer\n",
    "        self.graph_attn = tg_nn.GATv2Conv(dim_in, dim_hdn , heads=num_heads)\n",
    "        self.linear1 = nn.Linear(dim_hdn, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, dim_out)\n",
    "        self.norm0 = tg_nn.LayerNorm(dim_in)\n",
    "        self.norm1 = nn.LayerNorm(dim_hdn)\n",
    "        self.norm2 = nn.LayerNorm(dim_hdn)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "        \n",
    "        def __setstate__(self, state):\n",
    "            if 'activation' not in state:\n",
    "                state['activation'] = F.relu\n",
    "            super(nn.TransformerEncoderLayer, self).__setstate__(state)\n",
    "\n",
    "        def forward(self, x, edge_index, batch):\n",
    "            r\"\"\"Pass the input through the encoder layer.\n",
    "            Args:\n",
    "                x: node features\n",
    "                edge_index: graph edges\n",
    "                batch: current batch\n",
    "            \"\"\"\n",
    "            # Graph attention sublayer\n",
    "            x_norm = self.norm0(x, batch)\n",
    "            src2, att_weight = self.graph_attn(x_norm, edge_index)\n",
    "            src = src + self.dropout1(src2)\n",
    "            src = self.norm1(src)\n",
    "\n",
    "            # Feed-Forward-Network sublayer\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "            src = src + self.dropout2(src2)\n",
    "            src = self.norm2(src)\n",
    "            return src, att_weight\n",
    "        \n",
    "        def _get_activation_fn(activation):\n",
    "            if activation == \"relu\":\n",
    "                return F.relu\n",
    "            elif activation == \"gelu\":\n",
    "                return F.gelu\n",
    "\n",
    "            raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynBertForNer(BertForTokenClassification):\n",
    "      def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        # self.syngnn = SynGNN()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "      def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,valid_ids=None,attention_mask_label=None):\n",
    "         sequence_output = self.bert(input_ids, token_type_ids, attention_mask,head_mask=None)[0]\n",
    "         batch_size,max_len,feat_dim = sequence_output.shape\n",
    "         valid_output = torch.zeros(batch_size,max_len,feat_dim,dtype=torch.float32)\n",
    "         # Calculate sequence output: ignore non-valid tokens, e.g. subtokens of words\n",
    "         for batch_idx in range(batch_size):\n",
    "            valid_idx = -1\n",
    "            for token_idx in range(max_len):\n",
    "                     if valid_ids[batch_idx][token_idx].item() == 1:\n",
    "                        valid_idx += 1\n",
    "                        valid_output[batch_idx][valid_idx] = sequence_output[batch_idx][token_idx]\n",
    "\n",
    "         # Pipe Bert embeddings into syntactic GAN\n",
    "\n",
    "         sequence_output = self.dropout(valid_output)\n",
    "         logits = self.classifier(sequence_output)\n",
    "\n",
    "         if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=0)\n",
    "            # Only keep active parts of the loss\n",
    "            if attention_mask_label is not None:\n",
    "                  active_loss = attention_mask_label.view(-1) == 1\n",
    "                  active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
    "                  active_labels = labels.view(-1)[active_loss]\n",
    "                  loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                  loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "         else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNer: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForNer were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.tokenizer)\n",
    "if(config.task == 'mlm'):\n",
    "    model = BertForMaskedLM.from_pretrained(config.saved_model_path)\n",
    "if(config.task == 'ner'):\n",
    "    BERTconfig = BertConfig.from_pretrained(config.saved_model_path, num_labels=num_labels, tokenizer = tokenizer)\n",
    "    model = BertForNer.from_pretrained(config.saved_model_path, from_tf = False, config = BERTconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNer(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=79, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cpu')\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, valid_ids=None, label_mask=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMaskedInputs(inputs):\n",
    "    \"\"\"\n",
    "    creates masked input embeddings and labels from tokenized text\n",
    "\n",
    "    :param inputs: tokenized text\n",
    "    :return: masked input embeddings and new column labels \n",
    "    \"\"\" \n",
    "    # Clone input ids (tokens) to create labels\n",
    "    inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "    # create random array of floats with equal dimensions to input_ids tensor\n",
    "    rand = torch.rand(inputs.input_ids.shape)\n",
    "    # create mask array with 15% masked tokens\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "    # Select indices of each nonzero (= selected) value as token to be masked\n",
    "    selection = []\n",
    "\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        selection.append(\n",
    "            torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        )\n",
    "    # Mask selected tokens: replace with [MASK] code 103 in tensor\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNERInputFeatures(sentence_labels_list, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a list of sentences into a list of input features for the transformer\n",
    "    \n",
    "        :return: list of inpt features objects\n",
    "    \"\"\"\n",
    "\n",
    "    # Map NER labels to indices\n",
    "    # start with 1: 0 reserved for invalid labels e.g. subtoken labels\n",
    "    label_map = {label : i for i, label in enumerate(label_list,0)}\n",
    "    #label_map['X'] = 0\n",
    "\n",
    "    features = []\n",
    "    for (sentence_idx,sentence_label_pair) in enumerate(sentence_labels_list):\n",
    "    #     sentence = sentence.split(\" \")\n",
    "    #     labellist = labels[sentence_idx]\n",
    "        if sentence_idx < 2:\n",
    "            sentence_label_pair\n",
    "        # Tokenized text of sentence\n",
    "        tokens = []\n",
    "        # Token labels for sentence\n",
    "        labels = []\n",
    "        # Lists valid labels as 1 and labels to be ignored as 0 (e.g. for the labels for subword tokens which are not counting as separate labels for each token)\n",
    "        valid = []\n",
    "        # Mask for transformer indicating which tokens to ignore\n",
    "        label_mask = []\n",
    "        for word_label_pair in sentence_label_pair:\n",
    "            token = tokenizer.tokenize(word_label_pair[0])\n",
    "            tokens.extend(token)\n",
    "\n",
    "            label_word = word_label_pair[1]\n",
    "            for token_idx in range(len(token)):\n",
    "                # Append label for first token in word, mark as valid\n",
    "                if token_idx == 0:\n",
    "                    labels.append(label_word)\n",
    "                    valid.append(1)\n",
    "                    label_mask.append(1)\n",
    "                # Subword tokens: Mark as not valid\n",
    "                else:\n",
    "                    labels.append('X')\n",
    "                    valid.append(0)\n",
    "                    label_mask.append(1)\n",
    "        # Sentence exceeds max sequence length: cut to sequence length\n",
    "        if len(tokens) >= max_seq_length - 1:\n",
    "            tokens = tokens[0:(max_seq_length - 2)]\n",
    "            labels = labels[0:(max_seq_length - 2)]\n",
    "            valid = valid[0:(max_seq_length - 2)]\n",
    "            label_mask = label_mask[0:(max_seq_length - 2)]\n",
    "        # Tokens with BERT [CLS] and [SEP] tokens\n",
    "        ntokens = []\n",
    "        # Segment ids for BERT\n",
    "        segment_ids = []\n",
    "        # Label embedding ids for BERT\n",
    "        label_ids = []\n",
    "        # Start segment\n",
    "        ntokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(label_map[\"[CLS]\"])\n",
    "        # Mark as valid label\n",
    "        valid.insert(0,1)\n",
    "        label_mask.insert(0,1)\n",
    "\n",
    "        # add sentence tokens\n",
    "        for i, token in enumerate(tokens):\n",
    "            ntokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "            if len(labels) > i:\n",
    "                label_ids.append(label_map[labels[i]])\n",
    "        # End segment\n",
    "        ntokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "        valid.append(1)\n",
    "        label_mask.append(1)\n",
    "        label_ids.append(label_map[\"[SEP]\"])\n",
    "\n",
    "        # Convert tokens to ids\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Pad sentence to sequence length\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "            label_ids.append(0)\n",
    "            valid.append(1)\n",
    "            label_mask.append(0)\n",
    "        # Pad labels to sequence length\n",
    "        while len(label_ids) < max_seq_length:\n",
    "            label_ids.append(0)\n",
    "            label_mask.append(0)\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "        assert len(valid) == max_seq_length\n",
    "        assert len(label_mask) == max_seq_length\n",
    "        \n",
    "\n",
    "        features.append(\n",
    "        InputFeatures(input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        valid_ids=valid,\n",
    "                        label_mask=label_mask))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntransDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ud_tokenizer(tokenizer, tokenizer_name):\n",
    "    tokenizer_path = \"./tokenizers/\" + tokenizer_name \n",
    "    special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "    ]\n",
    "    # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "    vocab_size = 30_522\n",
    "    # Load data\n",
    "    text = []\n",
    "    for ud_file in glob.iglob(config.data_path + '**/UD_English-Pronouns/en_*.txt', recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        tokenizer.train(files=ud_file, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "    # make the directory if not already there\n",
    "    if not os.path.isdir(tokenizer_path):\n",
    "        os.mkdir(tokenizer_path)\n",
    "    # save the tokenizer  \n",
    "    tokenizer.save_model(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSentencesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentences\n",
    "    \"\"\" \n",
    "    sentences = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            sentences.extend(fp.read().split('\\n'))\n",
    "    return sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNERLabelsFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of NER labels per sentence\n",
    "    \"\"\" \n",
    "    labels = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            # Split labels file by sentences\n",
    "            labels.extend(fp.read().split('\\n'))\n",
    "        # Split sentences by tokens\n",
    "        labels = [x.split(\"\\t\") for x in labels]\n",
    "        # Remove empty line at end of sentence\n",
    "        [x.remove('') for x in labels] \n",
    "        # Split token and NER tags\n",
    "        labels = [list(map(lambda x:x.split(\" \") ,tag_token)) for tag_token in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSyntaxTreesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load binary syntax tree files (*.syntree).\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentence syntax trees\n",
    "    \"\"\" \n",
    "    all_syntrees = []\n",
    "    for syntree_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        syntree_file = os.path.abspath(syntree_file)\n",
    "        filename = os.path.basename(syntree_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(syntree_file, 'rb') as fp:\n",
    "            all_syntrees.append(pd.read_pickle(fp))\n",
    "    return all_syntrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_gum-ud-test.syntree\n",
      "Data(x=[33, 53], edge_index=[2, 64], edge_attr=[66, 53])\n"
     ]
    }
   ],
   "source": [
    "all_syntrees = loadSyntaxTreesFromFiles(filepath_test_syntrees)\n",
    "print(all_syntrees[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_syntrees = loadSyntaxTreesFromFiles(filepath_test_syntrees)\n",
    "# print(all_syntrees[0][0:2])\n",
    "\n",
    "# syntree_train_loader = tg_data.DataLoader(all_syntrees[0], batch_size=config.batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Print example of tokenized text\\nsentences = []\\nfor ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\\n\\n    ud_file = os.path.abspath(ud_file)\\n    filename = os.path.basename(ud_file)\\n    print(filename, flush = True)\\n    with open(ud_file, 'r') as fp:\\n        sentences.extend(fp.read().split('\\n'))\\ncount = 0\\nfor sentence in sentences:\\n    # Tokenize data\\n    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\\n    inputs = createMaskedInputs(inputs)\\n\\n    # Create dataset from tokenized data\\n    dataset = SyntransDataset(inputs)\\n    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\\n    if(count==1):\\n        print(inputs['input_ids'])\\n        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\\n        print(tokens)\\n        print(inputs['labels'])\\n        break\\n    count=count+1\""
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Print example of tokenized text\n",
    "sentences = []\n",
    "for ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\n",
    "\n",
    "    ud_file = os.path.abspath(ud_file)\n",
    "    filename = os.path.basename(ud_file)\n",
    "    print(filename, flush = True)\n",
    "    with open(ud_file, 'r') as fp:\n",
    "        sentences.extend(fp.read().split('\\n'))\n",
    "count = 0\n",
    "for sentence in sentences:\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs = createMaskedInputs(inputs)\n",
    "\n",
    "    # Create dataset from tokenized data\n",
    "    dataset = SyntransDataset(inputs)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    if(count==1):\n",
    "        print(inputs['input_ids'])\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        print(tokens)\n",
    "        print(inputs['labels'])\n",
    "        break\n",
    "    count=count+1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxSequenceLength(sentences, cutoff_limit_percent=0.9999):\n",
    "    \"\"\"\n",
    "    Calculate maximum sequence length for given data.\n",
    "    param sentences: list of sentences\n",
    "    param cutoff_limit_percent: percentage of all samples to accommodate with the max sequence length.\n",
    "    returns: max sequence length which encompasses cutoff_limit_percent of all data samples\n",
    "    \"\"\"\n",
    "    # Get number of tokens per sentence        \n",
    "    max_sentence_tokens = 0\n",
    "    sentence_tokens = {}\n",
    "    print(f\"Amount of samples: {len(sentences)}\")\n",
    "    # Tokenize data\n",
    "    for sentence in sentences:\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors='pt')\n",
    "        \n",
    "        token_count = inputs.input_ids.size(dim=1)\n",
    "        sentence_tokens[inputs.input_ids.size(dim=1)] = sentence_tokens.get(token_count,0) + 1\n",
    "        if(token_count > max_sentence_tokens): \n",
    "            max_sentence_tokens = token_count\n",
    "            \n",
    "    no_tokens = 0\n",
    "    # Calulate number of samples which should have a sequence length smaller than max_sequence_length\n",
    "    cutoff = cutoff_limit_percent * len(sentences)\n",
    "    max_sequence_length = 0\n",
    "    print(max_sentence_tokens)\n",
    "    for i in sorted(sentence_tokens):\n",
    "        # print((i, sentence_tokens[i]), end=\" \")\n",
    "        if(no_tokens <= cutoff):\n",
    "            no_tokens = no_tokens + sentence_tokens[i]\n",
    "            max_sequence_length = i\n",
    "\n",
    "    print(f\"Max sequence length: {max_sequence_length} with {cutoff_limit_percent}% of samples smaller\")\n",
    "    return max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = loadSentencesFromFiles(config.data_path + '**/en_*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getMaxSequenceLength(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataloader(filepath, shuffle_data=False):\n",
    "\n",
    "        # Load NER labels\n",
    "        if(config.task == 'ner'):\n",
    "            print(filepath)\n",
    "            sentence_labels_list = loadNERLabelsFromFiles(filepath)\n",
    "            if (activeMode == 'develop'):\n",
    "                sentence_labels_list = sentence_labels_list[0:20]\n",
    "            features = createNERInputFeatures(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer)\n",
    "            all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "            all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "            all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "            all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "            all_valid_ids = torch.tensor([f.valid_ids for f in features], dtype=torch.long)\n",
    "            all_lmask_ids = torch.tensor([f.label_mask for f in features], dtype=torch.long)\n",
    "            data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids)\n",
    "\n",
    "            # Print control example of InputFeatures\n",
    "            print(str(features[1].input_ids))\n",
    "            print(str(features[1].input_mask))\n",
    "            print(str(features[1].label_ids))\n",
    "            print(str(features[1].valid_ids))\n",
    "            print(str(features[1].label_mask))\n",
    "            print(str(features[1].segment_ids))\n",
    "\n",
    "\n",
    "        if(config.task == 'mlm'):\n",
    "            # Load data\n",
    "            sentences = loadSentencesFromFiles(filepath)\n",
    "            # Tokenize data\n",
    "            inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "            inputs = createMaskedInputs(inputs)\n",
    "\n",
    "            # Create dataset from tokenized data\n",
    "            data = SyntransDataset(inputs)\n",
    "        \n",
    "        loader = DataLoader(data, batch_size=config.batch_size, shuffle=shuffle_data)\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainData():\n",
    "    print(\"Loading Training Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        return createDataloader(filepath_train_ner_labels, shuffle_data=True)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadValidationData():\n",
    "    print(\"Loading Validation Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        return createDataloader(filepath_validation_ner_labels)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestData():\n",
    "    print(\"Test Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        return createDataloader(filepath_test_ner_labels)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(epoch, trainLoader, writer):\n",
    "    # activate training mode\n",
    "    model.train()\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "    # initialize optimizer\n",
    "    optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    epoch_loss = 0\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(trainLoader, leave=True, mininterval=40,maxinterval=120)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        if (config.task == 'ner'):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "            loss, _ = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "        if (config.task == 'mlm'):\n",
    "            # pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            # process\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            # extract loss\n",
    "            loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Train Epoch {epoch}')\n",
    "        batch_loss = loss.item()\n",
    "        loop.set_postfix(loss=batch_loss)\n",
    "        epoch_loss = epoch_loss + batch_loss\n",
    "    # Calculate epoch loss\n",
    "    epoch_loss = epoch_loss / len(trainLoader)\n",
    "    # Print info to Tensorboard\n",
    "    writer.add_scalar(\"Loss\", epoch_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateModel(epoch, validationLoader, writer):\n",
    "    # activate eval mode\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    # setup loop with TQDM and dataloader\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(validationLoader, leave=True, mininterval=40,maxinterval=120)\n",
    "        for batch in loop:\n",
    "            # pull all tensor batches required for training\n",
    "            if (config.task == 'ner'):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "                logits, loss = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "            if (config.task == 'mlm'):\n",
    "                # pull all tensor batches required for training\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                # process\n",
    "                outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                                labels=labels)\n",
    "                # extract loss\n",
    "                loss = outputs.loss\n",
    "            if(validation_mode):\n",
    "                # print relevant info to progress bar\n",
    "                loop.set_description(f'Validation Epoch {epoch}')\n",
    "                batch_loss = loss.item()\n",
    "                loop.set_postfix(loss=batch_loss)\n",
    "                epoch_loss = epoch_loss + batch_loss\n",
    "        if(validation_mode):\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(validationLoader)\n",
    "            print(epoch_loss)\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(data_loader, validation_mode = False, writer = None, epoch = None):\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    label_map = {i : label for i, label in enumerate(ner_tags_list,0)}\n",
    "\n",
    "    references_all = []\n",
    "    predictions_all = []\n",
    "    references_roc_all = []\n",
    "    predictions_roc_all = []\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        # Setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        for batch in loop:\n",
    "    \n",
    "            # Pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).tolist()\n",
    "\n",
    "            softmax = nn.Softmax(dim = -1)\n",
    "            with torch.no_grad():\n",
    "                predictions = model(input_ids)\n",
    "            predictions = predictions['logits']\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Change type to double to prevent floating point rounding errors\n",
    "            predictions = predictions.type(torch.float64)\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Get index of argmax\n",
    "            #y = np.argmax(predictions_sm, axis = -1)\n",
    "            # y = y.tolist()\n",
    "            y = torch.topk(predictions, k=1, dim = 2)[1].squeeze()\n",
    "            y = y.tolist()\n",
    "                \n",
    "\n",
    "            recall_metric = evaluate.load('recall')\n",
    "            precision_metric = evaluate.load('precision')\n",
    "            f1_metric = evaluate.load('f1')\n",
    "            roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "\n",
    "            # Go through all samples in batch and add to computation batch\n",
    "            for idx, pred_batch in enumerate(y):\n",
    "                references_all.extend(labels[idx])\n",
    "                predictions_all.extend(pred_batch)\n",
    "                #precision_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "                #recall_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "                #f1_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "            \n",
    "            # Calculate ROC\n",
    "            for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "                predictions_roc_all.extend(pred_batch.tolist())\n",
    "                references_roc_all.extend(labels[batch_idx])\n",
    "                #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "                break\n",
    "            break\n",
    "\n",
    "        numberOfBatches = len(loop)\n",
    "        # List all possible labels\n",
    "        labels = np.arange(tokenizer.vocab_size)\n",
    "        with open(f\"./logs/Results_{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}.txt\", \"w\") as output:\n",
    "            print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "            output.write(\"macro averaging\\n\")\n",
    "            output.write(str(recall_metric.compute(references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute(references = references_all, predictions = predictions_all, average = 'macro', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(\"weighted averaging\\n\")\n",
    "            output.write(str(recall_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.close()\n",
    "    \n",
    "    if (config.task == 'ner'):\n",
    "\n",
    "        sep_token_id = int(ner_tags_list.index(\"[SEP]\"))\n",
    "        cls_token_id = int(ner_tags_list.index(\"[CLS]\"))\n",
    "        unk_token_id = int(ner_tags_list.index(\"<unk>\"))\n",
    "        O_token_id = int(ner_tags_list.index(\"O\"))\n",
    "\n",
    "        special_token_predictions = 0\n",
    "\n",
    "        for input_ids, input_mask, segment_ids, label_ids,valid_ids,l_mask in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_mask = input_mask.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "                valid_ids = valid_ids.to(device)\n",
    "                label_ids = label_ids.to(device)\n",
    "                l_mask = l_mask.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if (validation_mode):\n",
    "                        loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "                    else:\n",
    "                        logits = model(input_ids, segment_ids, input_mask,valid_ids=valid_ids,attention_mask_label=l_mask)\n",
    "\n",
    "                if(validation_mode):\n",
    "                    # print relevant info to progress bar\n",
    "                    loop.set_description(f'Validation Epoch {epoch}')\n",
    "                    batch_loss = loss.item()\n",
    "                    loop.set_postfix(loss=batch_loss)\n",
    "                    epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "                softmax = nn.Softmax(dim=2)\n",
    "                logits = torch.argmax(softmax(logits),dim=2)\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = label_ids.to('cpu').numpy()\n",
    "                input_mask = input_mask.to('cpu').numpy()\n",
    "\n",
    "                #print(f\"First label in labels: {label_ids[1][0]}\")\n",
    "\n",
    "                for label_list_idx, true_sentence_labels in enumerate(label_ids):\n",
    "                    y_true_temp = []\n",
    "                    y_pred_temp = []\n",
    "\n",
    "                    for label_idx, label_id in enumerate(true_sentence_labels):\n",
    "\n",
    "                        # Skip 0 label\n",
    "                        if label_id == 0:\n",
    "                            continue\n",
    "\n",
    "                        # Skip [CLS] label at sequence beginning\n",
    "                        if label_id == cls_token_id:\n",
    "                            continue\n",
    "\n",
    "                        # Detect [SEP] label at sentence end and ignore [SEP] and sequence padding\n",
    "                        elif label_id == sep_token_id:\n",
    "                            y_true.append(y_true_temp)\n",
    "                            y_pred.append(y_pred_temp)\n",
    "                            break\n",
    "                        else:\n",
    "                            if (logits[label_list_idx][label_idx] == 0):\n",
    "                                special_token_predictions = special_token_predictions +1\n",
    "                                logits[label_list_idx][label_idx] = O_token_id\n",
    "                            \n",
    "                            y_true_temp.append(label_map[label_id])\n",
    "                            y_pred_temp.append(label_map[logits[label_list_idx][label_idx]])\n",
    "\n",
    "        report = classification_report(y_true, y_pred, digits=4, output_dict={validation_mode})\n",
    "        if (validation_mode):\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(data_loader)\n",
    "            print(epoch_loss)\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "            macro_precision = report['macro avg']['precision']\n",
    "            writer.add_scalar(\"macro_avg/precision\", macro_precision, epoch)\n",
    "            macro_recall = report['macro avg']['recall']\n",
    "            writer.add_scalar(\"macro_avg/recall\", macro_recall, epoch)\n",
    "            macro_f1 = report['macro avg']['f1']\n",
    "            writer.add_scalar(\"macro_avg/f1\", macro_f1, epoch)\n",
    "\n",
    "            weighted_precision = report['weighted avg']['precision']\n",
    "            writer.add_scalar(\"weighted_avg/precision\", weighted_precision, epoch)\n",
    "            weighted_recall = report['weighted avg']['recall']\n",
    "            writer.add_scalar(\"weighted_avg/recall\", weighted_recall, epoch)\n",
    "            weighted_f1 = report['weighted avg']['f1']\n",
    "            writer.add_scalar(\"weighted_avg/f1\", weighted_f1, epoch)\n",
    "        else:\n",
    "\n",
    "            with open(f\"./logs/{config.task}/Results_{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}.txt\", \"w\") as output:\n",
    "                print(\"***** Eval results *****\")\n",
    "                print(f\"{report}\\n Special token predictions: {special_token_predictions}\")\n",
    "                output.write(report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Loading Training Data\n",
      "./data/ud/UD_English-GUM/**/*-train-orig.ner\n",
      "en_gum-ud-train-orig.ner\n",
      "[101, 20062, 2013, 3239, 1011, 9651, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[77, 1, 1, 1, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Loading Validation Data\n",
      "./data/ud/UD_English-GUM/**/*-dev-orig.ner\n",
      "en_gum-ud-dev-orig.ner\n",
      "[101, 2470, 2006, 4639, 1011, 4342, 2117, 2653, 1006, 1048, 2475, 1007, 2038, 3024, 6196, 12369, 2046, 1996, 11265, 10976, 3597, 29076, 6024, 10595, 10318, 1996, 4083, 1998, 6364, 1997, 1048, 2475, 8035, 1031, 1015, 1033, 1516, 1031, 2340, 1033, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[77, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 6, 1, 0, 0, 6, 1, 1, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0: 100%|██████████| 5/5 [01:18<00:00, 15.67s/it, loss=2.02] \n",
      "Evaluating:   0%|          | 0/5 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loop' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=18'>19</a>\u001b[0m trainModel(epoch, trainLoader, train_writer)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=19'>20</a>\u001b[0m \u001b[39m#validateModel(epoch, validationLoader, validation_writer)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=20'>21</a>\u001b[0m evaluateModel(validationLoader, validation_mode \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, writer \u001b[39m=\u001b[39;49m validation_writer, epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m (activeMode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mprod\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=22'>23</a>\u001b[0m     \u001b[39m# Save model after each epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=23'>24</a>\u001b[0m     model\u001b[39m.\u001b[39msave_pretrained(save_directory\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./trained_models/\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mtask\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mtokenizer\u001b[39m}\u001b[39;00m\u001b[39m_E\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m_batches\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m_LR\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m_SL\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39msequence_length\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb Cell 38\u001b[0m in \u001b[0;36mevaluateModel\u001b[0;34m(data_loader, validation_mode, writer, epoch)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=108'>109</a>\u001b[0m         logits \u001b[39m=\u001b[39m model(input_ids, segment_ids, input_mask,valid_ids\u001b[39m=\u001b[39mvalid_ids,attention_mask_label\u001b[39m=\u001b[39ml_mask)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=110'>111</a>\u001b[0m \u001b[39mif\u001b[39;00m(validation_mode):\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=111'>112</a>\u001b[0m     \u001b[39m# print relevant info to progress bar\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=112'>113</a>\u001b[0m     loop\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=113'>114</a>\u001b[0m     batch_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000029vscode-remote?line=114'>115</a>\u001b[0m     loop\u001b[39m.\u001b[39mset_postfix(loss\u001b[39m=\u001b[39mbatch_loss)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'loop' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if (config.train_model):\n",
    "    print(\"Training model\", flush=True)\n",
    "\n",
    "\n",
    "    trainLoader = loadTrainData()\n",
    "    validationLoader = loadValidationData()\n",
    "\n",
    "    epochs = config.epochs\n",
    "    log_idx = 0\n",
    "    # Tensorboard logging\n",
    "    while(os.path.exists(f\"./runs/{config.task}/{config.tokenizer}_E{epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_{log_idx}/\") and log_idx <30):\n",
    "        log_idx = log_idx+1\n",
    "    log_dir = f\"./runs/{config.task}/{config.tokenizer}_E{epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_{log_idx}/\"\n",
    "    \n",
    "    train_writer = SummaryWriter(log_dir=log_dir+\"training\")\n",
    "    validation_writer = SummaryWriter(log_dir=log_dir+\"validation\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        trainModel(epoch, trainLoader, train_writer)\n",
    "        #validateModel(epoch, validationLoader, validation_writer)\n",
    "        evaluateModel(validationLoader, validation_mode = True, writer = validation_writer, epoch=epoch)\n",
    "        if (activeMode == 'prod'):\n",
    "            # Save model after each epoch\n",
    "            model.save_pretrained(save_directory=f\"./trained_models/{config.task}/{config.tokenizer}_E{epoch}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}/\")\n",
    "    train_writer.close()\n",
    "    validation_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model evaluation\\n\", flush = True)\n",
    "# Load test data\n",
    "if (config.task == 'mlm'):\n",
    "    # Read test files\n",
    "    sentences = loadSentencesFromFiles(config.data_path + '**/*-test.txt')\n",
    "    \n",
    "    test_inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    test_inputs = createMaskedInputs(test_inputs)\n",
    "    test_data = SyntransDataset(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_gum-ud-test-orig.ner\n",
      "Input Ids: \n",
      "[101, 25428, 2031, 8920, 1996, 5177, 6194, 2008, 2104, 8091, 9715, 1998, 9787, 13827, 2229, 1031, 1020, 1033, 1025, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input Tokens: \n",
      "['[CLS]', 'psychologists', 'have', 'examined', 'the', 'mental', 'processes', 'that', 'under', '##pin', 'conscious', 'and', 'unconscious', 'bias', '##es', '[', '6', ']', ';', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "Input Mask: \n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label Ids: \n",
      "[77, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 6, 1, 1, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Valid Ids: \n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Label Mask: \n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Segment Ids: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "if (config.task == 'ner'):\n",
    "    sentence_labels_list = loadNERLabelsFromFiles(filepath_test_ner_labels)\n",
    "    test_features = createNERInputFeatures(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer)\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in test_features], dtype=torch.long)\n",
    "    all_valid_ids = torch.tensor([f.valid_ids for f in test_features], dtype=torch.long)\n",
    "    all_lmask_ids = torch.tensor([f.label_mask for f in test_features], dtype=torch.long)\n",
    "\n",
    "    # Print control example of InputFeatures\n",
    "    print(f\"Input Ids: \\n{str(test_features[5].input_ids)}\")\n",
    "    tokens = []\n",
    "    for input_id in test_features[5].input_ids:\n",
    "        tokens.append(tokenizer.convert_ids_to_tokens(input_id))\n",
    "    print(f\"Input Tokens: \\n{str(tokens)}\")\n",
    "    print(f\"Input Mask: \\n{str(test_features[5].input_mask)}\")\n",
    "    print(f\"Label Ids: \\n{str(test_features[5].label_ids)}\")\n",
    "    print(f\"Valid Ids: \\n{str(test_features[5].valid_ids)}\")\n",
    "    print(f\"Label Mask: \\n{str(test_features[5].label_mask)}\")\n",
    "    print(f\"Segment Ids: \\n{str(test_features[5].segment_ids)}\")\n",
    "\n",
    "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n",
      "./data/ud/UD_English-GUM/**/*-test-orig.ner\n",
      "en_gum-ud-test-orig.ner\n",
      "[101, 3463, 2013, 1037, 9582, 4387, 7099, 1997, 6001, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[77, 1, 1, 1, 1, 1, 1, 1, 1, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loader = loadTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:14<00:00,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "{'CARDINAL': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 51}, 'CLS]': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'DATE': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'EVENT': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'FAC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'GPE': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'LANGUAGE': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'LAW': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'LOC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'MONEY': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'NORP': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}, 'ORDINAL': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'PERCENT': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}, 'PERSON': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'PRODUCT': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'QUANTITY': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'SEP]': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'START>': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'STOP>': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'TIME': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'WORK_OF_ART': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'unk>': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}, 'macro avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}, 'weighted avg': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}}\n",
      " Special token predictions: 10\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [SEP] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <unk> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <START> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: [CLS] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <STOP> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000035vscode-remote?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mreport\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m Special token predictions: \u001b[39m\u001b[39m{\u001b[39;00mspecial_token_predictions\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000035vscode-remote?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(report[\u001b[39m'\u001b[39m\u001b[39mmacro avg\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syntrans_ner.ipynb#ch0000035vscode-remote?line=60'>61</a>\u001b[0m output\u001b[39m.\u001b[39;49mwrite(report)\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not dict"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(references_all, predictions_all, labels=labels)\n",
    "#print(confusion_matrix)\n",
    "#disp = metrics.ConfusionMatrixDisplay(references_all, predictions_all, labels=labels)\n",
    "#disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# precision recall curve\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in labels:\n",
    "    precision[i], recall[i], _ = precision_recall_curve(references_roc_all[i],\n",
    "                                                        predictions_roc_all[i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "    break\n",
    "    \n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_syntrans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86a731642ee256d624a4d29e8688bb9c6ad7b39856affb444c6cc9f38126795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
