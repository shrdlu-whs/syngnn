{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: ner\n",
      "Model path: bert-base-cased\n",
      "Data path: ./data/ud/UD_English-GUM/\n",
      "Tokenizer: bert-base-cased\n",
      "Batch size: 2\n",
      "Epochs: 1\n",
      "Learning rate: 3e-05\n",
      "Sequence length: 96\n",
      "Training: True\n",
      "Num Threads: 2\n",
      "Num Sentences: 20\n",
      "Max Norm: 0.0\n",
      "Use GNN: False\n",
      "Use label weights: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import utilities as utils\n",
    "\n",
    "\n",
    "activeMode= \"develop\"\n",
    "\n",
    "# Reload utils library if changed\n",
    "importlib.reload(utils)\n",
    "\n",
    "configuration_csv = pd.read_csv(f\"./config/{activeMode}.csv\", dtype=str, sep=\";\")\n",
    "config = utils.configureParameters(configuration_csv)\n",
    "max_grad_norm_str = str(config.max_grad_norm).replace(\".\",\"-\")\n",
    "print(f\"Task: {config.task}\")\n",
    "print(f\"Model path: {config.saved_model_path}\")\n",
    "print(f\"Data path: {config.data_path}\")\n",
    "print(f\"Tokenizer: {config.tokenizer}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"Sequence length: {config.sequence_length}\")\n",
    "print(f\"Training: {config.train_model}\")\n",
    "print(f\"Num Threads: {config.num_threads}\")\n",
    "print(f\"Num Sentences: {config.num_sentences}\")\n",
    "print(f\"Max Norm: {config.max_grad_norm}\")\n",
    "print(f\"Use GNN: {config.use_gnn}\")\n",
    "if(config.use_gnn == True):\n",
    "    print(f\"Num layers: {config.num_layers}\")\n",
    "    print(f\"Num attention heads: {config.num_att_heads}\")\n",
    "print(f\"Use label weights: {config.use_label_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Export env vars to limit number of threads to use\n",
    "num_threads = str(config.num_threads)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"MKL_NUM_THREADS\"] = num_threads \n",
    "\n",
    "# Only use CPU, hide GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/shrdlu/cdaniel/syntrans/models.py'>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models as models\n",
    "# Reload models if changed\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForTokenClassification, BertConfig, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Import SummaryWriter for Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "# Load Pytorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.data as tg_data\n",
    "import torch_geometric.loader as tg_loader\n",
    "import torch_geometric.utils as tg_utils\n",
    "import torch_geometric.nn as tg_nn\n",
    "import torch.profiler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import evaluate\n",
    "# Evaluation metrics for NER task\n",
    "from seqeval.metrics import classification_report\n",
    "# Support for IOBES style NER labels\n",
    "from seqeval.scheme import IOBES\n",
    "import numpy as np\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "# Easy file reading\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 602, PGID: 116\n"
     ]
    }
   ],
   "source": [
    "PID = os.getpid()\n",
    "PGID = os.getpgid(PID)\n",
    "print(f\"PID: {PID}, PGID: {PGID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9413dfb750>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit no. of threads used by Pytorch\n",
    "torch.set_num_threads = int(num_threads)\n",
    "torch.set_num_interop_threads = int(num_threads)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATen/Parallel:\n",
      "\tat::get_num_threads() : 2\n",
      "\tat::get_num_interop_threads() : 2\n",
      "OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "\tomp_get_max_threads() : 2\n",
      "Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "\tmkl_get_max_threads() : 2\n",
      "Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
      "std::thread::hardware_concurrency() : 4\n",
      "Environment variables:\n",
      "\tOMP_NUM_THREADS : 2\n",
      "\tMKL_NUM_THREADS : 2\n",
      "ATen parallel backend: OpenMP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.__config__.parallel_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_list = ['X','O','<unk>', 'B-CARDINAL', 'E-CARDINAL', 'S-PERSON', 'S-CARDINAL', 'S-PRODUCT', 'B-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'E-WORK_OF_ART', 'B-PERSON', 'E-PERSON', 'S-GPE', 'B-DATE', 'I-DATE', 'E-DATE', 'S-ORDINAL', 'S-LANGUAGE', 'I-PERSON', 'S-EVENT', 'S-DATE', 'B-QUANTITY', 'E-QUANTITY', 'S-TIME', 'B-TIME', 'I-TIME', 'E-TIME', 'B-GPE', 'E-GPE', 'S-ORG', 'I-GPE', 'S-NORP', 'B-FAC', 'I-FAC', 'E-FAC', 'B-NORP', 'E-NORP', 'S-PERCENT', 'B-ORG', 'E-ORG', 'B-LANGUAGE', 'E-LANGUAGE', 'I-CARDINAL', 'I-ORG', 'S-WORK_OF_ART', 'I-QUANTITY', 'B-MONEY', 'I-MONEY', 'E-MONEY', 'B-LOC', 'E-LOC', 'I-LOC', 'B-PERCENT', 'I-PERCENT', 'E-PERCENT', 'S-LOC', 'S-FAC', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'S-MONEY', 'B-LAW', 'I-LAW', 'E-LAW', 'I-NORP', 'I-LANGUAGE', 'S-LAW', 'S-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'E-ORDINAL', '<START>', '<STOP>', \"[CLS]\", \"[SEP]\"]\n",
    "num_ner_labels = len(ner_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath for sentences\n",
    "filepath_train_data = config.data_path + '**/*-train.txt'\n",
    "filepath_validation_data = config.data_path + '**/*-dev.txt'\n",
    "filepath_test_data = config.data_path + '**/*-test.txt'\n",
    "\n",
    "# Filepath for syntax graphs\n",
    "filepath_train_syntrees = config.data_path + f'**/*-train-{config.tokenizer}.syntree'\n",
    "filepath_validation_syntrees = config.data_path + f'**/*-dev-{config.tokenizer}.syntree'\n",
    "filepath_test_syntrees = config.data_path + f'**/*-test-{config.tokenizer}.syntree'\n",
    "\n",
    "# Filepath for sentences with NER tags\n",
    "filepath_train_ner_labels = config.data_path + f'**/*-train-orig.ner'\n",
    "filepath_validation_ner_labels = config.data_path + f'**/*-dev-orig.ner'\n",
    "filepath_test_ner_labels = config.data_path + f'**/*-test-orig.ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_config = f\"{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_GN{max_grad_norm_str}\"\n",
    "\n",
    "if (config.use_gnn == True):\n",
    "    tensorboard_dir = f\"./runs/{config.task}/synGNN/{general_config}_TL_{config.num_layers}AttH_{config.num_att_heads}_LW{config.use_label_weights}\"\n",
    "    tensorboard_dir = utils.createNumberedDir(tensorboard_dir)\n",
    "\n",
    "    results_dir = f\"./logs/{config.task}/synGNN/{general_config}__TL_{config.num_layers}AttH_{config.num_att_heads}_LW{config.use_label_weights}\"\n",
    "    results_dir = utils.createNumberedDir(results_dir)\n",
    "    if (activeMode == \"prod\"):\n",
    "        trained_models_dir = f\"./trained_models/{config.task}/synGNN/{general_config}_TL_{config.num_layers}AttH_{config.num_att_heads}_LW{config.use_label_weights}\"\n",
    "        trained_models_dir = trained_models_dir.replace(f\"_E{config.epochs}_\", f\"_E0_\")\n",
    "else:\n",
    "    tensorboard_dir = f\"./runs/{config.task}/bert/{general_config}\"\n",
    "    tensorboard_dir = utils.createNumberedDir(tensorboard_dir)\n",
    "\n",
    "    results_dir = f\"./logs/{config.task}/bert/{general_config}\"\n",
    "    results_dir = utils.createNumberedDir(results_dir)\n",
    "    if (activeMode == \"prod\"):\n",
    "        trained_models_dir = f\"./trained_models/{config.task}/bert/{general_config}\"\n",
    "        trained_models_dir = trained_models_dir.replace(f\"_E{config.epochs}_\", f\"_E0_\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ud/UD_English-GUM/**/*-train-bert-base-cased.syntree\n"
     ]
    }
   ],
   "source": [
    "print(filepath_train_syntrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, valid_ids=None, label_mask=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masked_inputs(inputs):\n",
    "    \"\"\"\n",
    "    creates masked input embeddings and labels from tokenized text\n",
    "\n",
    "    :param inputs: tokenized text\n",
    "    :return: masked input embeddings and new column labels \n",
    "    \"\"\" \n",
    "    # Clone input ids (tokens) to create labels\n",
    "    inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "    # create random array of floats with equal dimensions to input_ids tensor\n",
    "    rand = torch.rand(inputs.input_ids.shape)\n",
    "    # create mask array with 15% masked tokens\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "    # Select indices of each nonzero (= selected) value as token to be masked\n",
    "    selection = []\n",
    "\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        selection.append(\n",
    "            torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        )\n",
    "    # Mask selected tokens: replace with [MASK] code 103 in tensor\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_input_features(sentence_labels_list, label_list, seq_length, tokenizer, create_label_weights = False):\n",
    "    \"\"\"Loads a list of sentences into a list of input features for the transformer\n",
    "    \n",
    "        :return: list of inpt features objects\n",
    "    \"\"\"\n",
    "\n",
    "    # Map NER labels to indices\n",
    "    label_map = {label : i for i, label in enumerate(label_list,0)}\n",
    "    #label_map['X'] = 0\n",
    "\n",
    "    features = []\n",
    "    all_label_ids = []\n",
    "    for (sentence_idx,sentence_label_pair) in enumerate(sentence_labels_list):\n",
    "        # Tokenized text of sentence\n",
    "        tokens = []\n",
    "        # Token labels for sentence\n",
    "        labels = []\n",
    "        # Lists valid labels as 1 and labels to be ignored as 0 (e.g. for the labels for subword tokens which are not counting as separate labels for each token)\n",
    "        valid = []\n",
    "        # Mask for transformer indicating which tokens to ignore\n",
    "        label_mask = []\n",
    "        for word_label_pair in sentence_label_pair:\n",
    "            token = tokenizer.tokenize(word_label_pair[0])\n",
    "            tokens.extend(token)\n",
    "\n",
    "            label_word = word_label_pair[1]\n",
    "            for token_idx in range(len(token)):\n",
    "                # Append label for first token in word, mark as valid\n",
    "                if token_idx == 0:\n",
    "                    labels.append(label_word)\n",
    "                    valid.append(1)\n",
    "                    label_mask.append(1)\n",
    "                # Subword tokens: Mark as not valid\n",
    "                else:\n",
    "                    labels.append('X')\n",
    "                    valid.append(0)\n",
    "                    label_mask.append(1)\n",
    "        # Sentence exceeds max sequence length: cut to sequence length\n",
    "        if len(tokens) > seq_length-2:\n",
    "            #if len(tokens)>90:\n",
    "            #    print(tokens)\n",
    "            tokens = tokens[0:(seq_length)]\n",
    "            labels = labels[0:(seq_length)]\n",
    "            valid = valid[0:(seq_length)]\n",
    "            label_mask = label_mask[0:(seq_length)]\n",
    "            if len(tokens)>90:\n",
    "                print(tokens)\n",
    "        # Tokens with BERT [CLS] and [SEP] tokens\n",
    "        ntokens = []\n",
    "        # Segment ids for BERT\n",
    "        segment_ids = []\n",
    "        # Label embedding ids for BERT\n",
    "        label_ids = []\n",
    "        # Start segment\n",
    "        ntokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        # Add CLS token label for Bert\n",
    "        label_ids.append(label_map[\"[CLS]\"])\n",
    "        # Mark as valid label\n",
    "        valid.insert(0,1)\n",
    "        label_mask.insert(0,1)\n",
    "\n",
    "        # add sentence tokens and label ids\n",
    "        for i, token in enumerate(tokens):\n",
    "            ntokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "            if len(labels) > i:\n",
    "                label_ids.append(label_map[labels[i]])\n",
    "        # End segment\n",
    "        ntokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "\n",
    "        # Add SEP end token label for Bert\n",
    "        label_ids.append(label_map[\"[SEP]\"])\n",
    "        valid.append(1)\n",
    "        label_mask.append(1)\n",
    "\n",
    "        # Convert tokens to ids\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Add label ids to list for weight computation\n",
    "        all_label_ids.extend(label_ids)\n",
    "        \n",
    "        # Pad sentence to sequence length\n",
    "        while len(input_ids) < seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "\n",
    "        # Pad labels to sequence length\n",
    "        while len(label_ids) < seq_length:\n",
    "            label_ids.append(0)\n",
    "            label_mask.append(0)\n",
    "            valid.append(1)\n",
    "        \n",
    "\n",
    "        assert len(input_ids) == seq_length\n",
    "        assert len(input_mask) == seq_length\n",
    "        assert len(segment_ids) == seq_length\n",
    "        assert len(label_ids) == seq_length\n",
    "        assert len(valid) == seq_length\n",
    "        assert len(label_mask) == seq_length\n",
    "\n",
    "        features.append(\n",
    "        InputFeatures(\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        valid_ids=valid,\n",
    "                        label_mask=label_mask,\n",
    "                        ))\n",
    "\n",
    "    # Set weights for label classes to 1 (=no change) \n",
    "    all_label_weights = np.ones(len(label_list))\n",
    "    \n",
    "    if create_label_weights == 1:\n",
    "        # Reduce weight of X and O, CLS, SEP for loss computation\n",
    "        #all_label_weights[0] = 0.2\n",
    "        #all_label_weights[1] = 0.1\n",
    "        #all_label_weights[77] = 0.2\n",
    "        #all_label_weights[78] = 0.2\n",
    "\n",
    "        bincount = np.bincount(all_label_ids)\n",
    "        sum = np.sum(bincount)\n",
    "        sum_X = bincount[0]\n",
    "        sum_O = bincount[1]\n",
    "        sum_ner = np.sum(bincount[2:77])\n",
    "        sum_SEP_CLS = np.sum(bincount[77:79])\n",
    "\n",
    "\n",
    "        #print(f\" {bincount}\")\n",
    "        #print(f\"Total:{sum}\")\n",
    "        #print(f\"X: {sum_X}\")\n",
    "        #print(f\"O: {sum_O}\")\n",
    "        #print(f\"NER {sum_ner}\")\n",
    "        #print(f\"SEP/CLS: {sum_SEP_CLS}\")\n",
    "\n",
    "        '''label_classes = np.unique(all_label_ids)\n",
    "        label_weights = compute_class_weight(class_weight='balanced', classes=label_classes, y=np.array(all_label_ids).reshape(-1))\n",
    "\n",
    "        for idx, label_weight in enumerate(label_weights):\n",
    "            label_class = label_classes[idx]\n",
    "            all_label_weights[label_class] = label_weight'''\n",
    "\n",
    "        with open(\"./temp/label_weights_ud.txt\", \"w\") as output:\n",
    "            output.write(str(all_label_weights))\n",
    "\n",
    "    return features, torch.tensor(all_label_weights, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, syntax_graphs=None,sentence_graph_idx_maps=None):\n",
    "\n",
    "        self.features = features\n",
    "        self.syntax_graphs = syntax_graphs\n",
    "        self.sentence_graph_idx_maps = sentence_graph_idx_maps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if(self.syntax_graphs is not None and self.sentence_graph_idx_maps is not None):\n",
    "\n",
    "            features = self.features[idx]\n",
    "            syntax_graphs = self.syntax_graphs[idx]\n",
    "            sentence_graph_idx_map = self.sentence_graph_idx_maps[idx]\n",
    "            return features, syntax_graphs, sentence_graph_idx_map\n",
    "        else:\n",
    "            return self.features[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_data_collate_function(data):\n",
    "\n",
    "    # Get all Bert input feature objects\n",
    "    if config.use_gnn == True:\n",
    "        input_features = list(zip(*data))[0]\n",
    "    else:\n",
    "        input_features = data\n",
    "    # Get all input ids\n",
    "    input_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.input_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all input masks\n",
    "    input_masks = torch.squeeze(torch.tensor(list(map(lambda x:x.input_mask,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all label ids\n",
    "    label_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.label_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all valid ids\n",
    "    valid_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.valid_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all label masks\n",
    "    label_masks = torch.squeeze(torch.tensor(list(map(lambda x:x.label_mask,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all segment ids\n",
    "    segment_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.segment_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    if config.use_gnn == True:\n",
    "        # Get all Pytorch Geom Data objects\n",
    "        pyg_data = list(zip(*data))[1]\n",
    "        # Get all sentence_graph_idx_maps\n",
    "        sentence_graph_idx_maps = list(zip(*data))[2]\n",
    "\n",
    "        return input_ids, input_masks, label_ids, valid_ids, label_masks, segment_ids, pyg_data, sentence_graph_idx_maps\n",
    "    else:\n",
    "        '''print(input_ids[0])\n",
    "        print(input_masks[0])\n",
    "        print(label_ids[0])\n",
    "        print(valid_ids[0])\n",
    "        print(label_masks[0])\n",
    "        print(segment_ids[0])'''\n",
    "        return input_ids, input_masks, label_ids, valid_ids, label_masks, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ud_tokenizer(tokenizer, tokenizer_name):\n",
    "    tokenizer_path = \"./tokenizers/\" + tokenizer_name \n",
    "    special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "    ]\n",
    "    # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "    vocab_size = 30_522\n",
    "    # Load data\n",
    "    text = []\n",
    "    for ud_file in glob.iglob(config.data_path + '**/UD_English-Pronouns/en_*.txt', recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        tokenizer.train(files=ud_file, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "    # make the directory if not already there\n",
    "    if not os.path.isdir(tokenizer_path):\n",
    "        os.mkdir(tokenizer_path)\n",
    "    # save the tokenizer  \n",
    "    tokenizer.save_model(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences_from_files(filepath, seq_length=None):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :param seq_length: BERT sequence length. Must be provided when SynGNN is used instead of vanilla Bert. SynGNN only supports sentences up to seq_length, others are discarded\n",
    "    :return: list of sentences\n",
    "    \"\"\" \n",
    "    sentences = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            sentences_temp = fp.read().split('\\n')\n",
    "            if (seq_length != None):\n",
    "                for sentence in sentences_temp:\n",
    "                    if(len(sentence) <= seq_length):\n",
    "                        sentences.extend(sentence)\n",
    "            else:\n",
    "                sentences.extend(fp.read().split('\\n'))\n",
    "    return sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ner_labels_from_files(filepath, num_sentences=0, excluded_idx_list=None):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of NER labels per sentence\n",
    "    \"\"\" \n",
    "    all_token_label_pairs = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "        sentences = []\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            if (config.num_sentences == 0):\n",
    "                # Split labels file by sentences\n",
    "                sentences = fp.read().split('\\n')\n",
    "            else:\n",
    "                sentences = fp.read().split('\\n')[0:num_sentences]\n",
    "        # Split sentences by tokens\n",
    "        token_labels = [x.split(\"\\t\") for x in sentences]\n",
    "        # Remove empty line at end of sentence\n",
    "        [x.remove('') for x in token_labels]\n",
    "        # Remove empty line at end of file\n",
    "        if token_labels[-1] == []:\n",
    "            token_labels.pop(-1)\n",
    "\n",
    "        print(f\"num sentences: {len(token_labels)}\")\n",
    "      \n",
    "        \n",
    "        # Split token and NER tags\n",
    "        token_labels = [list(map(lambda x:x.split(\" \") ,tag_token)) for tag_token in token_labels if tag_token != []]\n",
    "\n",
    "        all_token_label_pairs.extend(token_labels)\n",
    "    # Delete sentences longer than sequence length\n",
    "    if (excluded_idx_list != None):\n",
    "        all_token_label_pairs = [x for idx, x in enumerate(all_token_label_pairs) if idx not in excluded_idx_list]\n",
    "    return all_token_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_syntaxgraphs_from_files(filepath, seq_length=None, num_sentences=0):\n",
    "    r\"\"\"\n",
    "    Load binary syntax tree files (*.syntree).\n",
    "    Args:\n",
    "        filepath: path to files (supports glob regex)\n",
    "        return: list of pytorch geometric syntax graphs per file and list of sentence token to graph node mappings\n",
    "    \"\"\" \n",
    "    all_syntrees = []\n",
    "    all_sentence_to_graph_maps = []\n",
    "    excluded_idx_list = []\n",
    "    for syntree_file in sorted(glob.iglob(filepath, recursive=True)):   \n",
    "        syntree_file = os.path.abspath(syntree_file)\n",
    "        filename = os.path.basename(syntree_file)\n",
    "        print(f\"Loading syntax graphs: from file {filename}\", flush=True)\n",
    "        with open(syntree_file, 'rb') as fp:\n",
    "            if (config.num_sentences == 0):\n",
    "                file_graphs_and_maps = pd.read_pickle(fp)\n",
    "            else:\n",
    "                file_graphs_and_maps = pd.read_pickle(fp)[0:num_sentences]\n",
    "\n",
    "            print(f\"num graphs {len(file_graphs_and_maps)}\")\n",
    "\n",
    "\n",
    "            syntree_list = [graph_map_pair[0] for graph_map_pair in file_graphs_and_maps]\n",
    "            sentence_to_graph_map_list = [graph_map_pair[1] for graph_map_pair in file_graphs_and_maps]\n",
    "            all_syntrees.extend(syntree_list)\n",
    "            all_sentence_to_graph_maps.extend(sentence_to_graph_map_list)\n",
    "\n",
    "    # Delete all graphs where graph length >= seq_len\n",
    "    # Graph always is of length: num tokens+1, including graph root token.\n",
    "    for idx, graph in enumerate(all_syntrees):\n",
    "        graph_len =  graph.x.shape[0]\n",
    "        if graph_len>=seq_length:\n",
    "            excluded_idx_list.append(idx)\n",
    "    all_syntrees = [x for idx, x in enumerate(all_syntrees) if idx not in excluded_idx_list]\n",
    "    all_sentence_to_graph_maps = [x for idx, x in enumerate(all_sentence_to_graph_maps) if idx not in excluded_idx_list]\n",
    "    print(\"Example syntax graphs:\")\n",
    "    print(all_syntrees[0:2])\n",
    "    print(all_sentence_to_graph_maps[0:2])\n",
    "    return all_syntrees, all_sentence_to_graph_maps, excluded_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxSequenceLength(sentences, cutoff_limit_percent=0.9999):\n",
    "    \"\"\"\n",
    "    Calculate maximum sequence length for given data.\n",
    "    param sentences: list of sentences\n",
    "    param cutoff_limit_percent: percentage of all samples to accommodate with the max sequence length.\n",
    "    returns: max sequence length which encompasses cutoff_limit_percent of all data samples\n",
    "    \"\"\"\n",
    "    # Get number of tokens per sentence        \n",
    "    max_sentence_tokens = 0\n",
    "    sentence_tokens = {}\n",
    "    print(f\"Amount of samples: {len(sentences)}\")\n",
    "    # Tokenize data\n",
    "    for sentence in sentences:\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors='pt')\n",
    "        \n",
    "        token_count = inputs.input_ids.size(dim=1)\n",
    "        sentence_tokens[inputs.input_ids.size(dim=1)] = sentence_tokens.get(token_count,0) + 1\n",
    "        if(token_count > max_sentence_tokens): \n",
    "            max_sentence_tokens = token_count\n",
    "            \n",
    "    no_tokens = 0\n",
    "    # Calulate number of samples which should have a sequence length smaller than max_sequence_length\n",
    "    cutoff = cutoff_limit_percent * len(sentences)\n",
    "    max_sequence_length = 0\n",
    "    print(max_sentence_tokens)\n",
    "    for i in sorted(sentence_tokens):\n",
    "        # print((i, sentence_tokens[i]), end=\" \")\n",
    "        if(no_tokens <= cutoff):\n",
    "            no_tokens = no_tokens + sentence_tokens[i]\n",
    "            max_sequence_length = i\n",
    "\n",
    "    print(f\"Max sequence length: {max_sequence_length} with {cutoff_limit_percent}% of samples smaller\")\n",
    "    return max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_mlm(filepath, tokenizer, filepath_syntrees = None, shuffle_data=False):\n",
    "\n",
    "    # Load sentences data\n",
    "    sentences = load_sentences_from_files(filepath)\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs = create_masked_inputs(inputs)\n",
    "\n",
    "    \n",
    "    if (config.use_gnn and filepath_syntrees != None):\n",
    "        excluded_idx_list = None\n",
    "        # Load syntax graphs\n",
    "        syntax_graphs, sentence_to_graph_idx_maps, excluded_idx_list = load_syntaxgraphs_from_files(filepath_syntrees, config.sequence_length, config.num_sentences)\n",
    "        #TODO: Add syntax graphs to MlmDataset\n",
    "        data = MlmDataset(inputs)\n",
    "    else:\n",
    "        data = MlmDataset(inputs)\n",
    "    loader = DataLoader(data, batch_size=config.batch_size, shuffle=shuffle_data)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_ner(filepath, tokenizer, create_weights, filepath_syntrees = None, shuffle_data=False):\n",
    "    excluded_idx_list = None\n",
    "    if (config.use_gnn):\n",
    "        # Load syntax graphs\n",
    "        if(config.use_gnn and filepath_syntrees != None):\n",
    "            syntax_graphs, sentence_to_graph_idx_maps, excluded_idx_list = load_syntaxgraphs_from_files(filepath_syntrees, config.sequence_length, config.num_sentences)\n",
    "    \n",
    "    print(f\"Loading NER labels from {filepath}\")\n",
    "    # Load NER labels\n",
    "    sentence_labels_list = load_ner_labels_from_files(filepath, config.num_sentences, excluded_idx_list)\n",
    "    num_sentences = len(sentence_labels_list)\n",
    "\n",
    "    # Check that sentences and graphs match\n",
    "    if config.use_gnn == True:\n",
    "        num_graphs = len(syntax_graphs)\n",
    "\n",
    "        if num_sentences != num_graphs:\n",
    "            print(f\"Num Sentences ({num_sentences}) and num graphs ({num_graphs}) must be the same\")\n",
    "            exit()\n",
    "        # Check that graphs and sentences are of same length\n",
    "        # Account for root node in graph.\n",
    "        graph_sentence_unequal_count = 0\n",
    "        delete_idx_list = []\n",
    "        for graph_idx, graph in enumerate(syntax_graphs):\n",
    "            graph_len = graph.x.size()[0]\n",
    "            sentence = [sentence_label_pair[0] for sentence_label_pair in sentence_labels_list[graph_idx]]\n",
    "            sentence_tokenized = []\n",
    "            for word in sentence:\n",
    "                tokens = tokenizer.tokenize(word)\n",
    "                sentence_tokenized.extend(tokens)\n",
    "            sentence_len = len(sentence_tokenized)\n",
    "            # Graph and sentence unequal: schedule for delete\n",
    "            if graph_len-1 != sentence_len:\n",
    "                graph_sentence_unequal_count = graph_sentence_unequal_count+1\n",
    "                delete_idx_list.append(graph_idx)\n",
    "\n",
    "        syntax_graphs = [x for idx, x in enumerate(syntax_graphs) if idx not in delete_idx_list]\n",
    "        sentence_to_graph_idx_maps = [x for idx, x in enumerate(sentence_to_graph_idx_maps) if idx not in delete_idx_list]\n",
    "        sentence_labels_list = [x for idx, x in enumerate(sentence_labels_list) if idx not in delete_idx_list]\n",
    "\n",
    "    # Remove batches of size 1 \n",
    "    if num_sentences % config.batch_size == 1:\n",
    "            if config.use_gnn:\n",
    "                syntax_graphs.pop(-1)\n",
    "                sentence_to_graph_idx_maps.pop(-1)\n",
    "                num_graphs = len(syntax_graphs)\n",
    "            num_sentences = len(sentence_labels_list)\n",
    "            sentence_labels_list.pop(-1)\n",
    "    \n",
    "    num_batches = math.ceil(num_sentences / config.batch_size)\n",
    "\n",
    "    print(f\"Example of NER labels: {sentence_labels_list[0:2]}\")\n",
    "    features, label_weights = create_ner_input_features(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer, create_weights)\n",
    "\n",
    "    if config.use_gnn == True:\n",
    "        print(f\"Excluded {len(excluded_idx_list)} sentences longer than sequence length\")\n",
    "        print(f\"Excluded {graph_sentence_unequal_count} items with sentence != graph\")\n",
    "        print(f\"Deleted items: {delete_idx_list}\" )\n",
    "        print(f\"{num_sentences} sentences, {num_graphs} graphs, {num_batches} batches of size {config.batch_size}\\n\")\n",
    "        mlm_dataset = NerDataset(features, syntax_graphs, sentence_to_graph_idx_maps)\n",
    "    else:\n",
    "        print(f\"{num_sentences} sentences, {num_batches} batches of size {config.batch_size}\\n\")\n",
    "        mlm_dataset = NerDataset(features)\n",
    "\n",
    "    print(\"Control example of InputFeatures\")\n",
    "    print(f\"Input Ids: {str(features[1].input_ids)}\")\n",
    "    print(f\"Input Mask: {str(features[1].input_mask)}\")\n",
    "    print(f\"Label Ids: {str(features[1].label_ids)}\")\n",
    "    print(f\"Valid Ids: {str(features[1].valid_ids)}\")\n",
    "    print(f\"Label Mask: {str(features[1].label_mask)}\")\n",
    "    print(f\"Segment Ids: {str(features[1].segment_ids)}\")\n",
    "\n",
    "    loader = DataLoader(mlm_dataset, batch_size=config.batch_size, shuffle=shuffle_data, collate_fn=ner_data_collate_function)\n",
    "    return loader, label_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataloader(filepath, tokenizer, filepath_syntrees = None, shuffle_data=False, create_weights=0):\n",
    "        excluded_idx_list = None\n",
    "        # Load syntax graphs and create dataset\n",
    "        if(config.use_gnn and filepath_syntrees != None):\n",
    "            syntax_graphs, sentence_to_graph_idx_maps, excluded_idx_list = load_syntaxgraphs_from_files(filepath_syntrees, config.sequence_length, config.num_sentences)\n",
    "        # Load NER labels\n",
    "        if(config.task == 'ner'):\n",
    "            print(f\"Loading NER labels from {filepath}\")\n",
    "            # Load NER labels\n",
    "            sentence_labels_list = load_ner_labels_from_files(filepath, config.num_sentences, excluded_idx_list)\n",
    "            num_sentences = len(sentence_labels_list)\n",
    "            num_graphs = len(syntax_graphs)\n",
    "\n",
    "            if num_sentences != num_graphs:\n",
    "                print(f\"Num Sentences ({num_sentences}) and num graphs ({num_graphs}) must be the same\")\n",
    "                exit()\n",
    "            # Check that graphs and sentences are of same length\n",
    "            # Account for root node in graph.\n",
    "            graph_sentence_unequal_count = 0\n",
    "            delete_idx_list = []\n",
    "            for graph_idx, graph in enumerate(syntax_graphs):\n",
    "                graph_len = graph.x.size()[0]\n",
    "                sentence = [sentence_label_pair[0] for sentence_label_pair in sentence_labels_list[graph_idx]]\n",
    "                sentence_tokenized = []\n",
    "                for word in sentence:\n",
    "                    tokens = tokenizer.tokenize(word)\n",
    "                    sentence_tokenized.extend(tokens)\n",
    "                sentence_len = len(sentence_tokenized)\n",
    "                # Graph and sentence unequal: schedule for delete\n",
    "                if graph_len-1 != sentence_len:\n",
    "                    graph_sentence_unequal_count = graph_sentence_unequal_count+1\n",
    "                    delete_idx_list.append(graph_idx)\n",
    "\n",
    "            syntax_graphs = [x for idx, x in enumerate(syntax_graphs) if idx not in delete_idx_list]\n",
    "            sentence_to_graph_idx_maps = [x for idx, x in enumerate(sentence_to_graph_idx_maps) if idx not in delete_idx_list]\n",
    "            sentence_labels_list = [x for idx, x in enumerate(sentence_labels_list) if idx not in delete_idx_list]\n",
    "\n",
    "            # Remove batches of size 1 \n",
    "            if num_sentences % config.batch_size == 1:\n",
    "                 syntax_graphs.pop(-1)\n",
    "                 sentence_labels_list.pop(-1)\n",
    "                 sentence_to_graph_idx_maps.pop(-1)\n",
    "                 num_sentences = len(sentence_labels_list)\n",
    "                 num_graphs = len(syntax_graphs)\n",
    "            \n",
    "            num_batches = math.ceil(num_sentences / config.batch_size)\n",
    "            \n",
    "            print(f\"Excluded {len(excluded_idx_list)} sentences longer than sequence length\")\n",
    "            print(f\"Excluded {graph_sentence_unequal_count} items with sentence != graph\")\n",
    "            print(f\"Deleted items: {delete_idx_list}\" )\n",
    "            print(f\"{num_sentences} sentences, {num_graphs} graphs, {num_batches} batches of size {config.batch_size}\\n\")\n",
    "\n",
    "            print(f\"Example of NER labels: {sentence_labels_list[0:2]}\")\n",
    "            features, label_weights = create_ner_input_features(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer, create_weights)\n",
    "            #all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "            #all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "            #all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "            #all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "            #all_valid_ids = torch.tensor([f.valid_ids for f in features], dtype=torch.long)\n",
    "            #all_lmask_ids = torch.tensor([f.label_mask for f in features], dtype=torch.long)\n",
    "            #all_label_weights = torch.tensor(label_weights, dtype=torch.long)\n",
    "            \n",
    "            #data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids, all_label_weights)\n",
    "            #print(data.__sizeof__())\n",
    "\n",
    "            # Print control example of InputFeatures\n",
    "            print(\"Control example of InputFeatures\")\n",
    "            print(f\"Input Ids: {str(features[1].input_ids)}\")\n",
    "            print(f\"Input Mask: {str(features[1].input_mask)}\")\n",
    "            print(f\"Label Ids: {str(features[1].label_ids)}\")\n",
    "            print(f\"Valid Ids: {str(features[1].valid_ids)}\")\n",
    "            print(f\"Label Mask: {str(features[1].label_mask)}\")\n",
    "            print(f\"Segment Ids: {str(features[1].segment_ids)}\")\n",
    "\n",
    "\n",
    "        if(config.task == 'mlm'):\n",
    "            # Load data\n",
    "            sentences = load_sentences_from_files(filepath)\n",
    "            # Tokenize data\n",
    "            inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "            inputs = create_masked_inputs(inputs)\n",
    "\n",
    "            # Create dataset from tokenized data\n",
    "            data = MlmDataset(inputs)\n",
    "        \n",
    "        # Create dataset\n",
    "        if(config.use_gnn and filepath_syntrees != None):\n",
    "            syngnn_dataset = SynGNNDataset(features, syntax_graphs, sentence_to_graph_idx_maps)\n",
    "            loader = DataLoader(syngnn_dataset, batch_size=config.batch_size, shuffle=shuffle_data, collate_fn=syngnn_data_collate_function)\n",
    "        else:\n",
    "            loader = DataLoader(data, batch_size=config.batch_size, shuffle=shuffle_data)\n",
    "        return loader, label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(tokenizer):\n",
    "    if (config.use_label_weights == True):\n",
    "        # Create label weights from data\n",
    "        create_weights = 1\n",
    "    else:\n",
    "        # Use uniform label weights\n",
    "        create_weights = 2\n",
    "    print(\"Loading Training Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn):\n",
    "            return create_dataloader_ner(filepath_train_ner_labels, tokenizer, filepath_train_syntrees, shuffle_data=True, create_weights=create_weights)\n",
    "        else:\n",
    "            return create_dataloader_ner(filepath_train_ner_labels, tokenizer, shuffle_data=True,create_weights=create_weights)\n",
    "    if(config.task == 'mlm'):\n",
    "        if(config.use_gnn):\n",
    "            return create_dataloader_mlm(filepath_train_data, tokenizer, filepath_train_syntrees, shuffle_data=True, create_weights=create_weights)\n",
    "        else:\n",
    "            return create_dataloader_mlm(filepath_train_data, tokenizer, shuffle_data=True, create_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data(tokenizer):\n",
    "    print(\"Loading Validation Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn):\n",
    "            return create_dataloader_ner(filepath_validation_ner_labels, tokenizer, filepath_validation_syntrees, shuffle_data=True, create_weights=0)\n",
    "        else:\n",
    "            return create_dataloader_ner(filepath_validation_ner_labels, tokenizer, shuffle_data=True,  create_weights=0)\n",
    "    if(config.task == 'mlm'):\n",
    "        return create_dataloader_mlm(filepath_validation_data, tokenizer, create_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(tokenizer):\n",
    "    print(\"Test Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn):\n",
    "            return create_dataloader_ner(filepath_test_ner_labels, tokenizer, filepath_test_syntrees, shuffle_data=False, create_weights=0)\n",
    "        else:\n",
    "            return create_dataloader_ner(filepath_test_ner_labels, tokenizer, shuffle_data=False, create_weights=0)\n",
    "    if(config.task == 'mlm'):\n",
    "        return create_dataloader_mlm(filepath_test_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stderr\n",
    "prof = torch.profiler.profile(\n",
    "        activities=[ProfilerActivity.CPU],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=1, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/noembeddings'),\n",
    "        record_shapes=False,\n",
    "        with_stack=True)\n",
    "def runModelGNN(data_loader, model, device, tokenizer, mode=None, writer = None, results_dir = None,  epoch = None, optimizer = None):\n",
    "\n",
    "    if(mode == 'Train'):\n",
    "        model.train()\n",
    "    elif(mode == 'Test' or mode == 'Validation'):\n",
    "        model.eval()\n",
    "    else:\n",
    "        stderr(\"Mode must be Train, Validation or Test\")\n",
    "        exit()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    label_map = {i : label for i, label in enumerate(ner_tags_list,0)}\n",
    "\n",
    "    references_all = []\n",
    "    predictions_all = []\n",
    "    references_roc_all = []\n",
    "    predictions_roc_all = []\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        # Setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        for batch in loop:\n",
    "    \n",
    "            # Pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).tolist()\n",
    "\n",
    "            softmax = nn.Softmax(dim = -1)\n",
    "            if (mode == 'Test' or mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(input_ids)\n",
    "            if(mode == 'Train'):\n",
    "                # initialize calculated gradients (from prev step)\n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(input_ids)\n",
    "            predictions = predictions['logits']\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Change type to double to prevent floating point rounding errors\n",
    "            predictions = predictions.type(torch.float64)\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Get index of argmax\n",
    "            y = torch.topk(predictions, k=1, dim = 2)[1].squeeze()\n",
    "            y = y.tolist()\n",
    "                \n",
    "            recall_metric = evaluate.load('recall')\n",
    "            precision_metric = evaluate.load('precision')\n",
    "            f1_metric = evaluate.load('f1')\n",
    "            roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "            # Go through all samples in batch and add to computation batch\n",
    "            for idx, pred_batch in enumerate(y):\n",
    "                references_all.extend(labels[idx])\n",
    "                predictions_all.extend(pred_batch)\n",
    "            \n",
    "            # Calculate ROC (TODO)\n",
    "            #for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "            #    predictions_roc_all.extend(pred_batch.tolist())\n",
    "            #    references_roc_all.extend(labels[batch_idx])\n",
    "            #    #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "            #    break\n",
    "            #break\n",
    "\n",
    "        numberOfBatches = len(loop)\n",
    "        # List all possible labels\n",
    "        labels = np.arange(tokenizer.vocab_size)\n",
    "        with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "            print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "            output.write(\"macro averaging\\n\")\n",
    "            output.write(str(recall_metric.compute(references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute(references = references_all, predictions = predictions_all, average = 'macro', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(\"weighted averaging\\n\")\n",
    "            output.write(str(recall_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.close()\n",
    "    \n",
    "    if (config.task == 'ner'):\n",
    "\n",
    "        sep_token_id = int(ner_tags_list.index(\"[SEP]\"))\n",
    "        cls_token_id = int(ner_tags_list.index(\"[CLS]\"))\n",
    "        unk_token_id = int(ner_tags_list.index(\"<unk>\"))\n",
    "        O_token_id = int(ner_tags_list.index(\"O\"))\n",
    "\n",
    "        special_token_predictions = 0\n",
    "        O_token_predictions = 0\n",
    "        ner_token_predictions = 0\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        # Loop over all batches\n",
    "        #prof.start()\n",
    "        for batch in loop:\n",
    "            batch = tuple(t for t in batch)\n",
    "            if (config.use_gnn):\n",
    "                input_ids, input_masks, label_ids, valid_ids, label_mask, segment_ids, pyg_data, sentence_graph_idx_maps = batch\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_masks = input_masks.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "                label_ids = label_ids.to(device)\n",
    "                valid_ids = valid_ids.to(device)\n",
    "                label_mask = label_mask.to(device)\n",
    "            else:\n",
    "                input_ids, input_masks, label_ids, valid_ids, label_mask, segment_ids = batch\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_masks = input_masks.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "                label_ids = label_ids.to(device)\n",
    "                valid_ids = valid_ids.to(device)\n",
    "                label_mask = label_mask.to(device)\n",
    "\n",
    "            if(mode == 'Train'):\n",
    "                # initialize gradients for batch to zero\n",
    "                optimizer.zero_grad()\n",
    "                if (config.use_gnn):\n",
    "                    loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids, syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                else:\n",
    "                    loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids)\n",
    "                # calculate loss for every parameter that needs grad update\n",
    "                loss.backward()\n",
    "                if (config.max_grad_norm):\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "            elif(mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    if (config.use_gnn):\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids, syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                    else:\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids)\n",
    "            elif(mode == 'Test'):\n",
    "                if (config.use_gnn):\n",
    "                    logits = model(input_ids=input_ids, token_type_ids=segment_ids,attention_mask=input_masks,valid_ids=valid_ids,attention_mask_label=label_mask, syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                else:\n",
    "                    logits = model(input_ids, segment_ids, input_masks,valid_ids=valid_ids,attention_mask_label=label_mask)\n",
    "\n",
    "            if(mode == 'Validation' or mode == 'Train'):\n",
    "                # print relevant info to progress bar\n",
    "                loop.set_description(f'{mode} Epoch {epoch}')\n",
    "                batch_loss = loss.item()\n",
    "                loop.set_postfix(loss=batch_loss)\n",
    "                epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "            \n",
    "            #print(f\"Logits{logits.size()}\")\n",
    "            softmax = nn.Softmax(dim=2)\n",
    "\n",
    "            # Get highest NER label prediction for all sentences\n",
    "            #print(f\"Softmax:{softmax(logits)}\")\n",
    "            logits = torch.argmax(softmax(logits),dim=2)\n",
    "            #print(f\"Argmax: {logits.size()}\")\n",
    "            logits = logits.to('cpu').numpy()\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            input_masks = input_masks.to('cpu').numpy()\n",
    "\n",
    "            # Go through true labels\n",
    "            for label_list_idx, true_sentence_labels in enumerate(label_ids):\n",
    "                y_true_temp = []\n",
    "                y_pred_temp = []\n",
    "\n",
    "                for label_idx, label_id in enumerate(true_sentence_labels):\n",
    "\n",
    "                    # Skip 0 label\n",
    "                    if label_id == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip [CLS] label at sequence beginning\n",
    "                    if label_id == cls_token_id:\n",
    "                        continue\n",
    "\n",
    "                    # Detect [SEP] label at sentence end and ignore [SEP] and all sequence padding\n",
    "                    # Append all found labels to y_true and y_pred\n",
    "                    elif label_id == sep_token_id:\n",
    "                        y_true.append(y_true_temp)\n",
    "                        y_pred.append(y_pred_temp)\n",
    "                        break\n",
    "                    else:\n",
    "                        # Predicted NER label is special token X: count preds\n",
    "                        if (logits[label_list_idx][label_idx] == 0):\n",
    "                        #if (logits[label_list_idx] == 0):\n",
    "                            special_token_predictions = special_token_predictions +1\n",
    "                        # Predicted NER label is O: count preds\n",
    "                        elif (logits[label_list_idx][label_idx] == O_token_id):\n",
    "                        #elif (logits[label_list_idx] == O_token_id):\n",
    "                            O_token_predictions = O_token_predictions +1\n",
    "                        else:\n",
    "                            ner_token_predictions = ner_token_predictions +1\n",
    "\n",
    "                        # Append label and prediction to list\n",
    "                        y_true_temp.append(label_map[label_id])\n",
    "                        y_pred_temp.append(label_map[logits[label_list_idx][label_idx]])\n",
    "                        #y_pred_temp.append(label_map[logits[label_list_idx]])\n",
    "\n",
    "        if (mode == 'Train' or mode == 'Validation'):\n",
    "            print(f\"True: {y_true[0:5]}, Predicted: {y_pred[0:5]}\")\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=True, zero_division = 0)\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(data_loader)\n",
    "\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "            macro_precision = report['macro avg']['precision']\n",
    "            writer.add_scalar(\"macro_avg/precision\", macro_precision, epoch)\n",
    "            macro_recall = report['macro avg']['recall']\n",
    "            writer.add_scalar(\"macro_avg/recall\", macro_recall, epoch)\n",
    "            macro_f1 = report['macro avg']['f1-score']\n",
    "            writer.add_scalar(\"macro_avg/f1\", macro_f1, epoch)\n",
    "\n",
    "            weighted_precision = report['weighted avg']['precision']\n",
    "            writer.add_scalar(\"weighted_avg/precision\", weighted_precision, epoch)\n",
    "            weighted_recall = report['weighted avg']['recall']\n",
    "            writer.add_scalar(\"weighted_avg/recall\", weighted_recall, epoch)\n",
    "            weighted_f1 = report['weighted avg']['f1-score']\n",
    "            writer.add_scalar(\"weighted_avg/f1\", weighted_f1, epoch)\n",
    "            print(f\"O Token Predictions: {O_token_predictions}, NER token predictions: {ner_token_predictions}\")\n",
    "            print(f\"loss: {epoch_loss} w prec: {weighted_precision} w recall: {weighted_recall} w f1: {weighted_f1}\")\n",
    "            return epoch_loss, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1\n",
    "\n",
    "        else:\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=False)\n",
    "            with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "                print(\"***** Test results *****\")\n",
    "                print(f\"Task: {config.task}\")\n",
    "                print(f\"Model path: {config.saved_model_path}\")\n",
    "                print(f\"Data path: {config.data_path}\")\n",
    "                print(f\"Tokenizer: {config.tokenizer}\")\n",
    "                print(f\"Batch size: {config.batch_size}\")\n",
    "                print(f\"Epochs: {config.epochs}\")\n",
    "                print(f\"Learning rate: {config.learning_rate}\")\n",
    "                print(f\"Sequence length: {config.sequence_length}\")\n",
    "                print(f\"Training: {config.train_model}\")\n",
    "                print(f\"Num Threads: {config.num_threads}\")\n",
    "                print(f\"Num Sentences: {config.num_sentences}\")\n",
    "                print(f\"Max Grad Norm: {config.max_grad_norm}\")\n",
    "                print(f\"Max Grad Norm: {config.max_grad_norm}\")\n",
    "                print(f\"{report}\\n Special token predictions: {special_token_predictions}\")\n",
    "                output.write(report)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Loading Training Data\n",
      "Loading NER labels from ./data/ud/UD_English-GUM/**/*-train-orig.ner\n",
      "en_gum-ud-train-orig.ner\n",
      "num sentences: 20\n",
      "Example of NER labels: [[['Aesthetic', 'O'], ['Appreciation', 'O'], ['and', 'O'], ['Spanish', 'S-NORP'], ['Art', 'O'], [':', 'O']], [['Insights', 'O'], ['from', 'O'], ['Eye-Tracking', 'O']]]\n",
      "20 sentences, 10 batches of size 2\n",
      "\n",
      "Control example of InputFeatures\n",
      "Input Ids: [101, 1130, 18883, 1116, 1121, 9329, 118, 6563, 1158, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label Ids: [77, 1, 0, 0, 1, 1, 0, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Valid Ids: [1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Label Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Segment Ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Loading Validation Data\n",
      "Loading NER labels from ./data/ud/UD_English-GUM/**/*-dev-orig.ner\n",
      "en_gum-ud-dev-orig.ner\n",
      "num sentences: 20\n",
      "Example of NER labels: [[['Introduction', 'O']], [['Research', 'O'], ['on', 'O'], ['adult-learned', 'O'], ['second', 'O'], ['language', 'O'], ['(', 'O'], ['L2', 'O'], [')', 'O'], ['has', 'O'], ['provided', 'O'], ['considerable', 'O'], ['insight', 'O'], ['into', 'O'], ['the', 'O'], ['neurocognitive', 'O'], ['mechanisms', 'O'], ['underlying', 'O'], ['the', 'O'], ['learning', 'O'], ['and', 'O'], ['processing', 'O'], ['of', 'O'], ['L2', 'O'], ['grammar', 'O'], ['[', 'O'], ['1', 'S-CARDINAL'], [']–[', 'O'], ['11', 'S-CARDINAL'], [']', 'O'], ['.', 'O']]]\n",
      "20 sentences, 10 batches of size 2\n",
      "\n",
      "Control example of InputFeatures\n",
      "Input Ids: [101, 2713, 1113, 4457, 118, 3560, 1248, 1846, 113, 149, 1477, 114, 1144, 2136, 5602, 14222, 1154, 1103, 24928, 11955, 2528, 22152, 3946, 10748, 10311, 1103, 3776, 1105, 6165, 1104, 149, 1477, 12616, 164, 122, 166, 782, 164, 1429, 166, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label Ids: [77, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 6, 1, 0, 0, 6, 1, 1, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Valid Ids: [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Label Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Segment Ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForNer: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForNer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForNer were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "UnsupportedNodeError",
     "evalue": "GeneratorExp aren't supported:\n  File \"/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 1420\n        activations\".\n        \"\"\"\n        return any(hasattr(m, \"gradient_checkpointing\") and m.gradient_checkpointing for m in self.modules())\n                  ~ <--- HERE\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedNodeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mSynBertForNer(bert_config \u001b[39m=\u001b[39m BERTconfig, num_node_features\u001b[39m=\u001b[39m\u001b[39m768\u001b[39m, num_labels \u001b[39m=\u001b[39m num_ner_labels, num_edge_attrs \u001b[39m=\u001b[39m \u001b[39m54\u001b[39m, num_att_heads \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mnum_att_heads, num_layers \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mnum_layers, label_weights \u001b[39m=\u001b[39m label_weights)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript(models\u001b[39m.\u001b[39;49mBertForNer\u001b[39m.\u001b[39;49mfrom_pretrained(config\u001b[39m.\u001b[39;49msaved_model_path, from_tf \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, config \u001b[39m=\u001b[39;49m BERTconfig))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m device \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Move model to device\u001b[39;00m\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/_script.py:1265\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m   1264\u001b[0m     obj \u001b[39m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1265\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49mcreate_script_module(\n\u001b[1;32m   1266\u001b[0m         obj, torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49minfer_methods_to_compile\n\u001b[1;32m   1267\u001b[0m     )\n\u001b[1;32m   1269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mdict\u001b[39m):\n\u001b[1;32m   1270\u001b[0m     \u001b[39mreturn\u001b[39;00m create_script_dict(obj)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/_recursive.py:454\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    453\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[39m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m create_script_module_impl(nn_module, concrete_type, stubs_fn)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/_recursive.py:467\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    465\u001b[0m cpp_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_create_module_with_type(concrete_type\u001b[39m.\u001b[39mjit_type)\n\u001b[1;32m    466\u001b[0m method_stubs \u001b[39m=\u001b[39m stubs_fn(nn_module)\n\u001b[0;32m--> 467\u001b[0m property_stubs \u001b[39m=\u001b[39m get_property_stubs(nn_module)\n\u001b[1;32m    468\u001b[0m hook_stubs, pre_hook_stubs \u001b[39m=\u001b[39m get_hook_stubs(nn_module)\n\u001b[1;32m    470\u001b[0m user_annotated_ignored_attributes \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(nn_module, \u001b[39m\"\u001b[39m\u001b[39m__jit_ignored_attributes__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlist\u001b[39m())\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/_recursive.py:781\u001b[0m, in \u001b[0;36mget_property_stubs\u001b[0;34m(nn_module)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39mCreate property stubs for the properties of the module by creating method\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[39mstubs for the getter and setter.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    780\u001b[0m module_ty \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(nn_module)\n\u001b[0;32m--> 781\u001b[0m properties_asts \u001b[39m=\u001b[39m get_class_properties(module_ty, self_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRecursiveScriptModule\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    782\u001b[0m rcbs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    784\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(module_ty):\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:161\u001b[0m, in \u001b[0;36mget_class_properties\u001b[0;34m(cls, self_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m prop \u001b[39min\u001b[39;00m props:\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m prop[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m unused_properties \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m should_drop(prop[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mfget):\n\u001b[0;32m--> 161\u001b[0m         getter \u001b[39m=\u001b[39m get_jit_def(prop[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mfget, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m__\u001b[39;49m\u001b[39m{\u001b[39;49;00mprop[\u001b[39m0\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m_getter\u001b[39;49m\u001b[39m\"\u001b[39;49m, self_name\u001b[39m=\u001b[39;49mself_name)\n\u001b[1;32m    162\u001b[0m         setter \u001b[39m=\u001b[39m get_jit_def(prop[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mfset, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m{\u001b[39;00mprop[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_setter\u001b[39m\u001b[39m\"\u001b[39m, self_name\u001b[39m=\u001b[39mself_name) \u001b[39mif\u001b[39;00m prop[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mfset \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         properties\u001b[39m.\u001b[39mappend(Property(getter\u001b[39m.\u001b[39mrange(), Ident(getter\u001b[39m.\u001b[39mrange(), prop[\u001b[39m0\u001b[39m]), getter, setter))\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:264\u001b[0m, in \u001b[0;36mget_jit_def\u001b[0;34m(fn, def_name, self_name, is_classmethod)\u001b[0m\n\u001b[1;32m    261\u001b[0m     qualname \u001b[39m=\u001b[39m get_qualified_name(fn)\n\u001b[1;32m    262\u001b[0m     pdt_arg_types \u001b[39m=\u001b[39m type_trace_db\u001b[39m.\u001b[39mget_args_types(qualname)\n\u001b[0;32m--> 264\u001b[0m \u001b[39mreturn\u001b[39;00m build_def(parsed_def\u001b[39m.\u001b[39;49mctx, fn_def, type_line, def_name, self_name\u001b[39m=\u001b[39;49mself_name, pdt_arg_types\u001b[39m=\u001b[39;49mpdt_arg_types)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:315\u001b[0m, in \u001b[0;36mbuild_def\u001b[0;34m(ctx, py_def, type_line, def_name, self_name, pdt_arg_types)\u001b[0m\n\u001b[1;32m    310\u001b[0m     type_comment_decl \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mparse_type_comment(type_line)\n\u001b[1;32m    311\u001b[0m     decl \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mmerge_type_from_type_comment(decl, type_comment_decl, is_method)\n\u001b[1;32m    313\u001b[0m \u001b[39mreturn\u001b[39;00m Def(Ident(r, def_name),\n\u001b[1;32m    314\u001b[0m            decl,\n\u001b[0;32m--> 315\u001b[0m            build_stmts(ctx, body))\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:137\u001b[0m, in \u001b[0;36mbuild_stmts\u001b[0;34m(ctx, stmts)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_stmts\u001b[39m(ctx, stmts):\n\u001b[0;32m--> 137\u001b[0m     stmts \u001b[39m=\u001b[39m [build_stmt(ctx, s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m stmts]\n\u001b[1;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, stmts))\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:137\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_stmts\u001b[39m(ctx, stmts):\n\u001b[0;32m--> 137\u001b[0m     stmts \u001b[39m=\u001b[39m [build_stmt(ctx, s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m stmts]\n\u001b[1;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, stmts))\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:287\u001b[0m, in \u001b[0;36mBuilder.__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m UnsupportedNodeError(ctx, node)\n\u001b[0;32m--> 287\u001b[0m \u001b[39mreturn\u001b[39;00m method(ctx, node)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:563\u001b[0m, in \u001b[0;36mStmtBuilder.build_Return\u001b[0;34m(ctx, stmt)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_Return\u001b[39m(ctx, stmt):\n\u001b[1;32m    562\u001b[0m     r \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mmake_range(stmt\u001b[39m.\u001b[39mlineno, stmt\u001b[39m.\u001b[39mcol_offset, stmt\u001b[39m.\u001b[39mcol_offset \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m Return(r, \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m stmt\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m build_expr(ctx, stmt\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:287\u001b[0m, in \u001b[0;36mBuilder.__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m UnsupportedNodeError(ctx, node)\n\u001b[0;32m--> 287\u001b[0m \u001b[39mreturn\u001b[39;00m method(ctx, node)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:715\u001b[0m, in \u001b[0;36mExprBuilder.build_Call\u001b[0;34m(ctx, expr)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_Call\u001b[39m(ctx, expr):\n\u001b[1;32m    714\u001b[0m     func \u001b[39m=\u001b[39m build_expr(ctx, expr\u001b[39m.\u001b[39mfunc)\n\u001b[0;32m--> 715\u001b[0m     args \u001b[39m=\u001b[39m [build_expr(ctx, py_arg) \u001b[39mfor\u001b[39;00m py_arg \u001b[39min\u001b[39;00m expr\u001b[39m.\u001b[39margs]\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(expr, \u001b[39m'\u001b[39m\u001b[39mstarargs\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m expr\u001b[39m.\u001b[39mstarargs:\n\u001b[1;32m    717\u001b[0m         stararg_expr \u001b[39m=\u001b[39m build_expr(ctx, expr\u001b[39m.\u001b[39mstarargs)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:715\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_Call\u001b[39m(ctx, expr):\n\u001b[1;32m    714\u001b[0m     func \u001b[39m=\u001b[39m build_expr(ctx, expr\u001b[39m.\u001b[39mfunc)\n\u001b[0;32m--> 715\u001b[0m     args \u001b[39m=\u001b[39m [build_expr(ctx, py_arg) \u001b[39mfor\u001b[39;00m py_arg \u001b[39min\u001b[39;00m expr\u001b[39m.\u001b[39margs]\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(expr, \u001b[39m'\u001b[39m\u001b[39mstarargs\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m expr\u001b[39m.\u001b[39mstarargs:\n\u001b[1;32m    717\u001b[0m         stararg_expr \u001b[39m=\u001b[39m build_expr(ctx, expr\u001b[39m.\u001b[39mstarargs)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/jit/frontend.py:286\u001b[0m, in \u001b[0;36mBuilder.__call__\u001b[0;34m(self, ctx, node)\u001b[0m\n\u001b[1;32m    284\u001b[0m method \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbuild_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     \u001b[39mraise\u001b[39;00m UnsupportedNodeError(ctx, node)\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m method(ctx, node)\n",
      "\u001b[0;31mUnsupportedNodeError\u001b[0m: GeneratorExp aren't supported:\n  File \"/home/shrdlu/cdaniel/venv_syntrans/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 1420\n        activations\".\n        \"\"\"\n        return any(hasattr(m, \"gradient_checkpointing\") and m.gradient_checkpointing for m in self.modules())\n                  ~ <--- HERE\n"
     ]
    }
   ],
   "source": [
    "if (config.train_model):\n",
    "    tokenizer = BertTokenizer.from_pretrained(config.tokenizer)\n",
    "    print(\"Training model\", flush=True)\n",
    "\n",
    "    trainLoader, label_weights = load_train_data(tokenizer)\n",
    "    validationLoader, _ = load_validation_data(tokenizer)\n",
    "    epochs = config.epochs\n",
    "\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        model = BertForMaskedLM.from_pretrained(config.saved_model_path)\n",
    "    if(config.task == 'ner'):\n",
    "        BERTconfig = BertConfig.from_pretrained(config.saved_model_path, num_labels=num_ner_labels, tokenizer = tokenizer)\n",
    "    if (config.use_gnn):\n",
    "        #model = models.SynBertForNer.from_pretrained(config.saved_model_path, num_node_features=1, num_labels = num_ner_labels, num_att_heads = 2, num_layers = 3, from_tf = False, config = BERTconfig, low_cpu_mem_usage=True)\n",
    "        model = models.SynBertForNer(bert_config = BERTconfig, num_node_features=768, num_labels = num_ner_labels, num_edge_attrs = 54, num_att_heads = config.num_att_heads, num_layers = config.num_layers, label_weights = label_weights)\n",
    "    else:\n",
    "        model = models.BertForNer.from_pretrained(config.saved_model_path, from_tf = False, config = BERTconfig)\n",
    "    device =  torch.device('cpu')\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "    from torch.optim.lr_scheduler import LinearLR\n",
    "    # initialize optimizer\n",
    "    optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    # Initialize learning rate scheduler\n",
    "    lr_scheduler = LinearLR(optim, start_factor=1.0, end_factor=0.3, total_iters=5, verbose=True)\n",
    "    train_writer = SummaryWriter(log_dir=tensorboard_dir+\"training\")\n",
    "    validation_writer = SummaryWriter(log_dir=tensorboard_dir+\"validation\")\n",
    "\n",
    "    epoch_losses_train = []\n",
    "    macro_precisions_train = []\n",
    "    macro_recalls_train = []\n",
    "    macro_f1s_train = []\n",
    "    weighted_precisions_train = []\n",
    "    weighted_recalls_train = []\n",
    "    weighted_f1s_train = []\n",
    "\n",
    "    epoch_losses_validation = []\n",
    "    macro_precisions_val = []\n",
    "    macro_recalls_val = []\n",
    "    macro_f1s_val = []\n",
    "    weighted_precisions_val = []\n",
    "    weighted_recalls_val = []\n",
    "    weighted_f1s_val = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #epoch_losses_train.append(trainModel(epoch, trainLoader, train_writer))\n",
    "        #epoch_losses_validation.append(validateModel(epoch, validationLoader, validation_writer))\n",
    "\n",
    "        epoch_loss_train, macro_precision_train, macro_recall_train, macro_f1_train, weighted_precision_train, weighted_recall_train, weighted_f1_train = runModelGNN(data_loader = trainLoader, model = model, device = device, tokenizer = tokenizer, mode = 'Train', writer = train_writer, results_dir = results_dir, epoch=epoch, optimizer=optim)\n",
    "        epoch_losses_train.append(epoch_loss_train)\n",
    "        macro_precisions_train.append(macro_precision_train)\n",
    "        macro_recalls_train.append(macro_recall_train)\n",
    "        macro_f1s_train.append(macro_f1_train)\n",
    "\n",
    "        weighted_precisions_train.append(weighted_precision_train)\n",
    "        weighted_recalls_train.append(weighted_recall_train)\n",
    "        weighted_f1s_train.append(weighted_f1_train)\n",
    "\n",
    "        epoch_loss_val, macro_precision_val, macro_recall_val, macro_f1_val, weighted_precision_val, weighted_recall_val, weighted_f1_val = runModelGNN(data_loader = validationLoader,  tokenizer = tokenizer, model = model, device = device, mode = 'Validation', writer = validation_writer, results_dir = results_dir, epoch=epoch, optimizer=optim)\n",
    "        epoch_losses_validation.append(epoch_loss_val)\n",
    "        macro_precisions_val.append(macro_precision_val)\n",
    "        macro_recalls_val.append(macro_recall_val)\n",
    "        macro_f1s_val.append(macro_f1_val)\n",
    "\n",
    "        weighted_precisions_val.append(weighted_precision_val)\n",
    "        weighted_recalls_val.append(weighted_recall_val)\n",
    "        weighted_f1s_val.append(weighted_f1_val)\n",
    "\n",
    "        # Decrease learning rate\n",
    "        lr_scheduler.step()\n",
    "        if (activeMode == 'prod'):\n",
    "            last_epoch = epoch-1\n",
    "            if last_epoch < 0:\n",
    "                last_epoch = 0\n",
    "            # Save model after each epoch\n",
    "            trained_models_dir = trained_models_dir.replace(f\"_E{last_epoch}_\", f\"_E{epoch}_\")\n",
    "            trained_models_dir = utils.createNumberedDir(trained_models_dir)\n",
    "            model.save_pretrained(save_directory=trained_models_dir)\n",
    "\n",
    "    \n",
    "    train_writer.close()\n",
    "    validation_writer.close()\n",
    "    #prof.stop()\n",
    "    # Save epoch loss plots\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), epoch_losses_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), epoch_losses_validation, 'g', label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/loss.png\", facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), macro_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), macro_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), weighted_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), weighted_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    #  # Save weighted precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save macro precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Precison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_macro.png\", facecolor='white', transparent=False)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model evaluation\\n\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = load_test_data(tokenizer)\n",
    "runModelGNN(data_loader = test_loader, tokenizer = tokenizer, model = model, device = device, mode = 'Test', results_dir=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete created dirs if not used\n",
    "!find tensorboard_dir -type d -empty -delete\n",
    "!find results_dir -type d -empty -delete\n",
    "\n",
    "print(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(references_all, predictions_all, labels=labels)\n",
    "#print(confusion_matrix)\n",
    "#disp = metrics.ConfusionMatrixDisplay(references_all, predictions_all, labels=labels)\n",
    "#disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_syntrans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86a731642ee256d624a4d29e8688bb9c6ad7b39856affb444c6cc9f38126795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
