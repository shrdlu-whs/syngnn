{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "Name: num_sentences, dtype: object\n",
      "Task: ner\n",
      "Model path: bert-base-uncased\n",
      "Data path: ./data/ud/UD_English-GUM/\n",
      "Tokenizer: bert-base-uncased\n",
      "Batch size: 2\n",
      "Epochs: 1\n",
      "Learning rate: 5e-05\n",
      "Sequence length: 96\n",
      "Training: True\n",
      "Num Threads: 4\n",
      "Num Sentences: 4\n",
      "Max Norm: None\n",
      "Use GNN: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import utilities as utils\n",
    "import models as models\n",
    "import os\n",
    "\n",
    "activeMode= \"develop\"\n",
    "\n",
    "# Reload library if changed\n",
    "importlib.reload(utils)\n",
    "# Reload library if changed\n",
    "importlib.reload(models)\n",
    "\n",
    "configuration_csv = pd.read_csv(f\"./config/{activeMode}.csv\", dtype=str, sep=\";\")\n",
    "config = utils.configureParameters(configuration_csv)\n",
    "max_grad_norm_str = str(config.max_grad_norm).replace(\".\",\"-\")\n",
    "print(f\"Task: {config.task}\")\n",
    "print(f\"Model path: {config.saved_model_path}\")\n",
    "print(f\"Data path: {config.data_path}\")\n",
    "print(f\"Tokenizer: {config.tokenizer}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"Sequence length: {config.sequence_length}\")\n",
    "print(f\"Training: {config.train_model}\")\n",
    "print(f\"Num Threads: {config.num_threads}\")\n",
    "print(f\"Num Sentences: {config.num_sentences}\")\n",
    "print(f\"Max Norm: {config.max_grad_norm}\")\n",
    "print(f\"Use GNN: {config.use_gnn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Export env vars to limit number of threads to use\n",
    "num_threads = str(config.num_threads)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = num_threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = num_threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = num_threads\n",
    "\n",
    "# Only use CPU, hide GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForTokenClassification, BertConfig, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Import SummaryWriter for Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "# Load Pytorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.data as tg_data\n",
    "import torch_geometric.loader as tg_loader\n",
    "import torch_geometric.utils as tg_utils\n",
    "import torch_geometric.nn as tg_nn\n",
    "import evaluate\n",
    "# Evaluation metrics for NER task\n",
    "from seqeval.metrics import classification_report\n",
    "# Support for IOBES style NER labels\n",
    "from seqeval.scheme import IOBES\n",
    "import numpy as np\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "# Easy file reading\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 468, PGID: 116\n"
     ]
    }
   ],
   "source": [
    "PID = os.getpid()\n",
    "PGID = os.getpgid(PID)\n",
    "print(f\"PID: {PID}, PGID: {PGID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2f75a59590>"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit no. of threads used by Pytorch\n",
    "torch.set_num_threads = int(num_threads)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_list = ['X','O','<unk>', 'B-CARDINAL', 'E-CARDINAL', 'S-PERSON', 'S-CARDINAL', 'S-PRODUCT', 'B-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'E-WORK_OF_ART', 'B-PERSON', 'E-PERSON', 'S-GPE', 'B-DATE', 'I-DATE', 'E-DATE', 'S-ORDINAL', 'S-LANGUAGE', 'I-PERSON', 'S-EVENT', 'S-DATE', 'B-QUANTITY', 'E-QUANTITY', 'S-TIME', 'B-TIME', 'I-TIME', 'E-TIME', 'B-GPE', 'E-GPE', 'S-ORG', 'I-GPE', 'S-NORP', 'B-FAC', 'I-FAC', 'E-FAC', 'B-NORP', 'E-NORP', 'S-PERCENT', 'B-ORG', 'E-ORG', 'B-LANGUAGE', 'E-LANGUAGE', 'I-CARDINAL', 'I-ORG', 'S-WORK_OF_ART', 'I-QUANTITY', 'B-MONEY', 'I-MONEY', 'E-MONEY', 'B-LOC', 'E-LOC', 'I-LOC', 'B-PERCENT', 'I-PERCENT', 'E-PERCENT', 'S-LOC', 'S-FAC', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'S-MONEY', 'B-LAW', 'I-LAW', 'E-LAW', 'I-NORP', 'I-LANGUAGE', 'S-LAW', 'S-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'E-ORDINAL', '<START>', '<STOP>', \"[CLS]\", \"[SEP]\"]\n",
    "num_ner_labels = len(ner_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train_data = config.data_path + '**/*-train.txt'\n",
    "filepath_validation_data = config.data_path + '**/*-dev.txt'\n",
    "filepath_test_data = config.data_path + '**/*-test.txt'\n",
    "\n",
    "filepath_train_syntrees = config.data_path + f'**/*-train-{config.tokenizer}.syntree'\n",
    "filepath_validation_syntrees = config.data_path + f'**/*-dev-{config.tokenizer}.syntree'\n",
    "filepath_test_syntrees = config.data_path + f'**/*-test-{config.tokenizer}.syntree'\n",
    "\n",
    "filepath_train_ner_labels = config.data_path + f'**/*-train-orig.ner'\n",
    "filepath_validation_ner_labels = config.data_path + f'**/*-dev-orig.ner'\n",
    "filepath_test_ner_labels = config.data_path + f'**/*-test-orig.ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_dir = f\"./runs/{config.task}/{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_GN{max_grad_norm_str}\"\n",
    "tensorboard_dir = utils.createNumberedDir(tensorboard_dir)\n",
    "\n",
    "results_dir = f\"./logs/{config.task}/Results/{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_GN{max_grad_norm_str}\"\n",
    "results_dir = utils.createNumberedDir(results_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ud/UD_English-GUM/**/*-train-bert-base-uncased.syntree\n"
     ]
    }
   ],
   "source": [
    "print(filepath_train_syntrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.tokenizer)\n",
    "if(config.task == 'mlm'):\n",
    "    model = BertForMaskedLM.from_pretrained(config.saved_model_path)\n",
    "if(config.task == 'ner'):\n",
    "    BERTconfig = BertConfig.from_pretrained(config.saved_model_path, num_labels=num_ner_labels, tokenizer = tokenizer)\n",
    "    if (config.use_gnn):\n",
    "        print(num_ner_labels)\n",
    "        #model = models.SynBertForNer.from_pretrained(config.saved_model_path, num_node_features=1, num_labels = num_ner_labels, num_att_heads = 2, num_layers = 3, from_tf = False, config = BERTconfig, low_cpu_mem_usage=True)\n",
    "        model = models.SynBertForNer(bert_config = BERTconfig, num_node_features=768, num_labels = num_ner_labels, num_att_heads = 1, num_layers = 3)\n",
    "    else:\n",
    "        model = models.BertForNer.from_pretrained(config.saved_model_path, from_tf = False, config = BERTconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynBertForNer(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (gnn_layer): SynGNNLayer(\n",
       "    (graph_attn): GATv2Conv(768, 768, heads=1)\n",
       "    (linear1): Linear(768, 768, bias=True)\n",
       "    (linear2): Linear(768, 768, bias=True)\n",
       "    (linear_classifier): Linear(768, 79, bias=True)\n",
       "    (norm0): LayerNorm(768)\n",
       "    (norm1): LayerNorm(768)\n",
       "    (norm2): LayerNorm(768)\n",
       "    (norm3): LayerNorm(79)\n",
       "    (dropout0): Dropout(p=0.1, inplace=False)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (syngnn): SynGNN(\n",
       "    (layers): ModuleList(\n",
       "      (0): SynGNNLayer(\n",
       "        (graph_attn): GATv2Conv(768, 768, heads=1)\n",
       "        (linear1): Linear(768, 768, bias=True)\n",
       "        (linear2): Linear(768, 768, bias=True)\n",
       "        (linear_classifier): Linear(768, 79, bias=True)\n",
       "        (norm0): LayerNorm(768)\n",
       "        (norm1): LayerNorm(768)\n",
       "        (norm2): LayerNorm(768)\n",
       "        (norm3): LayerNorm(79)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): SynGNNLayer(\n",
       "        (graph_attn): GATv2Conv(768, 768, heads=1)\n",
       "        (linear1): Linear(768, 768, bias=True)\n",
       "        (linear2): Linear(768, 768, bias=True)\n",
       "        (linear_classifier): Linear(768, 79, bias=True)\n",
       "        (norm0): LayerNorm(768)\n",
       "        (norm1): LayerNorm(768)\n",
       "        (norm2): LayerNorm(768)\n",
       "        (norm3): LayerNorm(79)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): SynGNNLayer(\n",
       "        (graph_attn): GATv2Conv(768, 768, heads=1)\n",
       "        (linear1): Linear(768, 768, bias=True)\n",
       "        (linear2): Linear(768, 768, bias=True)\n",
       "        (linear_classifier): Linear(768, 79, bias=True)\n",
       "        (norm0): LayerNorm(768)\n",
       "        (norm1): LayerNorm(768)\n",
       "        (norm2): LayerNorm(768)\n",
       "        (norm3): LayerNorm(79)\n",
       "        (dropout0): Dropout(p=0.1, inplace=False)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cpu')\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, valid_ids=None, label_mask=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMaskedInputs(inputs):\n",
    "    \"\"\"\n",
    "    creates masked input embeddings and labels from tokenized text\n",
    "\n",
    "    :param inputs: tokenized text\n",
    "    :return: masked input embeddings and new column labels \n",
    "    \"\"\" \n",
    "    # Clone input ids (tokens) to create labels\n",
    "    inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "    # create random array of floats with equal dimensions to input_ids tensor\n",
    "    rand = torch.rand(inputs.input_ids.shape)\n",
    "    # create mask array with 15% masked tokens\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "    # Select indices of each nonzero (= selected) value as token to be masked\n",
    "    selection = []\n",
    "\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        selection.append(\n",
    "            torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        )\n",
    "    # Mask selected tokens: replace with [MASK] code 103 in tensor\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNERInputFeatures(sentence_labels_list, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a list of sentences into a list of input features for the transformer\n",
    "    \n",
    "        :return: list of inpt features objects\n",
    "    \"\"\"\n",
    "\n",
    "    # Map NER labels to indices\n",
    "    # start with 1: 0 reserved for invalid labels e.g. subtoken labels\n",
    "    label_map = {label : i for i, label in enumerate(label_list,0)}\n",
    "    #label_map['X'] = 0\n",
    "\n",
    "    features = []\n",
    "    for (sentence_idx,sentence_label_pair) in enumerate(sentence_labels_list):\n",
    "        # Tokenized text of sentence\n",
    "        tokens = []\n",
    "        # Token labels for sentence\n",
    "        labels = []\n",
    "        # Lists valid labels as 1 and labels to be ignored as 0 (e.g. for the labels for subword tokens which are not counting as separate labels for each token)\n",
    "        valid = []\n",
    "        # Mask for transformer indicating which tokens to ignore\n",
    "        label_mask = []\n",
    "        for word_label_pair in sentence_label_pair:\n",
    "            token = tokenizer.tokenize(word_label_pair[0])\n",
    "            tokens.extend(token)\n",
    "\n",
    "            label_word = word_label_pair[1]\n",
    "            for token_idx in range(len(token)):\n",
    "                # Append label for first token in word, mark as valid\n",
    "                if token_idx == 0:\n",
    "                    labels.append(label_word)\n",
    "                    valid.append(1)\n",
    "                    label_mask.append(1)\n",
    "                # Subword tokens: Mark as not valid\n",
    "                else:\n",
    "                    labels.append('X')\n",
    "                    valid.append(0)\n",
    "                    label_mask.append(1)\n",
    "        # Sentence exceeds max sequence length: cut to sequence length\n",
    "        if len(tokens) >= max_seq_length - 1:\n",
    "            tokens = tokens[0:(max_seq_length - 2)]\n",
    "            labels = labels[0:(max_seq_length - 2)]\n",
    "            valid = valid[0:(max_seq_length - 2)]\n",
    "            label_mask = label_mask[0:(max_seq_length - 2)]\n",
    "        # Tokens with BERT [CLS] and [SEP] tokens\n",
    "        ntokens = []\n",
    "        # Segment ids for BERT\n",
    "        segment_ids = []\n",
    "        # Label embedding ids for BERT\n",
    "        label_ids = []\n",
    "        # Start segment\n",
    "        ntokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(label_map[\"[CLS]\"])\n",
    "        # Mark as valid label\n",
    "        valid.insert(0,1)\n",
    "        label_mask.insert(0,1)\n",
    "\n",
    "        # add sentence tokens and label ids\n",
    "        for i, token in enumerate(tokens):\n",
    "            ntokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "            if len(labels) > i:\n",
    "                label_ids.append(label_map[labels[i]])\n",
    "        # End segment\n",
    "        ntokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "        valid.append(1)\n",
    "        label_mask.append(1)\n",
    "        label_ids.append(label_map[\"[SEP]\"])\n",
    "\n",
    "        if(sentence_idx<2):\n",
    "            print(ntokens)\n",
    "        # Convert tokens to ids\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Pad sentence to sequence length\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "            label_ids.append(0)\n",
    "            valid.append(1)\n",
    "            label_mask.append(0)\n",
    "\n",
    "        # Pad labels to sequence length\n",
    "        while len(label_ids) < max_seq_length:\n",
    "            label_ids.append(0)\n",
    "            label_mask.append(0)\n",
    "        \n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "        assert len(valid) == max_seq_length\n",
    "        assert len(label_mask) == max_seq_length\n",
    "\n",
    "        # Get syntax graph info\n",
    "        #syntax_graph = syntax_graphs[0][sentence_idx]\n",
    "        #sentence_graph_idx_map = sentence_graph_idx_maps[0][sentence_idx]\n",
    "\n",
    "        \n",
    "\n",
    "        features.append(\n",
    "        InputFeatures(\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        valid_ids=valid,\n",
    "                        label_mask=label_mask,\n",
    "                        #syntax_graph=syntax_graph,\n",
    "                        #sentence_graph_idx_map=sentence_graph_idx_map\n",
    "                        ))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynGNNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, syntax_graphs,sentence_graph_idx_maps):\n",
    "\n",
    "        self.features = features\n",
    "        self.syntax_graphs = syntax_graphs\n",
    "        self.sentence_graph_idx_maps = sentence_graph_idx_maps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.syntax_graphs[idx]\n",
    "        if(self.features is not None):\n",
    "            features = self.features[idx]\n",
    "            return features, data, self.sentence_graph_idx_maps[idx]\n",
    "        else:\n",
    "            return data, self.sentence_graph_idx_maps[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.syntax_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syngnn_data_collate_function(data):\n",
    "\n",
    "    # Get all Bert input feature objects\n",
    "    input_features = list(zip(*data))[0]\n",
    "    # Get all input ids\n",
    "    input_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.input_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all input masks\n",
    "    input_masks = torch.squeeze(torch.tensor(list(map(lambda x:x.input_mask,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all label ids\n",
    "    label_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.label_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all valid ids\n",
    "    valid_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.valid_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all label masks\n",
    "    label_masks = torch.squeeze(torch.tensor(list(map(lambda x:x.label_mask,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all segment ids\n",
    "    segment_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.segment_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all Pytorch Geom Data objects\n",
    "    pyg_data = list(zip(*data))[1]\n",
    "    #pyg_data = tg_data.Batch.from_data_list(pyg_data)\n",
    "\n",
    "    # Get all sentence_graph_idx_maps\n",
    "    sentence_graph_idx_maps = list(zip(*data))[2]\n",
    "\n",
    "\n",
    "    return input_ids, input_masks, label_ids, valid_ids, label_masks, segment_ids, pyg_data, sentence_graph_idx_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ud_tokenizer(tokenizer, tokenizer_name):\n",
    "    tokenizer_path = \"./tokenizers/\" + tokenizer_name \n",
    "    special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "    ]\n",
    "    # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "    vocab_size = 30_522\n",
    "    # Load data\n",
    "    text = []\n",
    "    for ud_file in glob.iglob(config.data_path + '**/UD_English-Pronouns/en_*.txt', recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        tokenizer.train(files=ud_file, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "    # make the directory if not already there\n",
    "    if not os.path.isdir(tokenizer_path):\n",
    "        os.mkdir(tokenizer_path)\n",
    "    # save the tokenizer  \n",
    "    tokenizer.save_model(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSentencesFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of sentences\n",
    "    \"\"\" \n",
    "    sentences = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            sentences.extend(fp.read().split('\\n'))\n",
    "    return sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNERLabelsFromFiles(filepath):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of NER labels per sentence\n",
    "    \"\"\" \n",
    "    all_token_label_pairs = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            # Split labels file by sentences\n",
    "            sentences = (fp.read().split('\\n'))\n",
    "        # Split sentences by tokens\n",
    "        token_labels = [x.split(\"\\t\") for x in sentences]\n",
    "        # Remove empty line at end of sentence\n",
    "        [x.remove('') for x in token_labels] \n",
    "        # Split token and NER tags\n",
    "        token_labels = [list(map(lambda x:x.split(\" \") ,tag_token)) for tag_token in token_labels]\n",
    "        all_token_label_pairs.extend(token_labels)\n",
    "\n",
    "    return all_token_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_syntaxgraphs_from_files(filepath):\n",
    "    r\"\"\"\n",
    "    Load binary syntax tree files (*.syntree).\n",
    "    Args:\n",
    "        filepath: path to files (supports glob regex)\n",
    "        return: list of pytorch geometric syntax graphs per file and list of sentence token to graph node mappings\n",
    "    \"\"\" \n",
    "    all_syntrees = []\n",
    "    all_sentence_to_graph_maps = []\n",
    "    for syntree_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        syntree_file = os.path.abspath(syntree_file)\n",
    "        filename = os.path.basename(syntree_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(syntree_file, 'rb') as fp:\n",
    "            if (config.num_sentences == 0):\n",
    "                file_graphs_and_maps = pd.read_pickle(fp)\n",
    "            else:\n",
    "                file_graphs_and_maps = pd.read_pickle(fp)[0:config.num_sentences]\n",
    "            #print (file_graphs_and_maps)\n",
    "            #print (file_graphs_and_maps)\n",
    "            syntree_list = [graph_map_pair[0] for graph_map_pair in file_graphs_and_maps]\n",
    "            sentence_to_graph_map_list = [graph_map_pair[1] for graph_map_pair in file_graphs_and_maps]\n",
    "            all_syntrees.extend(syntree_list)\n",
    "            all_sentence_to_graph_maps.extend(sentence_to_graph_map_list)\n",
    "    print(all_syntrees[0:2])\n",
    "    print(all_sentence_to_graph_maps[0:2])\n",
    "    return all_syntrees, all_sentence_to_graph_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnn_layer = models.SynGNNLayer(dim_in=1, dim_hdn = 5, dim_out = num_ner_labels, num_heads = 2)\n",
    "#syngnn_model = models.SynGNN(gnn_layer, num_layers = 2)\n",
    "#syngnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "#syntrees_test, sentence_to_graph_maps_test = load_syntaxgraphs_from_files(filepath_test_syntrees)\n",
    "#syntree_dataset = SynGNNDataset(syntrees_test, sentence_to_graph_maps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(syntrees_test[0])\n",
    "#print(sentence_to_graph_maps_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#num_node_features = syntrees_test[1].num_node_features\n",
    "#num_edge_features = syntrees_test[1].num_edge_features\n",
    "#syntree_test_loader = tg_loader.DataLoader(syntrees_test, batch_size=config.batch_size, shuffle=True)\n",
    "#syntree_test_loader = DataLoader(syntree_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=syngnn_data_collate_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model.eval()\\n # setup loop with TQDM and dataloader\\nwith torch.no_grad():\\n    loop = tqdm(syntree_test_loader, leave=True, mininterval=40,maxinterval=120)\\n    for batch in loop:\\n        # pull all tensor batches required for training\\n        if (config.task == 'ner'):\\n            #batch.to(device)\\n            print(batch)\\n            pyg_data, sentence_graph_idx_maps = batch\\n            logits = syngnn_model(pyg_data.x, pyg_data.edge_index, pyg_data.batch)\""
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.eval()\n",
    " # setup loop with TQDM and dataloader\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(syntree_test_loader, leave=True, mininterval=40,maxinterval=120)\n",
    "    for batch in loop:\n",
    "        # pull all tensor batches required for training\n",
    "        if (config.task == 'ner'):\n",
    "            #batch.to(device)\n",
    "            print(batch)\n",
    "            pyg_data, sentence_graph_idx_maps = batch\n",
    "            logits = syngnn_model(pyg_data.x, pyg_data.edge_index, pyg_data.batch)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Print example of tokenized text\\nsentences = []\\nfor ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\\n\\n    ud_file = os.path.abspath(ud_file)\\n    filename = os.path.basename(ud_file)\\n    print(filename, flush = True)\\n    with open(ud_file, 'r') as fp:\\n        sentences.extend(fp.read().split('\\n'))\\ncount = 0\\nfor sentence in sentences:\\n    # Tokenize data\\n    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\\n    inputs = createMaskedInputs(inputs)\\n\\n    # Create dataset from tokenized data\\n    dataset = SyntransDataset(inputs)\\n    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\\n    if(count==1):\\n        print(inputs['input_ids'])\\n        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\\n        print(tokens)\\n        print(inputs['labels'])\\n        break\\n    count=count+1\""
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Print example of tokenized text\n",
    "sentences = []\n",
    "for ud_file in glob.iglob(config.data_path + '**/UD_English-Atiien_*.txt', recursive=True):\n",
    "\n",
    "    ud_file = os.path.abspath(ud_file)\n",
    "    filename = os.path.basename(ud_file)\n",
    "    print(filename, flush = True)\n",
    "    with open(ud_file, 'r') as fp:\n",
    "        sentences.extend(fp.read().split('\\n'))\n",
    "count = 0\n",
    "for sentence in sentences:\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs = createMaskedInputs(inputs)\n",
    "\n",
    "    # Create dataset from tokenized data\n",
    "    dataset = SyntransDataset(inputs)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    if(count==1):\n",
    "        print(inputs['input_ids'])\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        print(tokens)\n",
    "        print(inputs['labels'])\n",
    "        break\n",
    "    count=count+1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxSequenceLength(sentences, cutoff_limit_percent=0.9999):\n",
    "    \"\"\"\n",
    "    Calculate maximum sequence length for given data.\n",
    "    param sentences: list of sentences\n",
    "    param cutoff_limit_percent: percentage of all samples to accommodate with the max sequence length.\n",
    "    returns: max sequence length which encompasses cutoff_limit_percent of all data samples\n",
    "    \"\"\"\n",
    "    # Get number of tokens per sentence        \n",
    "    max_sentence_tokens = 0\n",
    "    sentence_tokens = {}\n",
    "    print(f\"Amount of samples: {len(sentences)}\")\n",
    "    # Tokenize data\n",
    "    for sentence in sentences:\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors='pt')\n",
    "        \n",
    "        token_count = inputs.input_ids.size(dim=1)\n",
    "        sentence_tokens[inputs.input_ids.size(dim=1)] = sentence_tokens.get(token_count,0) + 1\n",
    "        if(token_count > max_sentence_tokens): \n",
    "            max_sentence_tokens = token_count\n",
    "            \n",
    "    no_tokens = 0\n",
    "    # Calulate number of samples which should have a sequence length smaller than max_sequence_length\n",
    "    cutoff = cutoff_limit_percent * len(sentences)\n",
    "    max_sequence_length = 0\n",
    "    print(max_sentence_tokens)\n",
    "    for i in sorted(sentence_tokens):\n",
    "        # print((i, sentence_tokens[i]), end=\" \")\n",
    "        if(no_tokens <= cutoff):\n",
    "            no_tokens = no_tokens + sentence_tokens[i]\n",
    "            max_sequence_length = i\n",
    "\n",
    "    print(f\"Max sequence length: {max_sequence_length} with {cutoff_limit_percent}% of samples smaller\")\n",
    "    return max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataloader(filepath, filepath_syntrees = None, shuffle_data=False):\n",
    "\n",
    "\n",
    "        # Load NER labels\n",
    "        if(config.task == 'ner'):\n",
    "            print(f\"Loading NER labels from {filepath}\")\n",
    "            # Load NER labels\n",
    "            sentence_labels_list = loadNERLabelsFromFiles(filepath)\n",
    "            num_sentences = len(sentence_labels_list)\n",
    "            num_batches = math.ceil(num_sentences / config.batch_size)\n",
    "            print(f\"{num_sentences} sentences, {num_batches} batches of size {config.batch_size}\")\n",
    "            print(f\"Example of NER labels: {sentence_labels_list[0:2]}\")\n",
    "\n",
    "            if (config.num_sentences > 0):\n",
    "                sentence_labels_list = sentence_labels_list[0:config.num_sentences]\n",
    "\n",
    "            features = createNERInputFeatures(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer)\n",
    "            all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "            all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "            all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "            all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "            all_valid_ids = torch.tensor([f.valid_ids for f in features], dtype=torch.long)\n",
    "            all_lmask_ids = torch.tensor([f.label_mask for f in features], dtype=torch.long)\n",
    "            \n",
    "            data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids)\n",
    "            #print(data.__sizeof__())\n",
    "\n",
    "            # Print control example of InputFeatures\n",
    "            print(\"Control example of InputFeatures\")\n",
    "            print(f\"Input Ids: {str(features[1].input_ids)}\")\n",
    "            print(f\"Input Mask: {str(features[1].input_mask)}\")\n",
    "            print(f\"Label Ids: {str(features[1].label_ids)}\")\n",
    "            print(f\"Valid Ids: {str(features[1].valid_ids)}\")\n",
    "            print(f\"Label Mask: {str(features[1].label_mask)}\")\n",
    "            print(f\"Segment Ids: {str(features[1].segment_ids)}\")\n",
    "\n",
    "\n",
    "        if(config.task == 'mlm'):\n",
    "            # Load data\n",
    "            sentences = loadSentencesFromFiles(filepath)\n",
    "            # Tokenize data\n",
    "            inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "            inputs = createMaskedInputs(inputs)\n",
    "\n",
    "            # Create dataset from tokenized data\n",
    "            data = MlmDataset(inputs)\n",
    "        \n",
    "        # Load syntax graphs and create dataset\n",
    "        if(config.use_gnn and filepath_syntrees != None):\n",
    "            syntax_graphs, sentence_to_graph_idx_maps = load_syntaxgraphs_from_files(filepath_syntrees)\n",
    "            syngnn_dataset = SynGNNDataset(features, syntax_graphs, sentence_to_graph_idx_maps)\n",
    "\n",
    "            print(f\"Syngnn dataset size: {syngnn_dataset.__len__()}\")\n",
    "\n",
    "            loader = DataLoader(syngnn_dataset, batch_size=config.batch_size, shuffle=shuffle_data, collate_fn=syngnn_data_collate_function)\n",
    "        else:\n",
    "            loader = DataLoader(data, batch_size=config.batch_size, shuffle=shuffle_data)\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainData():\n",
    "    print(\"Loading Training Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn):\n",
    "            return createDataloader(filepath_train_ner_labels, filepath_train_syntrees, shuffle_data=True)\n",
    "        else:\n",
    "            return createDataloader(filepath_train_ner_labels, shuffle_data=True)\n",
    "    if(config.task == 'mlm'):\n",
    "        if(config.use_gnn):\n",
    "            return createDataloader(filepath_train_data, filepath_train_syntrees, shuffle_data=True)\n",
    "        else:\n",
    "            return createDataloader(filepath_train_data, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadValidationData():\n",
    "    print(\"Loading Validation Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn):\n",
    "            return createDataloader(filepath_validation_ner_labels, filepath_validation_syntrees, shuffle_data=True)\n",
    "        else:\n",
    "            return createDataloader(filepath_validation_ner_labels, shuffle_data=True)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestData():\n",
    "    print(\"Test Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn):\n",
    "            return createDataloader(filepath_test_ner_labels, filepath_test_syntrees, shuffle_data=False)\n",
    "        else:\n",
    "            return createDataloader(filepath_test_ner_labels, shuffle_data=False)\n",
    "    if(config.task == 'mlm'):\n",
    "        return createDataloader(filepath_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(epoch, trainLoader, writer):\n",
    "    # activate training mode\n",
    "    model.train()\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "    # initialize optimizer\n",
    "    optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    epoch_loss = 0\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(trainLoader, leave=True, mininterval=40,maxinterval=120)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        if (config.task == 'ner'):\n",
    "            batch = tuple(t for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "            batch_loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "            batch_loss = loss.item()\n",
    "        if (config.task == 'mlm'):\n",
    "            # pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            # process\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            # extract loss\n",
    "            loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Train Epoch {epoch}')\n",
    "        loop.set_postfix(loss=batch_loss)\n",
    "        epoch_loss = epoch_loss + batch_loss\n",
    "    # Calculate epoch loss\n",
    "    epoch_loss = epoch_loss / len(trainLoader)\n",
    "    # Print info to Tensorboard\n",
    "    writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "    return epoch_loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateModel(epoch, validationLoader, writer):\n",
    "    # activate eval mode\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    # setup loop with TQDM and dataloader\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(validationLoader, leave=True, mininterval=40,maxinterval=120)\n",
    "        for batch in loop:\n",
    "            # pull all tensor batches required for training\n",
    "            if (config.task == 'ner'):\n",
    "                batch = tuple(t for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "                batch_loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "                batch_loss = batch_loss.item()\n",
    "            if (config.task == 'mlm'):\n",
    "                # pull all tensor batches required for training\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                # process\n",
    "                batch_loss, logits = model(input_ids, attention_mask=attention_mask,\n",
    "                                labels=labels)\n",
    "                batch_loss = batch_loss.item()\n",
    "\n",
    "            # print relevant info to progress bar\n",
    "            loop.set_description(f'Validation Epoch {epoch}')\n",
    "\n",
    "            loop.set_postfix(loss=batch_loss)\n",
    "            epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(validationLoader)\n",
    "            #print(epoch_loss)\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "            return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stderr\n",
    "def runModelGNN(data_loader, mode=None, writer = None, results_dir = None,  epoch = None):\n",
    "    if(mode == 'Train'):\n",
    "        model.train()\n",
    "        from torch.optim import AdamW\n",
    "        # initialize optimizer\n",
    "        optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    elif(mode == 'Test' or mode == 'Validation'):\n",
    "        model.eval()\n",
    "    else:\n",
    "        stderr(\"Mode must be Train, Validation or Test\")\n",
    "        exit()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    label_map = {i : label for i, label in enumerate(ner_tags_list,0)}\n",
    "\n",
    "    references_all = []\n",
    "    predictions_all = []\n",
    "    references_roc_all = []\n",
    "    predictions_roc_all = []\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        # Setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        for batch in loop:\n",
    "    \n",
    "            # Pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).tolist()\n",
    "\n",
    "            softmax = nn.Softmax(dim = -1)\n",
    "            if (mode == 'Test' or mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(input_ids)\n",
    "            if(mode == 'Train'):\n",
    "                # initialize calculated gradients (from prev step)\n",
    "                optim.zero_grad()\n",
    "                predictions = model(input_ids)\n",
    "            predictions = predictions['logits']\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Change type to double to prevent floating point rounding errors\n",
    "            predictions = predictions.type(torch.float64)\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Get index of argmax\n",
    "            y = torch.topk(predictions, k=1, dim = 2)[1].squeeze()\n",
    "            y = y.tolist()\n",
    "                \n",
    "            recall_metric = evaluate.load('recall')\n",
    "            precision_metric = evaluate.load('precision')\n",
    "            f1_metric = evaluate.load('f1')\n",
    "            roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "\n",
    "            # Go through all samples in batch and add to computation batch\n",
    "            for idx, pred_batch in enumerate(y):\n",
    "                references_all.extend(labels[idx])\n",
    "                predictions_all.extend(pred_batch)\n",
    "            \n",
    "            # Calculate ROC (TODO)\n",
    "            #for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "            #    predictions_roc_all.extend(pred_batch.tolist())\n",
    "            #    references_roc_all.extend(labels[batch_idx])\n",
    "            #    #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "            #    break\n",
    "            #break\n",
    "\n",
    "        numberOfBatches = len(loop)\n",
    "        # List all possible labels\n",
    "        labels = np.arange(tokenizer.vocab_size)\n",
    "        with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "            print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "            output.write(\"macro averaging\\n\")\n",
    "            output.write(str(recall_metric.compute(references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute(references = references_all, predictions = predictions_all, average = 'macro', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(\"weighted averaging\\n\")\n",
    "            output.write(str(recall_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.close()\n",
    "    \n",
    "    if (config.task == 'ner'):\n",
    "\n",
    "        sep_token_id = int(ner_tags_list.index(\"[SEP]\"))\n",
    "        cls_token_id = int(ner_tags_list.index(\"[CLS]\"))\n",
    "        unk_token_id = int(ner_tags_list.index(\"<unk>\"))\n",
    "        O_token_id = int(ner_tags_list.index(\"O\"))\n",
    "\n",
    "        special_token_predictions = 0\n",
    "        O_token_predictions = 0\n",
    "        ner_token_predictions = 0\n",
    "        epoch_loss = 0\n",
    "        # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        # Loop over all batches\n",
    "        for batch in loop:\n",
    "            batch = tuple(t for t in batch)\n",
    "            if (config.use_gnn):\n",
    "                input_ids, input_mask, label_ids, valid_ids, label_mask, segment_ids, pyg_data, sentence_graph_idx_maps = batch\n",
    "            else:\n",
    "                input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "\n",
    "            if(mode == 'Train'):\n",
    "                # initialize gradients for batch to zero\n",
    "                optim.zero_grad()\n",
    "                if (config.use_gnn):\n",
    "                    loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, attention_mask_label=label_mask,labels=label_ids,valid_ids=valid_ids,syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                else:\n",
    "                    loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids)\n",
    "                # calculate loss for every parameter that needs grad update\n",
    "                loss.backward()\n",
    "                if (config.max_grad_norm):\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                # update parameters\n",
    "                optim.step()\n",
    "            elif(mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    if (config.use_gnn):\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids,syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                    else:\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids)\n",
    "            elif(mode == 'Test'):\n",
    "                if (config.use_gnn):\n",
    "                     logits = model(input_ids=input_ids, token_type_ids=segment_ids,attention_mask=input_masks,valid_ids=valid_ids,attention_mask_label=label_mask, syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                else:\n",
    "                    logits = model(input_ids, segment_ids, input_mask,valid_ids=valid_ids,attention_mask_label=label_mask)\n",
    "\n",
    "            if(mode == 'Validation' or mode == 'Train'):\n",
    "                # print relevant info to progress bar\n",
    "                loop.set_description(f'{mode} Epoch {epoch}')\n",
    "                batch_loss = loss.item()\n",
    "                loop.set_postfix(loss=batch_loss)\n",
    "                epoch_loss = epoch_loss + batch_loss\n",
    "            \n",
    "            #print(f\"Logits{logits}\")\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "\n",
    "            # Get highest NER label prediction for all sentences\n",
    "            #print(f\"Softmax:{softmax(logits)}\")\n",
    "            logits = torch.argmax(softmax(logits),dim=1)\n",
    "            #print(f\"Argmax: {logits}\")\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            input_masks = input_masks.to('cpu').numpy()\n",
    "\n",
    "            # Go through true labels\n",
    "            for label_list_idx, true_sentence_labels in enumerate(label_ids):\n",
    "                y_true_temp = []\n",
    "                y_pred_temp = []\n",
    "\n",
    "                for label_idx, label_id in enumerate(true_sentence_labels):\n",
    "\n",
    "                    # Skip 0 label\n",
    "                    if label_id == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip [CLS] label at sequence beginning\n",
    "                    if label_id == cls_token_id:\n",
    "                        continue\n",
    "\n",
    "                    # Detect [SEP] label at sentence end and ignore [SEP] and all sequence padding\n",
    "                    elif label_id == sep_token_id:\n",
    "                        y_true.append(y_true_temp)\n",
    "                        y_pred.append(y_pred_temp)\n",
    "                        break\n",
    "                    else:\n",
    "                        # Predicted NER label is special token: count preds\n",
    "                        #if (logits[label_list_idx][label_idx] == 0):\n",
    "                        if (logits[label_list_idx] == 0):\n",
    "                            special_token_predictions = special_token_predictions +1\n",
    "                        # Predicted NER label is O: count preds\n",
    "                        #elif (logits[label_list_idx][label_idx] == O_token_id):\n",
    "                        elif (logits[label_list_idx] == O_token_id):\n",
    "                            O_token_predictions = O_token_predictions +1\n",
    "                        else:\n",
    "                            ner_token_predictions = ner_token_predictions +1\n",
    "\n",
    "                        # Append label and prediction to list\n",
    "                        y_true_temp.append(label_map[label_id])\n",
    "                        #y_pred_temp.append(label_map[logits[label_list_idx][label_idx]])\n",
    "                        y_pred_temp.append(label_map[logits[label_list_idx]])\n",
    "\n",
    "        if (mode == 'Train' or mode == 'Validation'):\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=True, zero_division = 0)\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(data_loader)\n",
    "\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "            macro_precision = report['macro avg']['precision']\n",
    "            writer.add_scalar(\"macro_avg/precision\", macro_precision, epoch)\n",
    "            macro_recall = report['macro avg']['recall']\n",
    "            writer.add_scalar(\"macro_avg/recall\", macro_recall, epoch)\n",
    "            macro_f1 = report['macro avg']['f1-score']\n",
    "            writer.add_scalar(\"macro_avg/f1\", macro_f1, epoch)\n",
    "\n",
    "            weighted_precision = report['weighted avg']['precision']\n",
    "            writer.add_scalar(\"weighted_avg/precision\", weighted_precision, epoch)\n",
    "            weighted_recall = report['weighted avg']['recall']\n",
    "            writer.add_scalar(\"weighted_avg/recall\", weighted_recall, epoch)\n",
    "            weighted_f1 = report['weighted avg']['f1-score']\n",
    "            writer.add_scalar(\"weighted_avg/f1\", weighted_f1, epoch)\n",
    "            print(f\"O Token Predictions: {O_token_predictions}, NER token predictions: {ner_token_predictions}\")\n",
    "            print(f\"loss: {epoch_loss} w prec: {weighted_precision} w recall: {weighted_recall} w f1: {weighted_f1}\")\n",
    "            return epoch_loss, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1\n",
    "\n",
    "        else:\n",
    "            print(y_true)\n",
    "            print(y_pred)\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=False)\n",
    "            with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "                print(\"***** Test results *****\")\n",
    "                print(f\"Task: {config.task}\")\n",
    "                print(f\"Model path: {config.saved_model_path}\")\n",
    "                print(f\"Data path: {config.data_path}\")\n",
    "                print(f\"Tokenizer: {config.tokenizer}\")\n",
    "                print(f\"Batch size: {config.batch_size}\")\n",
    "                print(f\"Epochs: {config.epochs}\")\n",
    "                print(f\"Learning rate: {config.learning_rate}\")\n",
    "                print(f\"Sequence length: {config.sequence_length}\")\n",
    "                print(f\"Training: {config.train_model}\")\n",
    "                print(f\"Num Threads: {config.num_threads}\")\n",
    "                print(f\"Num Sentences: {config.num_sentences}\")\n",
    "                print(f\"Max Grad Norm: {config.max_grad_norm}\")\n",
    "                print(f\"{report}\\n Special token predictions: {special_token_predictions}\")\n",
    "                output.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stderr\n",
    "def evaluateModel(data_loader, mode=None, writer = None, results_dir = None,  epoch = None):\n",
    "    if(mode == 'Train'):\n",
    "        model.train()\n",
    "        from torch.optim import AdamW\n",
    "        # initialize optimizer\n",
    "        optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    elif(mode == 'Test' or mode == 'Validation'):\n",
    "        model.eval()\n",
    "    else:\n",
    "        stderr(\"Mode must be Train, Validation or Test\")\n",
    "        exit()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    label_map = {i : label for i, label in enumerate(ner_tags_list,0)}\n",
    "\n",
    "    references_all = []\n",
    "    predictions_all = []\n",
    "    references_roc_all = []\n",
    "    predictions_roc_all = []\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        # Setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        for batch in loop:\n",
    "    \n",
    "            # Pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).tolist()\n",
    "\n",
    "            softmax = nn.Softmax(dim = -1)\n",
    "            if (mode == 'Test' or mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(input_ids)\n",
    "            if(mode == 'Train'):\n",
    "                # initialize calculated gradients (from prev step)\n",
    "                optim.zero_grad()\n",
    "                predictions = model(input_ids)\n",
    "            predictions = predictions['logits']\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Change type to double to prevent floating point rounding errors\n",
    "            predictions = predictions.type(torch.float64)\n",
    "            predictions_sm = softmax(predictions)\n",
    "\n",
    "            # Get index of argmax\n",
    "            #y = np.argmax(predictions_sm, axis = -1)\n",
    "            # y = y.tolist()\n",
    "            y = torch.topk(predictions, k=1, dim = 2)[1].squeeze()\n",
    "            y = y.tolist()\n",
    "                \n",
    "\n",
    "            recall_metric = evaluate.load('recall')\n",
    "            precision_metric = evaluate.load('precision')\n",
    "            f1_metric = evaluate.load('f1')\n",
    "            roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "\n",
    "            # Go through all samples in batch and add to computation batch\n",
    "            for idx, pred_batch in enumerate(y):\n",
    "                references_all.extend(labels[idx])\n",
    "                predictions_all.extend(pred_batch)\n",
    "                #precision_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "                #recall_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "                #f1_metric.add_batch(references=labels[idx], predictions=pred_batch)\n",
    "            \n",
    "            # Calculate ROC\n",
    "            for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "                predictions_roc_all.extend(pred_batch.tolist())\n",
    "                references_roc_all.extend(labels[batch_idx])\n",
    "                #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "                break\n",
    "            break\n",
    "\n",
    "        numberOfBatches = len(loop)\n",
    "        # List all possible labels\n",
    "        labels = np.arange(tokenizer.vocab_size)\n",
    "        with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "            print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "            output.write(\"macro averaging\\n\")\n",
    "            output.write(str(recall_metric.compute(references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute(references = references_all, predictions = predictions_all, average = 'macro', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(\"weighted averaging\\n\")\n",
    "            output.write(str(recall_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = references_all, predictions = predictions_all, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.close()\n",
    "    \n",
    "    if (config.task == 'ner'):\n",
    "\n",
    "        sep_token_id = int(ner_tags_list.index(\"[SEP]\"))\n",
    "        cls_token_id = int(ner_tags_list.index(\"[CLS]\"))\n",
    "        unk_token_id = int(ner_tags_list.index(\"<unk>\"))\n",
    "        O_token_id = int(ner_tags_list.index(\"O\"))\n",
    "\n",
    "        special_token_predictions = 0\n",
    "        O_token_predictions = 0\n",
    "        ner_token_predictions = 0\n",
    "        epoch_loss = 0\n",
    "        # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, mininterval=20,maxinterval=120)\n",
    "        # Loop over all batches\n",
    "        for batch in loop:\n",
    "            batch = tuple(t for t in batch)\n",
    "            if (config.use_gnn):\n",
    "                input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask, syntax_graphs, sentence_graph_idx_maps = batch\n",
    "\n",
    "            else:\n",
    "                input_ids, input_mask, segment_ids, label_ids, valid_ids,l_mask = batch\n",
    "\n",
    "            \n",
    "\n",
    "            if(mode == 'Train'):\n",
    "                # initialize calculated gradients (from prev step)\n",
    "                optim.zero_grad()\n",
    "                loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "                # calculate loss for every parameter that needs grad update\n",
    "                loss.backward()\n",
    "                if (config.max_grad_norm):\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                # update parameters\n",
    "                optim.step()\n",
    "            elif(mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    loss, logits = model(input_ids, segment_ids, input_mask, label_ids,valid_ids,l_mask)\n",
    "            elif(mode == 'Test'):\n",
    "                if (config.use_gnn):\n",
    "                     logits = model(input_ids=input_ids, token_type_ids=segment_ids,attention_mask=input_mask,valid_ids=valid_ids,attention_mask_label=l_mask, syntax_graphs=syntax_graphs, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                else:\n",
    "                    logits = model(input_ids, segment_ids, input_mask,valid_ids=valid_ids,attention_mask_label=l_mask)\n",
    "\n",
    "            if(mode == 'Validation' or mode == 'Train'):\n",
    "                # print relevant info to progress bar\n",
    "                loop.set_description(f'{mode} Epoch {epoch}')\n",
    "                batch_loss = loss.item()\n",
    "                loop.set_postfix(loss=batch_loss)\n",
    "                epoch_loss = epoch_loss + batch_loss\n",
    "            \n",
    "            #print(f\"Logits{logits}\")\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "\n",
    "            # Get highest NER label prediction for all sentences\n",
    "            #print(f\"Softmax:{softmax(logits)}\")\n",
    "            logits = torch.argmax(softmax(logits),dim=1)\n",
    "            #print(f\"Argmax: {logits}\")\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            input_masks = input_masks.to('cpu').numpy()\n",
    "\n",
    "            # Go through true labels\n",
    "            for label_list_idx, true_sentence_labels in enumerate(label_ids):\n",
    "                y_true_temp = []\n",
    "                y_pred_temp = []\n",
    "\n",
    "                for label_idx, label_id in enumerate(true_sentence_labels):\n",
    "\n",
    "                    # Skip 0 label\n",
    "                    if label_id == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip [CLS] label at sequence beginning\n",
    "                    if label_id == cls_token_id:\n",
    "                        continue\n",
    "\n",
    "                    # Detect [SEP] label at sentence end and ignore [SEP] and all sequence padding\n",
    "                    elif label_id == sep_token_id:\n",
    "                        y_true.append(y_true_temp)\n",
    "                        y_pred.append(y_pred_temp)\n",
    "                        break\n",
    "                    else:\n",
    "                        # Predicted NER label is special token: count preds\n",
    "                        if (logits[label_list_idx][label_idx] == 0):\n",
    "                            special_token_predictions = special_token_predictions +1\n",
    "                        # Predicted NER label is O: count preds\n",
    "                        elif (logits[label_list_idx][label_idx] == O_token_id):\n",
    "                            O_token_predictions = O_token_predictions +1\n",
    "                        else:\n",
    "                            ner_token_predictions = ner_token_predictions +1\n",
    "\n",
    "                        # Append label and prediction to list\n",
    "                        y_true_temp.append(label_map[label_id])\n",
    "                        y_pred_temp.append(label_map[logits[label_list_idx][label_idx]])\n",
    "\n",
    "        if (mode == 'Train' or mode == 'Validation'):\n",
    "            print(f\"True: {y_true[0:1]}, Predicted: {y_pred[0:1]}\")\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=True, zero_division = 0)\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(data_loader)\n",
    "\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "            macro_precision = report['macro avg']['precision']\n",
    "            writer.add_scalar(\"macro_avg/precision\", macro_precision, epoch)\n",
    "            macro_recall = report['macro avg']['recall']\n",
    "            writer.add_scalar(\"macro_avg/recall\", macro_recall, epoch)\n",
    "            macro_f1 = report['macro avg']['f1-score']\n",
    "            writer.add_scalar(\"macro_avg/f1\", macro_f1, epoch)\n",
    "\n",
    "            weighted_precision = report['weighted avg']['precision']\n",
    "            writer.add_scalar(\"weighted_avg/precision\", weighted_precision, epoch)\n",
    "            weighted_recall = report['weighted avg']['recall']\n",
    "            writer.add_scalar(\"weighted_avg/recall\", weighted_recall, epoch)\n",
    "            weighted_f1 = report['weighted avg']['f1-score']\n",
    "            writer.add_scalar(\"weighted_avg/f1\", weighted_f1, epoch)\n",
    "            print(f\"O Token Predictions: {O_token_predictions}, NER token predictions: {ner_token_predictions}\")\n",
    "            print(f\"loss: {epoch_loss} w prec: {weighted_precision} w recall: {weighted_recall} w f1: {weighted_f1}\")\n",
    "            return epoch_loss, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1\n",
    "\n",
    "        else:\n",
    "\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=False)\n",
    "            with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "                print(\"***** Test results *****\")\n",
    "                print(f\"Task: {config.task}\")\n",
    "                print(f\"Model path: {config.saved_model_path}\")\n",
    "                print(f\"Data path: {config.data_path}\")\n",
    "                print(f\"Tokenizer: {config.tokenizer}\")\n",
    "                print(f\"Batch size: {config.batch_size}\")\n",
    "                print(f\"Epochs: {config.epochs}\")\n",
    "                print(f\"Learning rate: {config.learning_rate}\")\n",
    "                print(f\"Sequence length: {config.sequence_length}\")\n",
    "                print(f\"Training: {config.train_model}\")\n",
    "                print(f\"Num Threads: {config.num_threads}\")\n",
    "                print(f\"Num Sentences: {config.num_sentences}\")\n",
    "                print(f\"Max Grad Norm: {config.max_grad_norm}\")\n",
    "                print(f\"{report}\\n Special token predictions: {special_token_predictions}\")\n",
    "                output.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Loading Training Data\n",
      "Loading NER labels from ./data/ud/UD_English-GUM/**/*-train-orig.ner\n",
      "en_gum-ud-train-orig.ner\n",
      "5661 sentences, 2831 batches of size 2\n",
      "Example of NER labels: [[['Aesthetic', 'O'], ['Appreciation', 'O'], ['and', 'O'], ['Spanish', 'S-NORP'], ['Art', 'O'], [':', 'O']], [['Insights', 'O'], ['from', 'O'], ['Eye-Tracking', 'O']]]\n",
      "['[CLS]', 'aesthetic', 'appreciation', 'and', 'spanish', 'art', ':', '[SEP]']\n",
      "['[CLS]', 'insights', 'from', 'eye', '-', 'tracking', '[SEP]']\n",
      "Control example of InputFeatures\n",
      "Input Ids: [101, 20062, 2013, 3239, 1011, 9651, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input Mask: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label Ids: [77, 1, 1, 1, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Valid Ids: [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Label Mask: ([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],)\n",
      "Segment Ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "en_gum-ud-train-bert-base-uncased.syntree\n",
      "[Data(x=[7, 768], edge_index=[2, 12], edge_attr=[12, 53]), Data(x=[6, 768], edge_index=[2, 10], edge_attr=[6, 53])]\n",
      "[{1: 2, 2: 1, 3: 4, 4: 5, 5: 3, 6: 6}, {1: 1, 2: 3, 3: 2, 4: 4, 5: 5}]\n",
      "Syngnn dataset size: 4\n",
      "Loading Validation Data\n",
      "Loading NER labels from ./data/ud/UD_English-GUM/**/*-dev-orig.ner\n",
      "en_gum-ud-dev-orig.ner\n",
      "844 sentences, 422 batches of size 2\n",
      "Example of NER labels: [[['Introduction', 'O']], [['Research', 'O'], ['on', 'O'], ['adult-learned', 'O'], ['second', 'O'], ['language', 'O'], ['(', 'O'], ['L2', 'O'], [')', 'O'], ['has', 'O'], ['provided', 'O'], ['considerable', 'O'], ['insight', 'O'], ['into', 'O'], ['the', 'O'], ['neurocognitive', 'O'], ['mechanisms', 'O'], ['underlying', 'O'], ['the', 'O'], ['learning', 'O'], ['and', 'O'], ['processing', 'O'], ['of', 'O'], ['L2', 'O'], ['grammar', 'O'], ['[', 'O'], ['1', 'S-CARDINAL'], ['][', 'O'], ['11', 'S-CARDINAL'], [']', 'O'], ['.', 'O']]]\n",
      "['[CLS]', 'introduction', '[SEP]']\n",
      "['[CLS]', 'research', 'on', 'adult', '-', 'learned', 'second', 'language', '(', 'l', '##2', ')', 'has', 'provided', 'considerable', 'insight', 'into', 'the', 'ne', '##uro', '##co', '##gni', '##tive', 'mechanisms', 'underlying', 'the', 'learning', 'and', 'processing', 'of', 'l', '##2', 'grammar', '[', '1', ']', '', '[', '11', ']', '.', '[SEP]']\n",
      "Control example of InputFeatures\n",
      "Input Ids: [101, 2470, 2006, 4639, 1011, 4342, 2117, 2653, 1006, 1048, 2475, 1007, 2038, 3024, 6196, 12369, 2046, 1996, 11265, 10976, 3597, 29076, 6024, 10595, 10318, 1996, 4083, 1998, 6364, 1997, 1048, 2475, 8035, 1031, 1015, 1033, 1516, 1031, 2340, 1033, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label Ids: [77, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 6, 1, 0, 0, 6, 1, 1, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Valid Ids: [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Label Mask: ([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],)\n",
      "Segment Ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "en_gum-ud-dev-bert-base-uncased.syntree\n",
      "[Data(x=[2, 768], edge_index=[2, 2], edge_attr=[2, 53]), Data(x=[41, 768], edge_index=[2, 80], edge_attr=[68, 53])]\n",
      "[{}, {1: 2, 2: 4, 3: 6, 4: 7, 5: 5, 6: 8, 7: 3, 8: 10, 9: 9, 10: 35, 11: 11, 12: 12, 13: 1, 14: 14, 15: 13, 16: 16, 17: 17, 18: 18, 19: 36, 20: 37, 21: 38, 22: 39, 23: 15, 24: 19, 25: 21, 26: 20, 27: 23, 28: 22, 29: 25, 30: 26, 31: 40, 32: 24, 33: 28, 34: 27, 35: 29, 36: 31, 37: 32, 38: 30, 39: 33, 40: 34}]\n",
      "Syngnn dataset size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/home/shrdlu/cdaniel/syntrans/models.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ptg_graph.x[graph_idx] = torch.tensor(embedding,dtype=torch.float32)\n",
      "/home/shrdlu/cdaniel/syntrans/models.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  logits, attn = self.syngnn(torch.tensor(pyg_data_batch.x,dtype=torch.float), pyg_data_batch.edge_index, pyg_data_batch.batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([29, 768])\n",
      "Graph Att Output src2: torch.Size([29, 768])\n",
      " After linear layer 2: torch.Size([29, 768])\n",
      " After linear output layer: torch.Size([29, 79])\n",
      "Input: torch.Size([29, 768])\n",
      "Graph Att Output src2: torch.Size([29, 768])\n",
      " After linear layer 2: torch.Size([29, 768])\n",
      " After linear output layer: torch.Size([29, 79])\n",
      "Input: torch.Size([29, 768])\n",
      "Graph Att Output src2: torch.Size([29, 768])\n",
      " After linear layer 2: torch.Size([29, 768])\n",
      " After linear output layer: torch.Size([29, 79])\n",
      "Logits:\n",
      "torch.Size([29, 79])\n",
      "torch.Size([29, 79])\n",
      "Labels:\n",
      "torch.Size([2, 96])\n",
      "torch.Size([192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [192] at index 0 does not match the shape of the indexed tensor [29, 79] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m weighted_f1s_val \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m#epoch_losses_train.append(trainModel(epoch, trainLoader, train_writer))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m#epoch_losses_validation.append(validateModel(epoch, validationLoader, validation_writer))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     epoch_loss_train, macro_precision_train, macro_recall_train, macro_f1_train, weighted_precision_train, weighted_recall_train, weighted_f1_train \u001b[39m=\u001b[39m runModelGNN(trainLoader, mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mTrain\u001b[39;49m\u001b[39m'\u001b[39;49m, writer \u001b[39m=\u001b[39;49m train_writer, results_dir \u001b[39m=\u001b[39;49m results_dir, epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     epoch_losses_train\u001b[39m.\u001b[39mappend(epoch_loss_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     macro_precisions_train\u001b[39m.\u001b[39mappend(macro_precision_train)\n",
      "\u001b[1;32m/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb Cell 37\u001b[0m in \u001b[0;36mrunModelGNN\u001b[0;34m(data_loader, mode, writer, results_dir, epoch)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=119'>120</a>\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39mif\u001b[39;00m (config\u001b[39m.\u001b[39muse_gnn):\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=121'>122</a>\u001b[0m     loss, logits \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49minput_ids, token_type_ids\u001b[39m=\u001b[39;49msegment_ids, attention_mask\u001b[39m=\u001b[39;49minput_mask, attention_mask_label\u001b[39m=\u001b[39;49mlabel_mask,labels\u001b[39m=\u001b[39;49mlabel_ids,valid_ids\u001b[39m=\u001b[39;49mvalid_ids,syntax_graphs\u001b[39m=\u001b[39;49mpyg_data, sentence_graph_idx_maps\u001b[39m=\u001b[39;49msentence_graph_idx_maps)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shrdlu/cdaniel/syntrans/syngnn_main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=123'>124</a>\u001b[0m     loss, logits \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39minput_ids, token_type_ids\u001b[39m=\u001b[39msegment_ids, attention_mask\u001b[39m=\u001b[39minput_mask, attention_mask_label\u001b[39m=\u001b[39mlabel_mask,label_ids\u001b[39m=\u001b[39mlabel_ids,valid_ids\u001b[39m=\u001b[39mvalid_ids)\n",
      "File \u001b[0;32m~/cdaniel/venv_syntrans/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cdaniel/syntrans/models.py:235\u001b[0m, in \u001b[0;36mSynBertForNer.forward\u001b[0;34m(self, input_ids, syntax_graphs, sentence_graph_idx_maps, token_type_ids, attention_mask, labels, valid_ids, attention_mask_label)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m attention_mask_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m        active_loss \u001b[39m=\u001b[39m attention_mask_label\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 235\u001b[0m        active_logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_labels)[active_loss]\n\u001b[1;32m    236\u001b[0m        active_labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[active_loss]\n\u001b[1;32m    237\u001b[0m        loss \u001b[39m=\u001b[39m loss_fct(active_logits, active_labels)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [192] at index 0 does not match the shape of the indexed tensor [29, 79] at index 0"
     ]
    }
   ],
   "source": [
    "if (config.train_model):\n",
    "    print(\"Training model\", flush=True)\n",
    "\n",
    "    trainLoader = loadTrainData()\n",
    "    validationLoader = loadValidationData()\n",
    "\n",
    "    epochs = config.epochs\n",
    "\n",
    "    train_writer = SummaryWriter(log_dir=tensorboard_dir+\"training\")\n",
    "    validation_writer = SummaryWriter(log_dir=tensorboard_dir+\"validation\")\n",
    "\n",
    "    epoch_losses_train = []\n",
    "    macro_precisions_train = []\n",
    "    macro_recalls_train = []\n",
    "    macro_f1s_train = []\n",
    "    weighted_precisions_train = []\n",
    "    weighted_recalls_train = []\n",
    "    weighted_f1s_train = []\n",
    "\n",
    "    epoch_losses_validation = []\n",
    "    macro_precisions_val = []\n",
    "    macro_recalls_val = []\n",
    "    macro_f1s_val = []\n",
    "    weighted_precisions_val = []\n",
    "    weighted_recalls_val = []\n",
    "    weighted_f1s_val = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #epoch_losses_train.append(trainModel(epoch, trainLoader, train_writer))\n",
    "        #epoch_losses_validation.append(validateModel(epoch, validationLoader, validation_writer))\n",
    "\n",
    "        epoch_loss_train, macro_precision_train, macro_recall_train, macro_f1_train, weighted_precision_train, weighted_recall_train, weighted_f1_train = runModelGNN(trainLoader, mode = 'Train', writer = train_writer, results_dir = results_dir, epoch=epoch)\n",
    "        epoch_losses_train.append(epoch_loss_train)\n",
    "        macro_precisions_train.append(macro_precision_train)\n",
    "        macro_recalls_train.append(macro_recall_train)\n",
    "        macro_f1s_train.append(macro_f1_train)\n",
    "\n",
    "        weighted_precisions_train.append(weighted_precision_train)\n",
    "        weighted_recalls_train.append(weighted_recall_train)\n",
    "        weighted_f1s_train.append(weighted_f1_train)\n",
    "\n",
    "        epoch_loss_val, macro_precision_val, macro_recall_val, macro_f1_val, weighted_precision_val, weighted_recall_val, weighted_f1_val = evaluateModel(validationLoader, mode = 'Validation', writer = validation_writer, results_dir = results_dir, epoch=epoch)\n",
    "        epoch_losses_validation.append(epoch_loss_val)\n",
    "        macro_precisions_val.append(macro_precision_val)\n",
    "        macro_recalls_val.append(macro_recall_val)\n",
    "        macro_f1s_val.append(macro_f1_val)\n",
    "\n",
    "        weighted_precisions_val.append(weighted_precision_val)\n",
    "        weighted_recalls_val.append(weighted_recall_val)\n",
    "        weighted_f1s_val.append(weighted_f1_val)\n",
    "\n",
    "\n",
    "        if (activeMode == 'prod'):\n",
    "            trained_models_dir = f\"./trained_models/{config.task}/{config.task}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_GN{max_grad_norm_str}\"\n",
    "            trained_models_dir = utils.createNumberedDir(trained_models_dir)\n",
    "            # Save model after each epoch\n",
    "            model.save_pretrained(save_directory=trained_models_dir)\n",
    "    \n",
    "    train_writer.close()\n",
    "    validation_writer.close()\n",
    "    # Save epoch loss plots\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), epoch_losses_train, 'b', label='Training loss')\n",
    "    plt.plot(range(0,epochs), epoch_losses_validation, 'g', label='Validation loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/loss.png\", facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), macro_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), macro_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), weighted_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), weighted_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    #  # Save weighted precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "\n",
    "    # # Save macro precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Precison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_macro.png\", facecolor='white', transparent=False)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model evaluation\\n\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = loadTestData()\n",
    "evaluateModelGNN(test_loader, mode = 'Test', results_dir=results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(references_all, predictions_all, labels=labels)\n",
    "#print(confusion_matrix)\n",
    "#disp = metrics.ConfusionMatrixDisplay(references_all, predictions_all, labels=labels)\n",
    "#disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_syntrans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86a731642ee256d624a4d29e8688bb9c6ad7b39856affb444c6cc9f38126795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
