{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import utilities as utils\n",
    "\n",
    "\n",
    "activeMode= \"develop\"\n",
    "\n",
    "# Reload utils library if changed\n",
    "importlib.reload(utils)\n",
    "\n",
    "configuration_csv = pd.read_csv(f\"./config/{activeMode}.csv\", dtype=str, sep=\";\")\n",
    "config = utils.configureParameters(configuration_csv)\n",
    "max_grad_norm_str = str(config.max_grad_norm).replace(\".\",\"-\")\n",
    "print(f\"Task: {config.task}\")\n",
    "print(f\"Model path: {config.saved_model_path}\")\n",
    "print(f\"Data path: {config.data_path}\")\n",
    "print(f\"Tokenizer: {config.tokenizer}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Trained epochs: {config.trained_epochs}\")\n",
    "print(f\"Learning rate: {config.learning_rate}\")\n",
    "print(f\"LR Decay: {config.lr_decay}\")\n",
    "print(f\"LR Decay End Epoch: {config.lr_decay_end}\")\n",
    "print(f\"Sequence length: {config.sequence_length}\")\n",
    "print(f\"Training: {config.train_model}\")\n",
    "print(f\"Num Threads: {config.num_threads}\")\n",
    "print(f\"Num Sentences: {config.num_sentences}\")\n",
    "print(f\"Max Norm: {config.max_grad_norm}\")\n",
    "print(f\"Use GNN: {config.use_gnn}\")\n",
    "if(config.use_gnn == True):\n",
    "    print(f\"Num layers: {config.num_layers}\")\n",
    "    print(f\"Num attention heads: {config.num_att_heads}\")\n",
    "    print(f\"Syntax tree style: {config.use_grammar}\")\n",
    "print(f\"Use label weights: {config.use_label_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Export env vars to limit number of threads to use\n",
    "num_threads = str(config.num_threads)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = num_threads \n",
    "os.environ[\"MKL_NUM_THREADS\"] = num_threads \n",
    "\n",
    "# Only use CPU, hide GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models as models\n",
    "# Reload models if changed\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForTokenClassification, BertConfig, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Import SummaryWriter for Tensorboard logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import (DataLoader, TensorDataset)\n",
    "# Load Pytorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.data as tg_data\n",
    "import torch_geometric.loader as tg_loader\n",
    "import torch_geometric.utils as tg_utils\n",
    "import torch_geometric.nn as tg_nn\n",
    "import torch.profiler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import evaluate\n",
    "# Evaluation metrics for NER task\n",
    "from seqeval.metrics import classification_report\n",
    "# Support for IOBES style NER labels\n",
    "from seqeval.scheme import IOBES\n",
    "import numpy as np\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "# Easy file reading\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID = os.getpid()\n",
    "PGID = os.getpgid(PID)\n",
    "print(f\"PID: {PID}, PGID: {PGID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit no. of threads used by Pytorch\n",
    "torch.set_num_threads = int(num_threads)\n",
    "torch.set_num_interop_threads = int(num_threads)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__config__.parallel_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_list = ['X','O','<unk>', 'B-CARDINAL', 'E-CARDINAL', 'S-PERSON', 'S-CARDINAL', 'S-PRODUCT', 'B-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'E-WORK_OF_ART', 'B-PERSON', 'E-PERSON', 'S-GPE', 'B-DATE', 'I-DATE', 'E-DATE', 'S-ORDINAL', 'S-LANGUAGE', 'I-PERSON', 'S-EVENT', 'S-DATE', 'B-QUANTITY', 'E-QUANTITY', 'S-TIME', 'B-TIME', 'I-TIME', 'E-TIME', 'B-GPE', 'E-GPE', 'S-ORG', 'I-GPE', 'S-NORP', 'B-FAC', 'I-FAC', 'E-FAC', 'B-NORP', 'E-NORP', 'S-PERCENT', 'B-ORG', 'E-ORG', 'B-LANGUAGE', 'E-LANGUAGE', 'I-CARDINAL', 'I-ORG', 'S-WORK_OF_ART', 'I-QUANTITY', 'B-MONEY', 'I-MONEY', 'E-MONEY', 'B-LOC', 'E-LOC', 'I-LOC', 'B-PERCENT', 'I-PERCENT', 'E-PERCENT', 'S-LOC', 'S-FAC', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'S-MONEY', 'B-LAW', 'I-LAW', 'E-LAW', 'I-NORP', 'I-LANGUAGE', 'S-LAW', 'S-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'E-ORDINAL', '<START>', '<STOP>', \"[CLS]\", \"[SEP]\"]\n",
    "num_ner_labels = len(ner_tags_list)\n",
    "num_mlm_labels = 30522 # Bert vocab size\n",
    "bert_embedding_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath for sentences\n",
    "filepath_train_data = config.data_path + f'**/*-train-{config.tokenizer}.txt'\n",
    "filepath_validation_data = config.data_path + f'**/*-dev-{config.tokenizer}.txt'\n",
    "filepath_test_data = config.data_path + f'**/*-test-{config.tokenizer}.txt'\n",
    "\n",
    "# Filepath for syntax graphs\n",
    "filepath_train_syntrees = config.data_path + f'**/*-train-{config.tokenizer}.syntree'\n",
    "filepath_validation_syntrees = config.data_path + f'**/*-dev-{config.tokenizer}.syntree'\n",
    "filepath_test_syntrees = config.data_path + f'**/*-test-{config.tokenizer}.syntree'\n",
    "\n",
    "# Filepath for sentences with NER tags\n",
    "filepath_train_ner_labels = config.data_path + f'**/*-train-{config.tokenizer}-orig.ner'\n",
    "filepath_validation_ner_labels = config.data_path + f'**/*-dev-{config.tokenizer}-orig.ner'\n",
    "filepath_test_ner_labels = config.data_path + f'**/*-test-{config.tokenizer}-orig.ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.now()\n",
    "month_day = date.strftime(\"%m_%d\")\n",
    "general_config = f\"{config.use_grammar}/{month_day}_{config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}_GN{max_grad_norm_str}_LW{config.use_label_weights}\"\n",
    "\n",
    "if (config.use_gnn == True):\n",
    "    tensorboard_dir = f\"./runs/{config.task}/synGNN/{general_config}_TL_{config.num_layers}AttH_{config.num_att_heads}\"\n",
    "    tensorboard_dir = utils.createNumberedDir(tensorboard_dir)\n",
    "\n",
    "    results_dir = f\"./logs/{config.task}/synGNN/{general_config}_TL_{config.num_layers}AttH_{config.num_att_heads}\"\n",
    "    results_dir = utils.createNumberedDir(results_dir)\n",
    "    if (activeMode == \"prod\"):\n",
    "        trained_models_dir = f\"./trained_models/{config.task}/synGNN/{general_config}_TL_{config.num_layers}AttH_{config.num_att_heads}\"\n",
    "        trained_models_dir = trained_models_dir.replace(f\"_E{config.epochs}_\", f\"_E0_\")\n",
    "else:\n",
    "    tensorboard_dir = f\"./runs/{config.task}/bert/{general_config}\"\n",
    "    tensorboard_dir = utils.createNumberedDir(tensorboard_dir)\n",
    "\n",
    "    results_dir = f\"./logs/{config.task}/bert/{general_config}\"\n",
    "    results_dir = utils.createNumberedDir(results_dir)\n",
    "    if (activeMode == \"prod\"):\n",
    "        trained_models_dir = f\"./trained_models/{config.task}/bert/{general_config}\"\n",
    "        trained_models_dir = trained_models_dir.replace(f\"_E{config.epochs}_\", f\"_E0_\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, valid_ids=None, label_mask=None):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masked_inputs(inputs):\n",
    "    \"\"\"\n",
    "    creates masked input embeddings and labels from tokenized text\n",
    "\n",
    "    :param inputs: tokenized text\n",
    "    :return: InputFeatures list with masked input embeddings, new column labels and Bert attention mask/segment ids\n",
    "    \"\"\" \n",
    "\n",
    "    features = []\n",
    "    # Clone input ids (tokens) to create labels\n",
    "    inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "    # create random array of floats with equal dimensions to input_ids tensor\n",
    "    rand = torch.rand(inputs.input_ids.shape)\n",
    "    # create mask array with 15% masked tokens (do not replace CLS and SEP)\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "    # Select indices of each nonzero (= selected) value as token to be masked\n",
    "    selection = []\n",
    "\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        selection.append(\n",
    "            torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        )\n",
    "    # Mask selected tokens: replace with [MASK] code 103 in tensor\n",
    "    for i in range(inputs.input_ids.shape[0]):\n",
    "        inputs.input_ids[i, selection[i]] = 103\n",
    "    \n",
    "    features.append(\n",
    "        InputFeatures(\n",
    "                        input_ids=inputs.input_ids,\n",
    "                        input_mask=inputs.attention_mask,\n",
    "                        segment_ids=inputs.token_type_ids,\n",
    "                        label_ids=inputs.labels\n",
    "                        ))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_label_weights(label_ids_sample,num_labels, create_label_weights, label_weights_clip=None):\n",
    "    #print(label_ids_sample)\n",
    "    all_label_weights = np.ones(num_labels)\n",
    "    # Set weights for label classes to 1 (=no change) \n",
    "    if create_label_weights == 1:\n",
    "        #print(\"Lavel ids sample:\")\n",
    "        #print(label_ids_sample)\n",
    "        bincount = np.bincount(label_ids_sample,minlength=num_labels)\n",
    "        bincount = np.where(bincount == 0, 1, bincount)\n",
    "\n",
    "        #print(bincount.size())\n",
    "        bincount = np.array(bincount, dtype=np.float64)\n",
    "        num_samples = len(label_ids_sample)\n",
    "        \n",
    "        \n",
    "        all_label_weights = num_samples / (num_labels * bincount)\n",
    "\n",
    "        #max_ner = np.max(bincount[2:77])\n",
    "        #all_label_weights = np.reciprocal(bincount+1)*(max_ner+1)\n",
    "        # Cap weight values at clip value\n",
    "        if label_weights_clip != None:\n",
    "            all_label_weights = np.clip(all_label_weights,None,label_weights_clip)\n",
    "        # Reduce weight of X and O, CLS, SEP for loss computation\n",
    "        # Run om 18.09 with weights calculated from sample of 750 sentences\n",
    "        #all_label_weights[0] = 0.04\n",
    "        #all_label_weights[1] = 0.0125\n",
    "        #all_label_weights[77] = 0.2\n",
    "        #all_label_weights[78] = 0.2\n",
    "\n",
    "        # Run om 19.09 with weights calculated from all sentences\n",
    "        #all_label_weights[0] = 0.04\n",
    "        #all_label_weights[1] = 0.017\n",
    "        #all_label_weights[77] = 0.1\n",
    "        #all_label_weights[78] = 0.1\n",
    "    \n",
    "        #sum = np.sum(bincount)\n",
    "        #sum_X = bincount[0]\n",
    "        #sum_O = bincount[1]\n",
    "        #sum_ner = np.sum(bincount[2:77])\n",
    "        #sum_SEP_CLS = np.sum(bincount[77:79])\n",
    "\n",
    "\n",
    "        #print(f\" {bincount}\")\n",
    "        #print(f\"Total:{sum}\")\n",
    "        #print(f\"X: {sum_X}\")\n",
    "        #print(f\"O: {sum_O}\")\n",
    "        #print(f\"NER {sum_ner}\")\n",
    "        #print(f\"SEP/CLS: {sum_SEP_CLS}\")\n",
    "\n",
    "        '''label_classes = np.unique(all_label_ids)\n",
    "        label_weights = compute_class_weight(class_weight='balanced', classes=label_classes, y=np.array(all_label_ids).reshape(-1))\n",
    "\n",
    "        for idx, label_weight in enumerate(label_weights):\n",
    "            label_class = label_classes[idx]\n",
    "            all_label_weights[label_class] = label_weight'''\n",
    "\n",
    "        with open(\"./temp/label_weights_ud.txt\", \"w\") as output:\n",
    "            output.write(str(all_label_weights))\n",
    "            output.write(str(np.max(all_label_weights)))\n",
    "            output.write(str(np.min(all_label_weights)))\n",
    "    return torch.tensor(all_label_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_input_features(sentence_labels_list, label_list, seq_length, tokenizer, create_label_weights = False):\n",
    "    \"\"\"Loads a list of sentences into a list of input features for the transformer\n",
    "    \n",
    "        :return: list of inpt features objects\n",
    "    \"\"\"\n",
    "\n",
    "    # Map NER labels to indices\n",
    "    label_map = {label : i for i, label in enumerate(label_list,0)}\n",
    "\n",
    "    features = []\n",
    "    all_label_ids = []\n",
    "    for (sentence_idx,sentence_label_pair) in enumerate(sentence_labels_list):\n",
    "        # Tokenized text of sentence\n",
    "        tokens = []\n",
    "        # Token labels for sentence\n",
    "        labels = []\n",
    "        # Lists valid labels as 1 and labels to be ignored as 0 (e.g. for the labels for subword tokens which are not counting as separate labels for each token)\n",
    "        valid = []\n",
    "        # Mask for transformer indicating which tokens to ignore\n",
    "        label_mask = []\n",
    "        for word_label_pair in sentence_label_pair:\n",
    "            token = tokenizer.tokenize(word_label_pair[0])\n",
    "            tokens.extend(token)\n",
    "\n",
    "            label_word = word_label_pair[1]\n",
    "            for token_idx in range(len(token)):\n",
    "                # Append label for first token in word, mark as valid\n",
    "                if token_idx == 0:\n",
    "                    labels.append(label_word)\n",
    "                    valid.append(1)\n",
    "                    label_mask.append(1)\n",
    "                # Subword tokens: Mark as not valid\n",
    "                else:\n",
    "                    labels.append('X')\n",
    "                    valid.append(0)\n",
    "                    label_mask.append(1)\n",
    "        # Sentence exceeds max sequence length: cut to sequence length\n",
    "        if len(tokens) > seq_length-2:\n",
    "            tokens = tokens[0:(seq_length-2)]\n",
    "            labels = labels[0:(seq_length-2)]\n",
    "            valid = valid[0:(seq_length-2)]\n",
    "            label_mask = label_mask[0:(seq_length-2)]\n",
    "            if len(tokens)>94:\n",
    "                print(tokens)\n",
    "        # Tokens with BERT [CLS] and [SEP] tokens\n",
    "        ntokens = []\n",
    "        # Segment ids for BERT\n",
    "        segment_ids = []\n",
    "        # Label embedding ids for BERT\n",
    "        label_ids = []\n",
    "        # Start segment\n",
    "        ntokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        # Add CLS token label for Bert\n",
    "        label_ids.append(label_map[\"[CLS]\"])\n",
    "        # Mark as valid label\n",
    "        valid.insert(0,1)\n",
    "        label_mask.insert(0,1)\n",
    "\n",
    "        # add sentence tokens and label ids\n",
    "        for i, token in enumerate(tokens):\n",
    "            ntokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "            if len(labels) > i:\n",
    "                label_ids.append(label_map[labels[i]])\n",
    "        # End segment\n",
    "        ntokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "\n",
    "        # Add SEP end token label for Bert\n",
    "        label_ids.append(label_map[\"[SEP]\"])\n",
    "        valid.append(1)\n",
    "        label_mask.append(1)\n",
    "\n",
    "        # Convert tokens to ids\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Add label ids to list for weight computation\n",
    "        all_label_ids.extend(label_ids)\n",
    "        \n",
    "        # Pad sentence to sequence length\n",
    "        while len(input_ids) < seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "\n",
    "        # Pad labels to sequence length\n",
    "        while len(label_ids) < seq_length:\n",
    "            label_ids.append(0)\n",
    "            label_mask.append(0)\n",
    "            valid.append(1)\n",
    "        \n",
    "        try:\n",
    "            assert len(input_ids) == seq_length\n",
    "            assert len(input_mask) == seq_length\n",
    "            assert len(segment_ids) == seq_length\n",
    "            assert len(label_ids) == seq_length\n",
    "            assert len(valid) == seq_length\n",
    "            assert len(label_mask) == seq_length\n",
    "        except Exception as e:\n",
    "            print(repr(e))\n",
    "            len(input_ids)\n",
    "\n",
    "\n",
    "        features.append(\n",
    "        InputFeatures(\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        label_ids=label_ids,\n",
    "                        valid_ids=valid,\n",
    "                        label_mask=label_mask,\n",
    "                        ))\n",
    "    num_labels = len(label_list)\n",
    "    all_label_weights = calculate_label_weights(all_label_ids, num_labels, create_label_weights, config.label_weights_clip)\n",
    "\n",
    "    return features, all_label_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, syntax_graphs=None,sentence_graph_idx_maps=None):\n",
    "        #self.features = features\n",
    "        self.input_ids = features['input_ids']\n",
    "        self.input_masks = features['attention_mask']\n",
    "        self.label_ids = features['labels']\n",
    "        self.segment_ids = features['token_type_ids']\n",
    "        self.syntax_graphs = syntax_graphs\n",
    "        self.sentence_graph_idx_maps = sentence_graph_idx_maps\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        input_ids = torch.squeeze(self.input_ids[idx])\n",
    "        input_masks = torch.squeeze(self.input_masks[idx])\n",
    "        label_ids = torch.squeeze(self.label_ids[idx])\n",
    "        segment_ids = torch.squeeze(self.segment_ids[idx])\n",
    "        if(self.syntax_graphs is not None and self.sentence_graph_idx_maps is not None):\n",
    "\n",
    "            syntax_graph = self.syntax_graphs[idx]\n",
    "            sentence_graph_idx_map = self.sentence_graph_idx_maps[idx]\n",
    "            return input_ids, input_masks, label_ids, segment_ids, syntax_graph, sentence_graph_idx_map\n",
    "        else:\n",
    "            return input_ids, input_masks, label_ids, segment_ids\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm_data_collate_function(data):\n",
    "    data = list(zip(*data))\n",
    "    #print(data)\n",
    "\n",
    "    # Get all input ids\n",
    "    input_ids = torch.stack(data[0])\n",
    "\n",
    "    # Get all input masks\n",
    "    input_masks = torch.stack(data[1])\n",
    "\n",
    "    # Get all label ids\n",
    "    label_ids = torch.stack(data[2])\n",
    "\n",
    "    # Get all segment ids\n",
    "    segment_ids = torch.stack(data[3])\n",
    "\n",
    "    if config.use_gnn == True:\n",
    "        # Get all Pytorch Geom Data objects\n",
    "        pyg_data = data[4]\n",
    "        # Get all sentence_graph_idx_maps\n",
    "        sentence_graph_idx_maps = data[5]\n",
    "\n",
    "        return input_ids, input_masks, label_ids, segment_ids, pyg_data, sentence_graph_idx_maps\n",
    "    else:\n",
    "        return input_ids, input_masks, label_ids, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, syntax_graphs=None,sentence_graph_idx_maps=None):\n",
    "\n",
    "        self.features = features\n",
    "        self.syntax_graphs = syntax_graphs\n",
    "        self.sentence_graph_idx_maps = sentence_graph_idx_maps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if(self.syntax_graphs is not None and self.sentence_graph_idx_maps is not None):\n",
    "\n",
    "            features = self.features[idx]\n",
    "            syntax_graphs = self.syntax_graphs[idx]\n",
    "            sentence_graph_idx_map = self.sentence_graph_idx_maps[idx]\n",
    "            return features, syntax_graphs, sentence_graph_idx_map\n",
    "        else:\n",
    "            return self.features[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_data_collate_function(data):\n",
    "    \n",
    "    # Get all Bert input feature objects\n",
    "    if config.use_gnn == True:\n",
    "        data = list(zip(*data))\n",
    "        input_features = data[0]\n",
    "    else:\n",
    "        input_features = data\n",
    "    # Get all input ids\n",
    "    input_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.input_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all input masks\n",
    "    input_masks = torch.squeeze(torch.tensor(list(map(lambda x:x.input_mask,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all label ids\n",
    "    label_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.label_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all valid ids\n",
    "    valid_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.valid_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all label masks\n",
    "    label_masks = torch.squeeze(torch.tensor(list(map(lambda x:x.label_mask,input_features)),dtype=torch.long))\n",
    "\n",
    "    # Get all segment ids\n",
    "    segment_ids = torch.squeeze(torch.tensor(list(map(lambda x:x.segment_ids,input_features)),dtype=torch.long))\n",
    "\n",
    "    if config.use_gnn == True:\n",
    "        # Get all Pytorch Geom Data objects\n",
    "        pyg_data = data[1]\n",
    "        # Get all sentence_graph_idx_maps\n",
    "        sentence_graph_idx_maps = data[2]\n",
    "\n",
    "        return input_ids, input_masks, label_ids, valid_ids, label_masks, segment_ids, pyg_data, sentence_graph_idx_maps\n",
    "    else:\n",
    "        return input_ids, input_masks, label_ids, valid_ids, label_masks, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ud_tokenizer(tokenizer, tokenizer_name):\n",
    "    tokenizer_path = \"./tokenizers/\" + tokenizer_name \n",
    "    special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "    ]\n",
    "    # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "    vocab_size = 30_522\n",
    "    # Load data\n",
    "    text = []\n",
    "    for ud_file in glob.iglob(config.data_path + '**/UD_English-Pronouns/en_*.txt', recursive=True):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        tokenizer.train(files=ud_file, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "    # make the directory if not already there\n",
    "    if not os.path.isdir(tokenizer_path):\n",
    "        os.mkdir(tokenizer_path)\n",
    "    # save the tokenizer  \n",
    "    tokenizer.save_model(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences_from_files(filepath, seq_length=None, num_sentences=0, excluded_idx_list=None):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :param seq_length: BERT sequence length. Must be provided when SynGNN is used instead of vanilla Bert. SynGNN only supports sentences up to seq_length, others are discarded\n",
    "    :return: list of sentences\n",
    "    \"\"\" \n",
    "    sentences = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "\n",
    "            sentences_temp = fp.read().split('\\n')\n",
    "            sentences.extend(sentences_temp)\n",
    "    if num_sentences != 0:\n",
    "        sentences = sentences[0:num_sentences]\n",
    "    # Delete sentences longer than sequence length\n",
    "    if (excluded_idx_list != None):\n",
    "        sentences = [x for idx, x in enumerate(sentences) if idx not in excluded_idx_list]\n",
    "\n",
    "\n",
    "    return sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ner_labels_from_files(filepath, num_sentences=0, excluded_idx_list=None):\n",
    "    \"\"\"\n",
    "    Load sentences from files.\n",
    "\n",
    "    :param filepath: path to files (supports glob regex)\n",
    "    :return: list of NER labels per sentence\n",
    "    \"\"\" \n",
    "    all_token_label_pairs = []\n",
    "    for ud_file in sorted(glob.iglob(filepath, recursive=True)):\n",
    "        sentences = []\n",
    "        ud_file = os.path.abspath(ud_file)\n",
    "        filename = os.path.basename(ud_file)\n",
    "        print(filename, flush = True)\n",
    "        with open(ud_file, 'r') as fp:\n",
    "            if (config.num_sentences == 0):\n",
    "                # Split labels file by sentences\n",
    "                sentences = fp.read().split('\\n')\n",
    "            else:\n",
    "                sentences = fp.read().split('\\n')[0:num_sentences]\n",
    "        # Split sentences by tokens\n",
    "        token_labels = [x.split(\"\\t\") for x in sentences]\n",
    "        # Remove empty line at end of sentence\n",
    "        [x.remove('') for x in token_labels]\n",
    "        # Remove empty line at end of file\n",
    "        if token_labels[-1] == []:\n",
    "            token_labels.pop(-1)\n",
    "\n",
    "        print(f\"num sentences: {len(token_labels)}\")\n",
    "      \n",
    "        \n",
    "        # Split token and NER tags\n",
    "        token_labels = [list(map(lambda x:x.split(\" \") ,tag_token)) for tag_token in token_labels if tag_token != []]\n",
    "\n",
    "        all_token_label_pairs.extend(token_labels)\n",
    "    # Delete sentences longer than sequence length\n",
    "    if (excluded_idx_list != None):\n",
    "        all_token_label_pairs = [x for idx, x in enumerate(all_token_label_pairs) if idx not in excluded_idx_list]\n",
    "    return all_token_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_syntaxgraphs_from_files(filepath, seq_length=None, num_sentences=0):\n",
    "    r\"\"\"\n",
    "    Load binary syntax tree files (*.syntree).\n",
    "    Args:\n",
    "        filepath: path to files (supports glob regex)\n",
    "        return: list of pytorch geometric syntax graphs per file and list of sentence token to graph node mappings\n",
    "    \"\"\" \n",
    "    all_syntrees = []\n",
    "    all_sentence_to_graph_maps = []\n",
    "    excluded_idx_list = []\n",
    "    for syntree_file in sorted(glob.iglob(filepath, recursive=True)):   \n",
    "        syntree_file = os.path.abspath(syntree_file)\n",
    "        filename = os.path.basename(syntree_file)\n",
    "        print(f\"Loading syntax graphs: from file {filename}\", flush=True)\n",
    "        with open(syntree_file, 'rb') as fp:\n",
    "            if (config.num_sentences == 0):\n",
    "                file_graphs_and_maps = pd.read_pickle(fp)\n",
    "            else:\n",
    "                file_graphs_and_maps = pd.read_pickle(fp)[0:num_sentences]\n",
    "\n",
    "            print(f\"num graphs {len(file_graphs_and_maps)}\")\n",
    "\n",
    "\n",
    "            syntree_list = [graph_map_pair[0] for graph_map_pair in file_graphs_and_maps]\n",
    "            sentence_to_graph_map_list = [graph_map_pair[1] for graph_map_pair in file_graphs_and_maps]\n",
    "            all_syntrees.extend(syntree_list)\n",
    "            all_sentence_to_graph_maps.extend(sentence_to_graph_map_list)\n",
    "\n",
    "    # Dependency trees:\n",
    "    # Delete all graphs where graph length >= seq_len\n",
    "    # Graph always is of length: num tokens+1, including graph root token.\n",
    "    # Constituency trees do not correspond to sentence length\n",
    "    if config.use_grammar == \"dep\":\n",
    "        for idx, graph in enumerate(all_syntrees):\n",
    "            graph_len =  graph.x.shape[0]\n",
    "            if graph_len>=seq_length:\n",
    "                excluded_idx_list.append(idx)\n",
    "    # Use sentence to graph map to exclude graphs > sequence length\n",
    "    if config.use_grammar == \"const\":\n",
    "        for idx, sentence_to_graph_map in enumerate(all_sentence_to_graph_maps):\n",
    "            sentence_len = len(sentence_to_graph_map.keys())\n",
    "            if sentence_len == 0:\n",
    "                print(all_syntrees[idx])\n",
    "            if sentence_len>seq_length:\n",
    "                excluded_idx_list.append(idx)\n",
    "    all_syntrees = [x for idx, x in enumerate(all_syntrees) if idx not in excluded_idx_list]\n",
    "    all_sentence_to_graph_maps = [x for idx, x in enumerate(all_sentence_to_graph_maps) if idx not in excluded_idx_list]\n",
    "    print(\"Example syntax graphs:\")\n",
    "    print(all_syntrees[0:2])\n",
    "    print(all_sentence_to_graph_maps[0:2])\n",
    "    return all_syntrees, all_sentence_to_graph_maps, excluded_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxSequenceLength(sentences, tokenizer, cutoff_limit_percent=0.9999):\n",
    "    \"\"\"\n",
    "    Calculate maximum sequence length for given data.\n",
    "    param sentences: list of sentences\n",
    "    param cutoff_limit_percent: percentage of all samples to accommodate with the max sequence length.\n",
    "    returns: max sequence length which encompasses cutoff_limit_percent of all data samples\n",
    "    \"\"\"\n",
    "    # Get number of tokens per sentence        \n",
    "    max_sentence_tokens = 0\n",
    "    sentence_tokens = {}\n",
    "    print(f\"Amount of samples: {len(sentences)}\")\n",
    "    # Tokenize data\n",
    "    for sentence in sentences:\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors='pt')\n",
    "        \n",
    "        token_count = inputs.input_ids.size(dim=1)\n",
    "        sentence_tokens[inputs.input_ids.size(dim=1)] = sentence_tokens.get(token_count,0) + 1\n",
    "        if(token_count > max_sentence_tokens): \n",
    "            max_sentence_tokens = token_count\n",
    "            \n",
    "    no_tokens = 0\n",
    "    # Calulate number of samples which should have a sequence length smaller than max_sequence_length\n",
    "    cutoff = cutoff_limit_percent * len(sentences)\n",
    "    max_sequence_length = 0\n",
    "    print(max_sentence_tokens)\n",
    "    for i in sorted(sentence_tokens):\n",
    "        # print((i, sentence_tokens[i]), end=\" \")\n",
    "        if(no_tokens <= cutoff):\n",
    "            no_tokens = no_tokens + sentence_tokens[i]\n",
    "            max_sequence_length = i\n",
    "\n",
    "    print(f\"Max sequence length: {max_sequence_length} with {cutoff_limit_percent}% of samples smaller\")\n",
    "    return max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_mlm(filepath, tokenizer, filepath_syntrees = None, shuffle_data=False, create_label_weights=False):\n",
    "    excluded_idx_list = None\n",
    "        \n",
    "    if (config.use_gnn and filepath_syntrees != None):\n",
    "        # Load syntax graphs\n",
    "        syntax_graphs, sentence_to_graph_idx_maps, excluded_idx_list = load_syntaxgraphs_from_files(filepath_syntrees, config.sequence_length, config.num_sentences)\n",
    "    # Load sentences data\n",
    "    sentences = load_sentences_from_files(filepath, config.sequence_length, config.num_sentences, excluded_idx_list)\n",
    "    num_sentences = len(sentences)\n",
    "    print(num_sentences)\n",
    "    print(sentences[0])\n",
    "    \n",
    "    if (config.use_gnn and filepath_syntrees != None):\n",
    "        num_graphs = len(syntax_graphs)\n",
    "\n",
    "        if num_sentences != num_graphs:\n",
    "            print(excluded_idx_list)\n",
    "            print(f\"Num Sentences ({num_sentences}) and num graphs ({num_graphs}) must be the same\")\n",
    "            exit()\n",
    "        # Check that graphs and sentences are of same length\n",
    "        # Account for root node in graph.\n",
    "        graph_sentence_unequal_count = 0\n",
    "        delete_idx_list = []\n",
    "        for graph_idx, graph in enumerate(syntax_graphs):\n",
    "            graph_len = graph.x.size()[0]\n",
    "            sentence = sentences[graph_idx].split(\" \")\n",
    "            sentence_tokenized = []\n",
    "            for word in sentence:\n",
    "                tokens = tokenizer.tokenize(word)\n",
    "                sentence_tokenized.extend(tokens)\n",
    "            sentence_len = len(sentence_tokenized)\n",
    "            # Graph and sentence unequal: schedule for delete\n",
    "            if graph_len-1 != sentence_len:\n",
    "                graph_sentence_unequal_count = graph_sentence_unequal_count+1\n",
    "                delete_idx_list.append(graph_idx)\n",
    "\n",
    "        syntax_graphs = [x for idx, x in enumerate(syntax_graphs) if idx not in delete_idx_list]\n",
    "        sentence_to_graph_idx_maps = [x for idx, x in enumerate(sentence_to_graph_idx_maps) if idx not in delete_idx_list]\n",
    "        sentences = [x for idx, x in enumerate(sentences) if idx not in delete_idx_list]\n",
    "        num_sentences = len(sentences)\n",
    "        print(num_sentences)\n",
    "\n",
    "    # Remove batches of size 1 \n",
    "    if num_sentences % config.batch_size == 1:\n",
    "            if config.use_gnn:\n",
    "                syntax_graphs.pop(-1)\n",
    "                sentence_to_graph_idx_maps.pop(-1)\n",
    "                num_graphs = len(syntax_graphs)\n",
    "            num_sentences = len(sentences)\n",
    "            sentences.pop(-1)\n",
    "    \n",
    "    num_batches = math.ceil(num_sentences / config.batch_size)\n",
    "\n",
    "    # Tokenize data\n",
    "    inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "    inputs_masked = create_masked_inputs(inputs)\n",
    "\n",
    "    if (config.use_gnn and filepath_syntrees != None):\n",
    "        #TODO: Add syntax graphs to MlmDataset\n",
    "        data = MlmDataset(inputs_masked, syntax_graphs, sentence_to_graph_idx_maps)\n",
    "    else:\n",
    "        data = MlmDataset(inputs_masked)\n",
    "    loader = DataLoader(data, batch_size=config.batch_size, shuffle=shuffle_data, collate_fn=mlm_data_collate_function)\n",
    "\n",
    "    '''label_weights = torch.tensor(np.ones(num_mlm_labels), dtype=torch.float)\n",
    "    sep_token_id = tokenizer.convert_tokens_to_ids(\"[SEP]\")\n",
    "    cls_token_id = tokenizer.convert_tokens_to_ids(\"[CLS]\")\n",
    "    mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "    label_weights[sep_token_id] = 0.1\n",
    "    label_weights[cls_token_id] = 0.1'''\n",
    "    all_label_ids = inputs['input_ids'].detach().numpy().flatten()\n",
    "    label_weights = calculate_label_weights(all_label_ids, num_mlm_labels,create_label_weights=config.use_label_weights)\n",
    "\n",
    "    return loader, label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_ner(filepath, tokenizer, create_weights, filepath_syntrees = None, shuffle_data=False):\n",
    "    excluded_idx_list = None\n",
    "    if (config.use_gnn):\n",
    "        # Load syntax graphs\n",
    "        if(config.use_gnn and filepath_syntrees != None):\n",
    "            syntax_graphs, sentence_to_graph_idx_maps, excluded_idx_list = load_syntaxgraphs_from_files(filepath_syntrees, config.sequence_length, config.num_sentences)\n",
    "\n",
    "    print(f\"Loading NER labels from {filepath}\")\n",
    "    # Load NER labels\n",
    "    sentence_labels_list = load_ner_labels_from_files(filepath, config.num_sentences, excluded_idx_list)\n",
    "    num_sentences = len(sentence_labels_list)\n",
    "    # Check that sentences and graphs match\n",
    "    if config.use_gnn == True:\n",
    "        num_graphs = len(syntax_graphs)\n",
    "\n",
    "        if num_sentences != num_graphs:\n",
    "            print(f\"Num Sentences ({num_sentences}) and num graphs ({num_graphs}) must be the same. Excluded items: {len(excluded_idx_list)}\")\n",
    "            exit()\n",
    "        delete_idx_list = []\n",
    "        graph_sentence_unequal_count = 0\n",
    "        if config.use_grammar==\"dep\":\n",
    "            # Check that graphs and sentences are of same length\n",
    "            # Account for root node in graph.\n",
    "            for graph_idx, graph in enumerate(syntax_graphs):\n",
    "                graph_len = graph.x.size()[0]\n",
    "                sentence = [sentence_label_pair[0] for sentence_label_pair in sentence_labels_list[graph_idx]]\n",
    "                sentence_tokenized = []\n",
    "                for word in sentence:\n",
    "                    tokens = tokenizer.tokenize(word)\n",
    "                    sentence_tokenized.extend(tokens)\n",
    "                sentence_len = len(sentence_tokenized)\n",
    "                # Graph and sentence unequal: schedule for delete\n",
    "                if graph_len-1 != sentence_len:\n",
    "                    graph_sentence_unequal_count = graph_sentence_unequal_count+1\n",
    "                    delete_idx_list.append(graph_idx)\n",
    "        \n",
    "\n",
    "            syntax_graphs = [x for idx, x in enumerate(syntax_graphs) if idx not in delete_idx_list]\n",
    "            sentence_to_graph_idx_maps = [x for idx, x in enumerate(sentence_to_graph_idx_maps) if idx not in delete_idx_list]\n",
    "            sentence_labels_list = [x for idx, x in enumerate(sentence_labels_list) if idx not in delete_idx_list]\n",
    "\n",
    "    # Remove batches of size 1 \n",
    "    if num_sentences % config.batch_size == 1:\n",
    "            if config.use_gnn:\n",
    "                syntax_graphs.pop(-1)\n",
    "                sentence_to_graph_idx_maps.pop(-1)\n",
    "                num_graphs = len(syntax_graphs)\n",
    "            sentence_labels_list.pop(-1)\n",
    "            \n",
    "    num_sentences = len(sentence_labels_list)\n",
    "    num_batches = math.ceil(num_sentences / config.batch_size)\n",
    "\n",
    "    print(f\"Example of NER labels: {sentence_labels_list[0:2]}\")\n",
    "    features, label_weights = create_ner_input_features(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer, create_weights)\n",
    "\n",
    "    if config.use_gnn == True:\n",
    "        print(f\"Excluded {len(excluded_idx_list)} sentences longer than sequence length\")\n",
    "        print(f\"Excluded {graph_sentence_unequal_count} items with sentence != graph\")\n",
    "        print(f\"Deleted items: {delete_idx_list}\" )\n",
    "        print(f\"{num_sentences} sentences, {num_graphs} graphs, {num_batches} batches of size {config.batch_size}\\n\")\n",
    "        mlm_dataset = NerDataset(features, syntax_graphs, sentence_to_graph_idx_maps)\n",
    "    else:\n",
    "        print(f\"{num_sentences} sentences, {num_batches} batches of size {config.batch_size}\\n\")\n",
    "        mlm_dataset = NerDataset(features)\n",
    "\n",
    "    print(\"Control example of InputFeatures\")\n",
    "    print(f\"Input Ids: {str(features[1].input_ids)}\")\n",
    "    print(f\"Input Mask: {str(features[1].input_mask)}\")\n",
    "    print(f\"Label Ids: {str(features[1].label_ids)}\")\n",
    "    print(f\"Valid Ids: {str(features[1].valid_ids)}\")\n",
    "    print(f\"Label Mask: {str(features[1].label_mask)}\")\n",
    "    print(f\"Segment Ids: {str(features[1].segment_ids)}\")\n",
    "\n",
    "    loader = DataLoader(mlm_dataset, batch_size=config.batch_size, shuffle=shuffle_data, collate_fn=ner_data_collate_function)\n",
    "    return loader, label_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataloader(filepath, tokenizer, filepath_syntrees = None, shuffle_data=False, create_weights=0):\n",
    "        excluded_idx_list = None\n",
    "        # Load syntax graphs and create dataset\n",
    "        if(config.use_gnn and filepath_syntrees != None):\n",
    "            syntax_graphs, sentence_to_graph_idx_maps, excluded_idx_list = load_syntaxgraphs_from_files(filepath_syntrees, config.sequence_length, config.num_sentences)\n",
    "        # Load NER labels\n",
    "        if(config.task == 'ner'):\n",
    "            print(f\"Loading NER labels from {filepath}\")\n",
    "            # Load NER labels\n",
    "            sentence_labels_list = load_ner_labels_from_files(filepath, config.num_sentences, excluded_idx_list)\n",
    "            num_sentences = len(sentence_labels_list)\n",
    "            num_graphs = len(syntax_graphs)\n",
    "\n",
    "            if num_sentences != num_graphs:\n",
    "                print(f\"Num Sentences ({num_sentences}) and num graphs ({num_graphs}) must be the same\")\n",
    "                exit()\n",
    "            # Check that graphs and sentences are of same length\n",
    "            # Account for root node in graph.\n",
    "            graph_sentence_unequal_count = 0\n",
    "            delete_idx_list = []\n",
    "            for graph_idx, graph in enumerate(syntax_graphs):\n",
    "                graph_len = graph.x.size()[0]\n",
    "                sentence = [sentence_label_pair[0] for sentence_label_pair in sentence_labels_list[graph_idx]]\n",
    "                sentence_tokenized = []\n",
    "                for word in sentence:\n",
    "                    tokens = tokenizer.tokenize(word)\n",
    "                    sentence_tokenized.extend(tokens)\n",
    "                sentence_len = len(sentence_tokenized)\n",
    "                # Graph and sentence unequal: schedule for delete\n",
    "                if graph_len-1 != sentence_len:\n",
    "                    graph_sentence_unequal_count = graph_sentence_unequal_count+1\n",
    "                    delete_idx_list.append(graph_idx)\n",
    "\n",
    "            syntax_graphs = [x for idx, x in enumerate(syntax_graphs) if idx not in delete_idx_list]\n",
    "            sentence_to_graph_idx_maps = [x for idx, x in enumerate(sentence_to_graph_idx_maps) if idx not in delete_idx_list]\n",
    "            sentence_labels_list = [x for idx, x in enumerate(sentence_labels_list) if idx not in delete_idx_list]\n",
    "\n",
    "            # Remove batches of size 1 \n",
    "            if num_sentences % config.batch_size == 1:\n",
    "                 syntax_graphs.pop(-1)\n",
    "                 sentence_labels_list.pop(-1)\n",
    "                 sentence_to_graph_idx_maps.pop(-1)\n",
    "                 num_sentences = len(sentence_labels_list)\n",
    "                 num_graphs = len(syntax_graphs)\n",
    "            \n",
    "            num_batches = math.ceil(num_sentences / config.batch_size)\n",
    "            \n",
    "            print(f\"Excluded {len(excluded_idx_list)} sentences longer than sequence length\")\n",
    "            print(f\"Excluded {graph_sentence_unequal_count} items with sentence != graph\")\n",
    "            print(f\"Deleted items: {delete_idx_list}\" )\n",
    "            print(f\"{num_sentences} sentences, {num_graphs} graphs, {num_batches} batches of size {config.batch_size}\\n\")\n",
    "\n",
    "            print(f\"Example of NER labels: {sentence_labels_list[0:2]}\")\n",
    "            features, label_weights = create_ner_input_features(sentence_labels_list, ner_tags_list, config.sequence_length, tokenizer, create_weights)\n",
    "            #all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "            #all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "            #all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "            #all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "            #all_valid_ids = torch.tensor([f.valid_ids for f in features], dtype=torch.long)\n",
    "            #all_lmask_ids = torch.tensor([f.label_mask for f in features], dtype=torch.long)\n",
    "            #all_label_weights = torch.tensor(label_weights, dtype=torch.long)\n",
    "            \n",
    "            #data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids,all_valid_ids,all_lmask_ids, all_label_weights)\n",
    "            #print(data.__sizeof__())\n",
    "\n",
    "            # Print control example of InputFeatures\n",
    "            print(\"Control example of InputFeatures\")\n",
    "            print(f\"Input Ids: {str(features[1].input_ids)}\")\n",
    "            print(f\"Input Mask: {str(features[1].input_mask)}\")\n",
    "            print(f\"Label Ids: {str(features[1].label_ids)}\")\n",
    "            print(f\"Valid Ids: {str(features[1].valid_ids)}\")\n",
    "            print(f\"Label Mask: {str(features[1].label_mask)}\")\n",
    "            print(f\"Segment Ids: {str(features[1].segment_ids)}\")\n",
    "\n",
    "\n",
    "        if(config.task == 'mlm'):\n",
    "            # Load data\n",
    "            sentences = load_sentences_from_files(filepath)\n",
    "            # Tokenize data\n",
    "            inputs = tokenizer(sentences, return_tensors='pt', max_length=config.sequence_length, truncation=True, padding='max_length')\n",
    "            inputs = create_masked_inputs(inputs)\n",
    "\n",
    "            # Create dataset from tokenized data\n",
    "            data = MlmDataset(inputs)\n",
    "        \n",
    "        # Create dataset\n",
    "        if(config.use_gnn and filepath_syntrees != None):\n",
    "            syngnn_dataset = SynGNNDataset(features, syntax_graphs, sentence_to_graph_idx_maps)\n",
    "            loader = DataLoader(syngnn_dataset, batch_size=config.batch_size, shuffle=shuffle_data, collate_fn=syngnn_data_collate_function)\n",
    "        else:\n",
    "            loader = DataLoader(data, batch_size=config.batch_size, shuffle=shuffle_data)\n",
    "        return loader, label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(tokenizer):\n",
    "    if (config.use_label_weights == True):\n",
    "        # Create label weights from data\n",
    "        create_weights = 1\n",
    "    else:\n",
    "        # Use uniform label weights\n",
    "        create_weights = 0\n",
    "    print(\"Loading Training Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn == True):\n",
    "            return create_dataloader_ner(filepath_train_ner_labels, tokenizer, create_weights=create_weights, filepath_syntrees=filepath_train_syntrees, shuffle_data=True)\n",
    "        else:\n",
    "            return create_dataloader_ner(filepath_train_ner_labels, tokenizer, create_weights=create_weights, shuffle_data=True)\n",
    "    if(config.task == 'mlm'):\n",
    "        \n",
    "        if(config.use_gnn == True):\n",
    "            return create_dataloader_mlm(filepath_train_data, tokenizer, filepath_train_syntrees, shuffle_data=True)\n",
    "        else:\n",
    "            return create_dataloader_mlm(filepath_train_data, tokenizer, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data(tokenizer):\n",
    "    print(\"Loading Validation Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn == True):\n",
    "            return create_dataloader_ner(filepath_validation_ner_labels, tokenizer, create_weights=0, filepath_syntrees=filepath_validation_syntrees, shuffle_data=True)\n",
    "        else:\n",
    "            return create_dataloader_ner(filepath_validation_ner_labels, tokenizer, create_weights=0, shuffle_data=True)\n",
    "    if(config.task == 'mlm'):\n",
    "        if(config.use_gnn == True):\n",
    "            return create_dataloader_mlm(filepath_validation_data, tokenizer, filepath_validation_syntrees, shuffle_data=True)\n",
    "        else:\n",
    "            return create_dataloader_mlm(filepath_validation_data, tokenizer, shuffle_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(tokenizer):\n",
    "    print(\"Test Data\")\n",
    "    if(config.task == 'ner'):\n",
    "        if(config.use_gnn):\n",
    "            return create_dataloader_ner(filepath_test_ner_labels, tokenizer, create_weights=0, filepath_syntrees=filepath_test_syntrees, shuffle_data=False)\n",
    "        else:\n",
    "            return create_dataloader_ner(filepath_test_ner_labels, tokenizer, create_weights=0, shuffle_data=False)\n",
    "    if(config.task == 'mlm'):\n",
    "        if(config.use_gnn == True):\n",
    "            return create_dataloader_mlm(filepath_test_data, tokenizer, filepath_test_syntrees, shuffle_data=False)\n",
    "        else:\n",
    "            return create_dataloader_mlm(filepath_test_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stderr\n",
    "prof = torch.profiler.profile(\n",
    "        activities=[ProfilerActivity.CPU],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=2, active=1, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profiler/09_20'),\n",
    "        record_shapes=False,\n",
    "        with_stack=True)\n",
    "def runModel(data_loader, model, device, tokenizer, mode=None, writer = None, results_dir = None,  epoch = None, optimizer = None):\n",
    "\n",
    "    if(mode == 'Train'):\n",
    "        model.train()\n",
    "    elif(mode == 'Test' or mode == 'Validation'):\n",
    "        model.eval()\n",
    "    else:\n",
    "        stderr(\"Mode must be Train, Validation or Test\")\n",
    "        exit()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_input = []\n",
    "    label_map = {i : label for i, label in enumerate(ner_tags_list,0)}\n",
    "\n",
    "    references_all = []\n",
    "    predictions_all = []\n",
    "    references_roc_all = []\n",
    "    predictions_roc_all = []\n",
    "    epoch_loss = 0\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "\n",
    "        sep_token_id = tokenizer.convert_tokens_to_ids(\"[SEP]\")\n",
    "        cls_token_id = tokenizer.convert_tokens_to_ids(\"[CLS]\")\n",
    "        mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n",
    "\n",
    "        # Setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, miniters=200, maxinterval=7000)\n",
    "        number_of_batches = len(loop)\n",
    "        for batch in loop:\n",
    "    \n",
    "            # Pull all tensor batches required for training\n",
    "            batch = tuple(t for t in batch)\n",
    "            if (config.use_gnn == True):\n",
    "                input_ids, input_masks, label_ids, segment_ids, pyg_data, sentence_graph_idx_maps = batch\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_masks = input_masks.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "                label_ids = label_ids.to(device)\n",
    "                #print(input_ids.size())\n",
    "                #print(input_masks.size())\n",
    "                #print(segment_ids.size())\n",
    "                #print(label_ids.size())\n",
    "\n",
    "            else:\n",
    "                input_ids, input_masks, label_ids,segment_ids = batch\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_masks = input_masks.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "                label_ids = label_ids.to(device)\n",
    "\n",
    "            #softmax = nn.Softmax(dim = -1)\n",
    "            if (mode == 'Test' or mode == 'Validation'):\n",
    "                #print(\"Validation\")\n",
    "                with torch.no_grad():\n",
    "                    if (config.use_gnn == True):\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks,label_ids=label_ids,syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                    else:\n",
    "                        outputs = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, labels=label_ids)\n",
    "                        loss, logits = outputs[:2]\n",
    "            if(mode == 'Train'):\n",
    "                #print(\"Training\")\n",
    "                # initialize calculated gradients (from prev step)\n",
    "                optimizer.zero_grad()\n",
    "                if (config.use_gnn == True):\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks,label_ids=label_ids,syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                else:\n",
    "                    outputs =  model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, labels=label_ids)\n",
    "                    loss, logits = outputs[:2]\n",
    "                # calculate loss for every parameter that needs grad update\n",
    "                loss.backward()\n",
    "                if (config.max_grad_norm):\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "            if(mode == 'Validation' or mode == 'Train'):\n",
    "                #print(\"Updating loss\")        \n",
    "                batch_loss = loss.item()\n",
    "                # print relevant info to progress bar\n",
    "                loop.set_description(f'{mode} Epoch {epoch}', refresh=False)\n",
    "\n",
    "                loop.set_postfix(loss=batch_loss, refresh=False)\n",
    "                epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "            # Change type to double to prevent floating point rounding errors\n",
    "            logits = logits.type(torch.float64)\n",
    "            softmax = nn.Softmax(dim=-1)\n",
    "            # Get highest NER label prediction for all sentences\n",
    "            #print(f\"Softmax:{softmax(logits)}\")\n",
    "            predictions = torch.argmax(softmax(logits),dim=-1)\n",
    "            predictions = predictions.to('cpu').numpy()\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            input_masks = input_masks.to('cpu').numpy()\n",
    "            sample_length = 50\n",
    "            # Go through true labels\n",
    "            for input_list_idx, sentence_input_ids in enumerate(input_ids):\n",
    "                y_true_temp = []\n",
    "                y_pred_temp = []\n",
    "                y_input_temp = []\n",
    "                for input_idx, input_id in enumerate(sentence_input_ids):\n",
    "\n",
    "                    # Only count predictions for masked tokens\n",
    "                    if input_id == mask_token_id:\n",
    "                        y_true_temp.append(label_ids[input_list_idx][input_idx])\n",
    "                        y_input_temp.append(input_ids[input_list_idx][input_idx])\n",
    "                        y_pred_temp.append(predictions[input_list_idx][input_idx].tolist())\n",
    "                    \n",
    "\n",
    "                    \n",
    "\n",
    "                    # Detect [SEP] label at sentence end and ignore [SEP] and all sequence padding\n",
    "                    # Append all found labels to y_true and y_pred\n",
    "                    elif input_id == sep_token_id:\n",
    "                        y_true.extend(y_true_temp)\n",
    "                        y_pred.extend(y_pred_temp)\n",
    "                        y_input.extend(y_input_temp)\n",
    "                        break\n",
    "\n",
    "        epoch_loss = epoch_loss/number_of_batches\n",
    "\n",
    "        #if(mode == 'Test'):\n",
    "        print(y_true[0:50])\n",
    "        print(y_pred[0:50])\n",
    "        #print(input_ids[1])\n",
    "        #print(predictions[1])\n",
    "        \n",
    "\n",
    "\n",
    "        recall_metric = evaluate.load('recall')\n",
    "        precision_metric = evaluate.load('precision')\n",
    "        f1_metric = evaluate.load('f1')\n",
    "        roc_auc_metric = evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "\n",
    "        micro_precision = precision_metric.compute( references = y_true, predictions = y_pred, average= 'micro', zero_division = 0)['precision']\n",
    "        macro_precision = precision_metric.compute(references = y_true, predictions = y_pred, average = 'macro', zero_division = 0)['precision']\n",
    "        weighted_precision = precision_metric.compute( references = y_true, predictions = y_pred, average = 'weighted', zero_division = 0)['precision']\n",
    "\n",
    "        micro_recall = recall_metric.compute( references = y_true, predictions = y_pred, average= 'micro', zero_division = 0)['recall']\n",
    "        macro_recall = recall_metric.compute(references = y_true, predictions = y_pred, average = 'macro', zero_division = 0)['recall']\n",
    "        weighted_recall = recall_metric.compute( references = y_true, predictions = y_pred, average = 'weighted', zero_division = 0)['recall']\n",
    "\n",
    "        micro_f1 = f1_metric.compute( references = y_true, predictions = y_pred, average= 'micro')['f1']\n",
    "        macro_f1 = f1_metric.compute(references = y_true, predictions = y_pred, average = 'macro')['f1']\n",
    "        weighted_f1 = f1_metric.compute( references = y_true, predictions = y_pred, average = 'weighted')['f1']\n",
    "\n",
    "        return epoch_loss, micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1\n",
    "\n",
    "\n",
    "\n",
    "            # Go through all samples in batch and add to computation batch\n",
    "            #for idx, pred_batch in enumerate(predictions):\n",
    "            #    references_all.extend(label_ids[idx])\n",
    "            #    predictions_all.extend(pred_batch)\n",
    "            \n",
    "            # Calculate ROC (TODO)\n",
    "            #for batch_idx, pred_batch in enumerate(predictions_sm):\n",
    "            #    predictions_roc_all.extend(pred_batch.tolist())\n",
    "            #    references_roc_all.extend(labels[batch_idx])\n",
    "            #    #roc_auc_metric.add_batch(references=labels[batch_idx], prediction_scores = pred_batch.tolist())\n",
    "            #    break\n",
    "            #break\n",
    "        #\n",
    "\n",
    "        \n",
    "        # List all possible labels\n",
    "        labels = np.arange(tokenizer.vocab_size)\n",
    "        with open(results_dir +\"results.txt\", \"w\") as output:\n",
    "            print(f\"Results: {config.tokenizer}, Train={config.train_model} {config.tokenizer}_E{config.epochs}_batches{config.batch_size}_LR{config.learning_rate}_SL{config.sequence_length}\", file = output)\n",
    "            output.write(\"macro averaging\\n\")\n",
    "            output.write(str(recall_metric.compute(references = y_true, predictions = y_pred, average = 'macro')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute(references = y_true, predictions = y_pred, average = 'macro', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = y_true, predictions = y_pred, average = 'macro')))\n",
    "            #output.write(\"\\n\")\n",
    "            #output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'macro', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(\"weighted averaging\\n\")\n",
    "            output.write(str(recall_metric.compute( references = y_true, predictions = y_pred, average = 'weighted')))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(precision_metric.compute( references = y_true, predictions = y_pred, average = 'weighted', zero_division = 0)))\n",
    "            output.write(\"\\n\")\n",
    "            output.write(str(f1_metric.compute( references = y_true, predictions = y_pred, average = 'weighted')))\n",
    "            #output.write(\"\\n\")\n",
    "            #output.write(str(roc_auc_metric.compute( references = references_roc_all, prediction_scores = predictions_roc_all, average = 'weighted', multi_class = 'ovo', labels = labels, max_fpr = 1.0)))\n",
    "            output.close()\n",
    "    \n",
    "    if (config.task == 'ner'):\n",
    "\n",
    "        sep_token_id = int(ner_tags_list.index(\"[SEP]\"))\n",
    "        cls_token_id = int(ner_tags_list.index(\"[CLS]\"))\n",
    "        unk_token_id = int(ner_tags_list.index(\"<unk>\"))\n",
    "        O_token_id = int(ner_tags_list.index(\"O\"))\n",
    "\n",
    "        special_token_predictions = 0\n",
    "        O_token_predictions = 0\n",
    "        ner_token_predictions = 0\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(data_loader, leave=True, miniters=200, maxinterval=7000)\n",
    "        # Loop over all batches\n",
    "        #prof.start()\n",
    "        for batch in loop:\n",
    "            batch = tuple(t for t in batch)\n",
    "            if (config.use_gnn):\n",
    "                input_ids, input_masks, label_ids, valid_ids, label_mask, segment_ids, pyg_data, sentence_graph_idx_maps = batch\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_masks = input_masks.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "                label_ids = label_ids.to(device)\n",
    "                valid_ids = valid_ids.to(device)\n",
    "                label_mask = label_mask.to(device)\n",
    "            else:\n",
    "                input_ids, input_masks, label_ids, valid_ids, label_mask, segment_ids = batch\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_masks = input_masks.to(device)\n",
    "                segment_ids = segment_ids.to(device)\n",
    "                label_ids = label_ids.to(device)\n",
    "                valid_ids = valid_ids.to(device)\n",
    "                label_mask = label_mask.to(device)\n",
    "\n",
    "            if(mode == 'Train'):\n",
    "                # initialize gradients for batch to zero\n",
    "                optimizer.zero_grad()\n",
    "                if (config.use_gnn):\n",
    "                    loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids, syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                    #prof.step()\n",
    "                else:\n",
    "                    loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids)\n",
    "                # calculate loss for every parameter that needs grad update\n",
    "                loss.backward()\n",
    "                if (config.max_grad_norm):\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "            elif(mode == 'Validation'):\n",
    "                with torch.no_grad():\n",
    "                    if (config.use_gnn):\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids, syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                    else:\n",
    "                        loss, logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, attention_mask_label=label_mask,label_ids=label_ids,valid_ids=valid_ids)\n",
    "            elif(mode == 'Test'):\n",
    "                if (config.use_gnn):\n",
    "                    logits = model(input_ids=input_ids, token_type_ids=segment_ids,attention_mask=input_masks,valid_ids=valid_ids,attention_mask_label=label_mask, syntax_graphs=pyg_data, sentence_graph_idx_maps=sentence_graph_idx_maps)\n",
    "                else:\n",
    "                    logits = model(input_ids, segment_ids, input_masks,valid_ids=valid_ids,attention_mask_label=label_mask)\n",
    "\n",
    "            if(mode == 'Validation' or mode == 'Train'):\n",
    "                # print relevant info to progress bar\n",
    "                loop.set_description(f'{mode} Epoch {epoch}', refresh=False)\n",
    "                batch_loss = loss.item()\n",
    "                loop.set_postfix(loss=batch_loss, refresh=False)\n",
    "                epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "            \n",
    "            #print(f\"Logits{logits.size()}\")\n",
    "            softmax = nn.Softmax(dim=2)\n",
    "\n",
    "            # Get highest NER label prediction for all sentences\n",
    "            #print(f\"Softmax:{softmax(logits)}\")\n",
    "            logits = torch.argmax(softmax(logits),dim=2)\n",
    "            #print(f\"Argmax: {logits.size()}\")\n",
    "            logits = logits.to(device).numpy()\n",
    "            label_ids = label_ids.numpy()\n",
    "            input_masks = input_masks.numpy()\n",
    "\n",
    "            # Go through true labels\n",
    "            for label_list_idx, true_sentence_labels in enumerate(label_ids):\n",
    "                y_true_temp = []\n",
    "                y_pred_temp = []\n",
    "\n",
    "                for label_idx, label_id in enumerate(true_sentence_labels):\n",
    "\n",
    "                    # Skip 0 label\n",
    "                    if label_id == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip [CLS] label at sequence beginning\n",
    "                    if label_id == cls_token_id:\n",
    "                        continue\n",
    "\n",
    "                    # Detect [SEP] label at sentence end and ignore [SEP] and all sequence padding\n",
    "                    # Append all found labels to y_true and y_pred\n",
    "                    elif label_id == sep_token_id:\n",
    "                        y_true.append(y_true_temp)\n",
    "                        y_pred.append(y_pred_temp)\n",
    "                        break\n",
    "                    else:\n",
    "                        # Predicted NER label is special token X: count preds\n",
    "                        if (logits[label_list_idx][label_idx] == 0):\n",
    "                        #if (logits[label_list_idx] == 0):\n",
    "                            special_token_predictions = special_token_predictions +1\n",
    "                        # Predicted NER label is O: count preds\n",
    "                        elif (logits[label_list_idx][label_idx] == O_token_id):\n",
    "                        #elif (logits[label_list_idx] == O_token_id):\n",
    "                            O_token_predictions = O_token_predictions +1\n",
    "                        else:\n",
    "                            ner_token_predictions = ner_token_predictions +1\n",
    "\n",
    "                        # Append label and prediction to list\n",
    "                        y_true_temp.append(label_map[label_id])\n",
    "                        y_pred_temp.append(label_map[logits[label_list_idx][label_idx]])\n",
    "                        #y_pred_temp.append(label_map[logits[label_list_idx]])\n",
    "\n",
    "        if (mode == 'Train' or mode == 'Validation'):\n",
    "            #print(f\"True: {y_true[0:5]}, Predicted: {y_pred[0:5]}\")\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=True, zero_division = 0)\n",
    "            # Calculate epoch loss\n",
    "            epoch_loss = epoch_loss / len(data_loader)\n",
    "\n",
    "            # Print info to Tensorboard\n",
    "            writer.add_scalar(\"Loss\", epoch_loss, epoch)\n",
    "\n",
    "            micro_precision = report['micro avg']['precision']\n",
    "            writer.add_scalar(\"micro_avg/precision\", micro_precision, epoch)\n",
    "            micro_recall = report['micro avg']['recall']\n",
    "            writer.add_scalar(\"micro_avg/recall\", micro_recall, epoch)\n",
    "            micro_f1 = report['micro avg']['f1-score']\n",
    "            writer.add_scalar(\"micro_avg/f1\", micro_f1, epoch)\n",
    "\n",
    "            macro_precision = report['macro avg']['precision']\n",
    "            writer.add_scalar(\"macro_avg/precision\", macro_precision, epoch)\n",
    "            macro_recall = report['macro avg']['recall']\n",
    "            writer.add_scalar(\"macro_avg/recall\", macro_recall, epoch)\n",
    "            macro_f1 = report['macro avg']['f1-score']\n",
    "            writer.add_scalar(\"macro_avg/f1\", macro_f1, epoch)\n",
    "\n",
    "            weighted_precision = report['weighted avg']['precision']\n",
    "            writer.add_scalar(\"weighted_avg/precision\", weighted_precision, epoch)\n",
    "            weighted_recall = report['weighted avg']['recall']\n",
    "            writer.add_scalar(\"weighted_avg/recall\", weighted_recall, epoch)\n",
    "            weighted_f1 = report['weighted avg']['f1-score']\n",
    "            writer.add_scalar(\"weighted_avg/f1\", weighted_f1, epoch)\n",
    "            print(f\"O Token Predictions: {O_token_predictions}, NER token predictions: {ner_token_predictions}\")\n",
    "            print(f\"loss: {epoch_loss} w prec: {weighted_precision} w recall: {weighted_recall} w f1: {weighted_f1}\")\n",
    "            return epoch_loss, micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1, weighted_precision, weighted_recall, weighted_f1\n",
    "\n",
    "        else:\n",
    "            date = datetime.datetime.now()\n",
    "            report = classification_report(y_true, y_pred, digits=4, output_dict=False)\n",
    "            with open(results_dir +f\"results_E{epoch}.txt\", \"w\") as output:\n",
    "                print(\"***** Test results *****\")\n",
    "                print(f\"{report}\\n Special token predictions: {special_token_predictions}\")\n",
    "\n",
    "                output.write(\"***** Test results *****\\n\")\n",
    "                output.write(date.strftime(\"%c\")+\"\\n\")\n",
    "                output.write(f\"Task: {config.task}\\n\")\n",
    "                output.write(f\"Model path: {config.saved_model_path}\\n\")\n",
    "                output.write(f\"Data path: {config.data_path}\\n\")\n",
    "                output.write(f\"Tokenizer: {config.tokenizer}\\n\")\n",
    "                output.write(f\"Batch size: {config.batch_size}\\n\")\n",
    "                output.write(f\"Epoch: {epoch}\\n\")\n",
    "                output.write(f\"Learning rate: {config.learning_rate}\\n\")\n",
    "                output.write(f\"LR Decay End Factor: {config.lr_decay}\")\n",
    "                output.write(f\"LR Decay End Epoch: {config.lr_decay_end}\")\n",
    "                output.write(f\"Sequence length: {config.sequence_length}\\n\")\n",
    "                output.write(f\"Training: {config.train_model}\\n\")\n",
    "                output.write(f\"Num Threads: {config.num_threads}\\n\")\n",
    "                output.write(f\"Num Sentences: {config.num_sentences}\\n\")\n",
    "                output.write(f\"Max Grad Norm: {config.max_grad_norm}\\n\")\n",
    "                output.write(f\"Use GNN: {config.use_gnn}\\n\")\n",
    "                if(config.use_gnn == True):\n",
    "                    output.write(f\"Num layers: {config.num_layers}\\n\")\n",
    "                    output.write(f\"Num attention heads: {config.num_att_heads}\\n\")\n",
    "                output.write(f\"Syntax graph style: {config.use_grammar}\\n\")\n",
    "                output.write(f\"Use label weights: {config.use_label_weights}\\n\")\n",
    "                output.write(f\"Clip value: {config.label_weights_clip}\\n\")\n",
    "\n",
    "                output.write(f\"{report}\\n Special token predictions: {special_token_predictions}\\n\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (config.train_model):\n",
    "    tokenizer = BertTokenizer.from_pretrained(config.tokenizer)\n",
    "    print(\"Training model\", flush=True)\n",
    "\n",
    "    # NER: create class weights to counter class imbalance\n",
    "    # MLM: create uniform class weights\n",
    "    trainLoader, label_weights = load_train_data(tokenizer)\n",
    "    validationLoader, _ = load_validation_data(tokenizer)\n",
    "    test_loader, _ = load_test_data(tokenizer)\n",
    "\n",
    "    epochs = config.epochs\n",
    "\n",
    "\n",
    "    if(config.task == 'mlm'):\n",
    "        if (config.use_gnn):\n",
    "            BERTconfig = BertConfig.from_pretrained(config.saved_model_path, num_labels=num_ner_labels, tokenizer = tokenizer, is_decoder=False)\n",
    "            model = models.SynBertForNer(bert_config = BERTconfig, bert_model = config.saved_model_path, num_node_features=bert_embedding_size, num_labels = num_mlm_labels, num_edge_attrs = 54, num_att_heads = config.num_att_heads, num_layers = config.num_layers, label_weights = label_weights, task = config.task)\n",
    "        else:\n",
    "            model = BertForMaskedLM.from_pretrained(config.saved_model_path)\n",
    "    elif(config.task == 'ner'):\n",
    "        BERTconfig = BertConfig.from_pretrained(config.saved_model_path, num_labels=num_ner_labels, tokenizer = tokenizer)\n",
    "        if (config.use_gnn):\n",
    "        #model = models.SynBertForNer.from_pretrained(config.saved_model_path, num_node_features=1, num_labels = num_ner_labels, num_att_heads = 2, num_layers = 3, from_tf = False, config = BERTconfig, low_cpu_mem_usage=True)\n",
    "            if config.use_grammar == \"dep\":\n",
    "                model = models.SynBertForNer(bert_config = BERTconfig, bert_model = config.saved_model_path, num_node_features = bert_embedding_size, num_labels = num_ner_labels, num_edge_attrs = 54, num_att_heads = config.num_att_heads, num_layers = config.num_layers, label_weights = label_weights, task = config.task)\n",
    "            # No edge attributes\n",
    "            elif config.use_grammar == \"const\":\n",
    "                model = models.SynBertForNer(bert_config = BERTconfig, bert_model = config.saved_model_path, num_node_features = bert_embedding_size, num_labels = num_ner_labels, num_edge_attrs = None, num_att_heads = config.num_att_heads, num_layers = config.num_layers, label_weights = label_weights, task = config.task)\n",
    "        else:\n",
    "            model = models.BertForNer.from_pretrained(config.saved_model_path, from_tf = False, config = BERTconfig, label_weights=label_weights)\n",
    "    device =  torch.device('cpu')\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    from torch.optim import AdamW\n",
    "    from torch.optim.lr_scheduler import LinearLR\n",
    "    # initialize optimizer\n",
    "    optim = AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    # Initialize learning rate scheduler\n",
    "    lr_scheduler = LinearLR(optim, start_factor=1.0, end_factor=config.lr_decay, total_iters=config.lr_decay_end, verbose=True)\n",
    "    train_writer = SummaryWriter(log_dir=tensorboard_dir+\"training\")\n",
    "    validation_writer = SummaryWriter(log_dir=tensorboard_dir+\"validation\")\n",
    "\n",
    "    epoch_losses_train = []\n",
    "    micro_precisions_train = []\n",
    "    micro_recalls_train = []\n",
    "    micro_f1s_train = []\n",
    "    macro_precisions_train = []\n",
    "    macro_recalls_train = []\n",
    "    macro_f1s_train = []\n",
    "    weighted_precisions_train = []\n",
    "    weighted_recalls_train = []\n",
    "    weighted_f1s_train = []\n",
    "\n",
    "    epoch_losses_validation = []\n",
    "    micro_precisions_val = []\n",
    "    micro_recalls_val = []\n",
    "    micro_f1s_val = []\n",
    "    macro_precisions_val = []\n",
    "    macro_recalls_val = []\n",
    "    macro_f1s_val = []\n",
    "    weighted_precisions_val = []\n",
    "    weighted_recalls_val = []\n",
    "    weighted_f1s_val = []\n",
    "\n",
    "    for epoch in range(config.trained_epochs,epochs+config.trained_epochs):\n",
    "        #epoch_losses_train.append(trainModel(epoch, trainLoader, train_writer))\n",
    "        #epoch_losses_validation.append(validateModel(epoch, validationLoader, validation_writer))\n",
    "\n",
    "        epoch_loss_train, micro_precision_train, micro_recall_train, micro_f1_train, macro_precision_train, macro_recall_train, macro_f1_train, weighted_precision_train, weighted_recall_train, weighted_f1_train = runModel(data_loader = trainLoader, model = model, device = device, tokenizer = tokenizer, mode = 'Train', writer = train_writer, results_dir = results_dir, epoch=epoch, optimizer=optim)\n",
    "        epoch_losses_train.append(epoch_loss_train)\n",
    "\n",
    "        micro_precisions_train.append(micro_precision_train)\n",
    "        micro_recalls_train.append(micro_recall_train)\n",
    "        micro_f1s_train.append(micro_f1_train)\n",
    "\n",
    "        macro_precisions_train.append(macro_precision_train)\n",
    "        macro_recalls_train.append(macro_recall_train)\n",
    "        macro_f1s_train.append(macro_f1_train)\n",
    "\n",
    "        weighted_precisions_train.append(weighted_precision_train)\n",
    "        weighted_recalls_train.append(weighted_recall_train)\n",
    "        weighted_f1s_train.append(weighted_f1_train)\n",
    "\n",
    "        epoch_loss_val, micro_precision_val, micro_recall_val, micro_f1_val, macro_precision_val, macro_recall_val, macro_f1_val, weighted_precision_val, weighted_recall_val, weighted_f1_val = runModel(data_loader = validationLoader,  tokenizer = tokenizer, model = model, device = device, mode = 'Validation', writer = validation_writer, results_dir = results_dir, epoch=epoch, optimizer=optim)\n",
    "        epoch_losses_validation.append(epoch_loss_val)\n",
    "\n",
    "        micro_precisions_val.append(micro_precision_val)\n",
    "        micro_recalls_val.append(micro_recall_val)\n",
    "        micro_f1s_val.append(micro_f1_val)\n",
    "\n",
    "        macro_precisions_val.append(macro_precision_val)\n",
    "        macro_recalls_val.append(macro_recall_val)\n",
    "        macro_f1s_val.append(macro_f1_val)\n",
    "\n",
    "        weighted_precisions_val.append(weighted_precision_val)\n",
    "        weighted_recalls_val.append(weighted_recall_val)\n",
    "        weighted_f1s_val.append(weighted_f1_val)\n",
    "\n",
    "        # Decrease learning rate\n",
    "        lr_scheduler.step()\n",
    "        if (activeMode == 'prod' and config.use_gnn == False):\n",
    "            last_epoch = epoch-1\n",
    "            if last_epoch < 0:\n",
    "                last_epoch = 0\n",
    "            # Save model after each epoch\n",
    "            trained_models_dir = trained_models_dir.replace(f\"_E{last_epoch}_\", f\"_E{epoch}_\")\n",
    "            trained_models_dir = utils.createNumberedDir(trained_models_dir)\n",
    "            model.save_pretrained(save_directory=trained_models_dir)\n",
    "\n",
    "        if epoch > 5:\n",
    "            print(\"Model evaluation\\n\", flush = True)\n",
    "            runModel(data_loader = test_loader, tokenizer = tokenizer, model = model, device = device, mode = 'Test', results_dir=results_dir, epoch= epoch)\n",
    "    \n",
    "    train_writer.close()\n",
    "    validation_writer.close()\n",
    "    #prof.stop()\n",
    "    # Save epoch loss plots\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), epoch_losses_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), epoch_losses_validation, 'g', label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/loss.png\", facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # # Save micro f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), micro_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), micro_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Micro Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_micro.png\", facecolor='white', transparent=False)\n",
    "\n",
    "    # # Save macro f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), macro_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), macro_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted f1 plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs), weighted_f1s_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs), weighted_f1s_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg F1')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/f1_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save micro recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), micro_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), micro_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Micro Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_micro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save macro recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_macro.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save weighted recall plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_recalls_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/recall_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "    # # Save micro precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), micro_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), micro_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Micro Avg Precison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_micro.png\", facecolor='white', transparent=False)\n",
    "\n",
    "    # # Save macro precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), macro_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Macro Avg Precison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_macro.png\", facecolor='white', transparent=False)\n",
    "\n",
    "    #  # Save weighted precision plot\n",
    "    plt.figure()\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_train, 'b', label='Training')\n",
    "    plt.plot(range(0,epochs,1), weighted_precisions_val, 'g', label='Validation')\n",
    "    plt.title('Weighted Avg Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    plt.savefig(results_dir +\"/precision_weighted.png\", facecolor='white', transparent=False)\n",
    "    # #plt.show()\n",
    "\n",
    "\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs)\n",
    "for epoch in range(config.trained_epochs,epochs):\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Model evaluation\\n\", flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy log file into results folder\n",
    "import shutil\n",
    "shutil.copy(\"./logs/syngnn_main.log\", results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(references_all, predictions_all, labels=labels)\n",
    "#print(confusion_matrix)\n",
    "#disp = metrics.ConfusionMatrixDisplay(references_all, predictions_all, labels=labels)\n",
    "#disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_syntrans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86a731642ee256d624a4d29e8688bb9c6ad7b39856affb444c6cc9f38126795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
